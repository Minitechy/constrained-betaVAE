{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a004ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from adjustText import adjust_text\n",
    "from numpy import pi, e\n",
    "from numpy.linalg import inv, det\n",
    "from numpy.linalg import norm as LA_norm\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from termcolor import colored\n",
    "import itertools\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48c1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(m, n):\n",
    "    return np.random.rand(m, n)\n",
    "\n",
    "def initial_inputs(flag):\n",
    "    if flag == 0:\n",
    "        # Create initial encoder inputs (B, Sigma_W)\n",
    "        B = create_matrix(m, n)\n",
    "        Sigma_W = make_spd_matrix(m)\n",
    "        return np.concatenate(([flag], B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        # Create initial decoder inputs (A, Sigma_Z)\n",
    "        A = create_matrix(n, m)\n",
    "        Sigma_Z = np.diag(random(n))\n",
    "        return np.concatenate(([flag], A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "\n",
    "def is_close_to_zero(arr, etol):\n",
    "    return np.allclose(arr, 0, atol=etol)\n",
    "\n",
    "def is_singular(matrix):\n",
    "    is_singular = np.linalg.matrix_rank(matrix) < min(matrix.shape)\n",
    "    if is_singular:\n",
    "        print(colored('The matrix is singular.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not singular.', 'red', attrs=['bold']))\n",
    "\n",
    "def is_positive_definite(matrix):\n",
    "    if np.all(np.linalg.eigvals(matrix) > 0):\n",
    "        print(colored('The matrix is positive definite.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not positive definite.', 'red', attrs=['bold']))\n",
    "        \n",
    "def assign_None(matrix, matrix_list):\n",
    "    if len(matrix) == 0:\n",
    "        matrix_list.append(None)\n",
    "    else:\n",
    "        matrix_list.append(matrix)\n",
    "\n",
    "def matrix_B(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    B = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A) @ A.T @ inv_Sigma_Z_hat\n",
    "    return B\n",
    "\n",
    "def covariance_matrix_W(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    Sigma_W = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A)\n",
    "    return Sigma_W\n",
    "\n",
    "def matrix_A(B, Sigma_W):\n",
    "    A = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B) @ B.T @ inv(Sigma_W)\n",
    "    return A\n",
    "\n",
    "def covariance_matrix_Z(B, Sigma_W):\n",
    "    Sigma_Z = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B)\n",
    "    diagonalized_Sigma_Z = np.diag(Sigma_Z.diagonal())\n",
    "    return diagonalized_Sigma_Z\n",
    "\n",
    "def covariance_matrix_XV(B):\n",
    "    cov_XV = np.block([[np.identity(m), B @ eigenvectors @ Sigma_V],\n",
    "                       [(B @ eigenvectors @ Sigma_V).T, Sigma_V]])\n",
    "    return cov_XV\n",
    "\n",
    "def encoder_mi(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(Sigma_W))\n",
    "\n",
    "def decoder_mi(A, Sigma_Z):\n",
    "    return 0.5 * np.log(det(A @ A.T + Sigma_Z) / det(Sigma_Z))\n",
    "\n",
    "def mi_VX(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(sigma_squared * B @ B.T + Sigma_W))\n",
    "\n",
    "def reconstruction_error(recon, orig):\n",
    "    norm_diff = LA_norm(orig - recon, 2)\n",
    "    orig_norm = LA_norm(orig, 2)\n",
    "    recon_err = norm_diff / orig_norm\n",
    "    return recon_err\n",
    "\n",
    "def objective_function(A, B, Sigma_Z, Sigma_W):\n",
    "    Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "    \n",
    "    regularizer = 0.5 * (np.trace(Sigma_X) - np.log(det(Sigma_W)) - m)\n",
    "    reconstruction = 0.5 * (np.trace(Sigma_X) + \\\n",
    "                            np.trace(A.T @ inv(Sigma_Z) @ Sigma_Y @ B.T) + \\\n",
    "                            np.trace(inv(Sigma_Z) @ A @ B @ Sigma_Y) - \\\n",
    "                            np.trace(inv(Sigma_Z) @ Sigma_Y) - \\\n",
    "                            np.trace((np.identity(m) + A.T @ inv(Sigma_Z) @ A) @ Sigma_X) - \\\n",
    "                            n * np.log(2 * pi) - np.log(det(Sigma_Z)))\n",
    "    lambda_term = lamda * np.trace((np.identity(n) - A @ B) @ Sigma_Y @ ((np.identity(n) - A @ B).T) + A @ Sigma_W @ A.T)\n",
    "    \n",
    "    return regularizer - gamma * reconstruction + lambda_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c4fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_function(cf_arr):\n",
    "    \"\"\"\n",
    "    Plot values of objective function against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(cf_arr) + 1), cf_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Cost Function', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_encoder_mi(en_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of encoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(en_mi_arr) + 1), en_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Encoder', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decoder_mi(de_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of decoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(de_mi_arr) + 1), de_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Decoder', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ae4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_optimal_solution(sol, m):\n",
    "    A_arr = sol[:n*m] \n",
    "    B_arr = sol[n*m:2*n*m]\n",
    "    Sigma_Z_arr = sol[2*n*m:2*n*m+n*n]\n",
    "    Sigma_Z = Sigma_Z_arr.reshape((n, n))\n",
    "    Sigma_W_arr = sol[2*n*m+n*n:2*n*m+n*n+m*m]\n",
    "    Sigma_W = Sigma_W_arr.reshape((m, m))\n",
    "    cost_function = sol[2*n*m+n*n+m*m:2*n*m+n*n+m*m+1][0]\n",
    "    en_mi = sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0]\n",
    "    de_mi = sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0]\n",
    "    recon_err = sol[-1]\n",
    "    len_cf_mi_arr = sol[2*n*m+n*n+m*m+3:2*n*m+n*n+m*m+6]\n",
    "    Sigma_X = sol[2*n*m+n*n+m*m+6:2*n*m+n*n+2*m*m+6].reshape((m, m))\n",
    "    Sigma_Y_hat = sol[2*n*m+n*n+2*m*m+6:2*n*m+2*n*n+2*m*m+6].reshape((n, n))\n",
    "    \n",
    "    print(colored('Optimal solution:', attrs=['bold']))\n",
    "    \n",
    "    if m > 1:\n",
    "        print('Matrix A:\\n{}'.format(np.round(A_arr.reshape((n, m)), 4)))\n",
    "        print('\\nMatrix B:\\n{}'.format(np.round(B_arr.reshape((m, n)), 4)))\n",
    "        print('\\nCovariance matrix of Z:\\n{}'.format(np.round(Sigma_Z, 4)))\n",
    "        print('\\nCovariance matrix of W:\\n{}'.format(np.round(Sigma_W, 4)))\n",
    "        print('\\nMinimum value of the cost function:\\n{}'.format(round(cost_function, 4)))\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 8)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 8)))\n",
    "        print('\\nValue of Sigma_Y_hat:\\n{}'.format(np.round(Sigma_Y_hat, 4)))\n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "    else:\n",
    "        print('Vector a:\\n{}'.format(np.round(A_arr.reshape((n, m)), 4)))\n",
    "        print('\\nVector b:\\n{}'.format(np.round(B_arr.reshape((m, n)), 4)[0]))\n",
    "        print('\\nCovariance matrix of Z:\\n{}'.format(np.round(Sigma_Z, 4)))\n",
    "        print('\\nVariance of W:\\n{}'.format(np.round(Sigma_W, 4)[0][0]))\n",
    "        print('\\nMinimum value of the cost function:\\n{}'.format(round(cost_function, 4)))\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 8)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 8)))\n",
    "        print('\\nValue of Sigma_Y_hat:\\n{}'.format(np.round(Sigma_Y_hat, 4)))  \n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "        \n",
    "    return len_cf_mi_arr\n",
    "\n",
    "def print_comprehensive_results(gamma, lamda, flag, m, n, is_arr):\n",
    "    if flag == 0:\n",
    "        # Generate random initial encoder inputs (B, Sigma_W)\n",
    "        B, Sigma_W = initial_inputs(flag)[1:1+m*n].reshape((m, n)), initial_inputs(flag)[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "    else:\n",
    "        # Generate random initial decoder inputs (A, Sigma_Z)\n",
    "        A, Sigma_Z = initial_inputs(flag)[1:1+n*m].reshape((n, m)), initial_inputs(flag)[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "    \n",
    "    # Print given inputs\n",
    "    if is_arr == 0:\n",
    "        if m > 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial matrix B:')\n",
    "            print(np.round(B.reshape((m, n)), 4))\n",
    "            print('\\nInitial covariance matrix of W:')\n",
    "            print(np.round(Sigma_W, 4))\n",
    "        elif m == 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial vector b:')\n",
    "            print(np.round(B.reshape((m, n)), 4)[0])\n",
    "            print('\\nInitial variance of W:')\n",
    "            print(np.round(Sigma_W, 4)[0][0])\n",
    "        elif m > 1 and flag == 1:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial matrix A:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))\n",
    "        else:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial vector a:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))    \n",
    "    \n",
    "        # Print results\n",
    "        if flag == 0:\n",
    "            # Compute optimal solution given encoder inputs\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "    \n",
    "            # Extract length of arrays for cost function and mutual information of encoder and decoder\n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            # Plot values of cost function and mutual information against iterations\n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)  \n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "        \n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)\n",
    "    else:\n",
    "        if flag == 0:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 8)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 8)\n",
    "            recon_err = round(opt_sol[-1], 8)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]\n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 8)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 8)\n",
    "            recon_err = round(opt_sol[-1], 8)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fbe240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "*****************************************************************\n",
    "**                          ALGORITHM                          **\n",
    "*****************************************************************\n",
    "   \n",
    "Inputs:\n",
    "- MAX_ITERS: Maximum number of iterations\n",
    "- n, m: Dimensions of the matrix\n",
    "- TOL_ERR: Tolerable error\n",
    "- Sigma_Y: A random nxn positive definite matrix\n",
    "\n",
    "Algorithm:\n",
    "1. Initialize flag\n",
    "    a. If we start with the encoder, set flag = 0.\n",
    "    b. Otherwise, set flag = 1.\n",
    "    \n",
    "2. Generate initial inputs for the iteration step\n",
    "    a. If flag = 0, then do:\n",
    "        i. create random initial encoder inputs, including \n",
    "            - a random mxn matrix B\n",
    "            - a random mxm positive definite covariance matrix Sigma_W\n",
    "        ii. set flag = 1.\n",
    "    b. If flag = 1, then do:\n",
    "        i. create random initial decoder inputs, including \n",
    "            - a random nxm matrix A\n",
    "            - a random nxn positive definite covariance matrix Sigma_Z\n",
    "        ii. set flag = 0.\n",
    "        \n",
    "3. Set iteration counter i = 0. \n",
    "\n",
    "4. Iterative step\n",
    "    a. If flag = 0, given the decoder inputs (A, Sigma_Z) at iteration i,\n",
    "        i. compute the corresponding encoder inputs at iteration i+1:\n",
    "            B = matrix_B(A, Sigma_Z)\n",
    "            Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "        ii. set flag = 1.\n",
    "        iii. compute the resulting gamma-VAE cost function and mutual information of the encoder.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "    b. If flag = 1, given the encoder inputs (B, Sigma_W) at iteration i,\n",
    "        i. compute the corresponding decoder inputs at iteration i:\n",
    "            A = matrix_A(B, Sigma_W)\n",
    "            Sigma_Z = covariance_matrix_Z(B, Sigma_W, is_diagonal)\n",
    "        ii. set flag = 0.\n",
    "        iii. compute the resulting gamma-VAE cost function, mutual information of the decoder, and reconstruction error.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "            \n",
    "5. Increment iteration counter i <- i + 1.\n",
    "\n",
    "6. If the iteration counter i < MAX_ITERS, then move back to step 4.\n",
    "    Otherwise, move to step 7.\n",
    "    \n",
    "7. Compute the values of Sigma_X and Sigma_Y_hat.\n",
    "        \n",
    "8. Display results\n",
    "    a. display the optimal solution (A, B, Sigma_Z, Sigma_W).\n",
    "    b. display the corresponding minimum value of gamma-VAE cost function.\n",
    "    c. display the resulting mutual information of both encoder and decoder.\n",
    "    d. display the values of Sigma_X and Sigma_Y_hat.\n",
    "    e. display the value of reconstruction error.\n",
    "    f. move to step 9.\n",
    "    \n",
    "9. Stop.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def rate_distortion(inputs, is_arr):\n",
    "    flag = inputs[0]\n",
    "    if flag == 0:\n",
    "        B = inputs[1:1+m*n].reshape((m, n))\n",
    "        Sigma_W = inputs[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "        flag = 1\n",
    "        # Array of current encoder inputs (B_t, Sigma_W_t)\n",
    "        current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        A = inputs[1:1+n*m].reshape((n, m))\n",
    "        Sigma_Z = inputs[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "        flag = 0\n",
    "        # Array of current decoder inputs (A_t, Sigma_Z_t)\n",
    "        current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "    \n",
    "    # Cost function and mutual information arrays\n",
    "    cf_arr = []\n",
    "    en_mi_arr = []\n",
    "    de_mi_arr = [] \n",
    "\n",
    "    # Iteration step\n",
    "    try:\n",
    "        for i in range(0, MAX_ITERS):\n",
    "            if  flag == 0:\n",
    "                B = matrix_B(A, Sigma_Z)\n",
    "                Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "                flag = 1\n",
    "                \n",
    "                # Check if the value of the cost function is not a number\n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_en_mi = encoder_mi(B, Sigma_W)\n",
    "                en_mi_arr = np.concatenate((en_mi_arr, [current_en_mi]))\n",
    "                \n",
    "                # For the first iteration, update the current encoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. B and itself in the previous iteration\n",
    "                #    ii. Sigma_W and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current encoder inputs and value of the cost function\n",
    "                else:\n",
    "                    B_diff = B - current_encoder_inputs[:m*n].reshape((m, n))\n",
    "                    B_norm_diff = LA_norm(B_diff, 'fro')\n",
    "                    Sigma_W_diff = Sigma_W - current_encoder_inputs[m*n:m*n+m*m].reshape((m, m))\n",
    "                    Sigma_W_norm_diff = LA_norm(Sigma_W_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    # Check for convergence\n",
    "                    if B_norm_diff <= TOL_ERR and Sigma_W_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break\n",
    "            else:\n",
    "                A = matrix_A(B, Sigma_W)\n",
    "                Sigma_Z = covariance_matrix_Z(B, Sigma_W)\n",
    "                flag = 0\n",
    "                \n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_de_mi = decoder_mi(A, Sigma_Z)\n",
    "                de_mi_arr = np.concatenate((de_mi_arr, [current_de_mi]))\n",
    "                \n",
    "                Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "                recon_err = reconstruction_error(Sigma_Y_hat, Sigma_Y)\n",
    "                \n",
    "                # For the first iteration, update the current decoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. A and itself in the previous iteration\n",
    "                #    ii. Sigma_Z and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current dencoder inputs and value of the cost function                \n",
    "                else:\n",
    "                    A_diff = A - current_decoder_inputs[:n*m].reshape((n, m))\n",
    "                    A_norm_diff = LA_norm(A_diff, 'fro')\n",
    "                    Sigma_Z_diff = Sigma_Z - current_decoder_inputs[n*m:n*m+n*n].reshape((n, n))\n",
    "                    Sigma_Z_norm_diff = LA_norm(Sigma_Z_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    # Check for convergence\n",
    "                    if A_norm_diff <= TOL_ERR and Sigma_Z_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break                       \n",
    "\n",
    "        # Compute Sigma_X and Sigma_Y_hat  \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi],\n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "          \n",
    "        if is_arr == 0 and i == MAX_ITERS - 1 and recon_err > MAX_RECON_ERR:\n",
    "            print(colored('\\nMax iterations was reached!', 'red', attrs=['bold']))\n",
    "            print('There is NO solutions that has reconstruction error statisfying the tolerance error = {}.\\n'.format(MAX_RECON_ERR))\n",
    "            \n",
    "        return sol\n",
    "    \n",
    "    except Exception as e:\n",
    "        if is_arr == 0:\n",
    "            print(colored('\\nThe algorithm fails to converge after {} iterations due to {}.\\n'.format(i+1, e), 'red', attrs=['bold']))\n",
    "         \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi], \n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "        return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ee78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Sigma_V(case):\n",
    "    for case_idx in range(num_cases):\n",
    "        if case_idx == 0:\n",
    "            # Case 1: Independent of generative parameters\n",
    "            std_devs = [std_dev_v1, std_dev_v2, std_dev_v3]\n",
    "            V_1 = [np.random.normal(mean, std_dev, size=num_samples) for std_dev in std_devs]\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_1 = np.round(np.cov(V_1), 4)\n",
    "        \n",
    "        elif case_idx == 1:\n",
    "            # Case 2: Linear dependence of v_1 and v_2, with independence of v_3\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            v_3 = np.random.normal(mean, std_dev_v3, size=num_samples)\n",
    "            \n",
    "            # Calculate v_2 using scaling factor alpha and random noise\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            \n",
    "            # Create generative variable V\n",
    "            V_2 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_2 = np.round(np.cov(V_2), 4)  \n",
    "        \n",
    "        else:\n",
    "            # Case 3: Linear dependence of v_2 and v_3, with v_1\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            \n",
    "            # Calculate additional generative parameters using scaling factors\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            random_noise_z3 = np.random.normal(mean, std_dev_z3, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            v_3 = beta * v_1 + random_noise_z3\n",
    "\n",
    "            # Create generative variable V\n",
    "            V_3 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_3 = np.round(np.cov(V_3), 4)\n",
    "    \n",
    "    if case == 0:\n",
    "        print(colored('Scenario 1:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v2, sigma_v3) = {std_dev_v1, std_dev_v2, std_dev_v3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_1)\n",
    "        is_singular(Sigma_V_1)\n",
    "        return Sigma_V_1\n",
    "    \n",
    "    elif case == 1:\n",
    "        print(colored('\\nScenario 2:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v3) = {std_dev_v1, std_dev_v3}, alpha = {alpha}, and sigma_z2 = {std_dev_z2}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_2)\n",
    "        is_singular(Sigma_V_2)\n",
    "        return Sigma_V_2\n",
    "    \n",
    "    else:\n",
    "        print(colored('\\nScenario 3:', attrs=['bold','underline']))\n",
    "        print(f'Given sigma_v1 = {std_dev_v1}, (alpha, beta) = {alpha, beta}, and (sigma_z2, sigma_z3) = {std_dev_z2, std_dev_z3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_3)\n",
    "        is_singular(Sigma_V_3)\n",
    "        return Sigma_V_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff45dfc",
   "metadata": {},
   "source": [
    "## I. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc2f26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mAn array of gamma:\u001b[0m\n",
      "[0.98 1.   1.02]\n",
      "\u001b[1m\u001b[34m\n",
      "An array of lambda:\u001b[0m\n",
      "[-0.02  0.    0.02]\n",
      "\u001b[1m\u001b[34m\n",
      "Independent eigenvectors:\u001b[0m\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance of noise Z_tilde:\u001b[0m\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0016 0.     0.    ]\n",
      " [0.     0.     0.0016 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given:\n",
    "1. Maximum number of iterations: MAX_ITERS = 10,000\n",
    "2. Dimensions of the matrix: s = 3, n = 4, and m = 3\n",
    "3. Tolerable error: TOL_ERR = 1e-8\n",
    "4. Reconstruction error tolerance: MAX_RECON_ERR = 0.05\n",
    "5. A nxn positive definite matrix Sigma_Y = Gamma * Sigma_V * Gamma_T + Sigma_Z_tilde\n",
    "6. An array of gamma = [0.98, 1, 1.02]\n",
    "7. An array of lambda = [-0.02, 0, 0.02]\n",
    "\"\"\"\n",
    "\n",
    "# Constants\n",
    "MAX_ITERS = 10000\n",
    "s, n, m = 3, 4, 3\n",
    "TOL_ERR = 1e-8\n",
    "MAX_RECON_ERR = 0.05\n",
    "\n",
    "num_cases = 3\n",
    "num_samples = int(1e7)\n",
    "alpha = 2\n",
    "beta = 4\n",
    "mean = 0\n",
    "std_dev_v1 = 0.01\n",
    "std_dev_v2 = 0.02\n",
    "std_dev_v3 = 0.03\n",
    "std_dev_z2 = 0.02\n",
    "std_dev_z3 = 0.03\n",
    "\n",
    "# Arrays of gamma and lambda\n",
    "gamma_arr = np.array([0.98, 1, 1.02])\n",
    "print(colored('An array of gamma:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(gamma_arr))\n",
    "\n",
    "lambda_arr = np.array([-0.02, 0, 0.02])\n",
    "print(colored('\\nAn array of lambda:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(lambda_arr))\n",
    "\n",
    "# Independent eigenvectors\n",
    "eigenvectors = np.array([[1, 0, 0],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 0, 1],\n",
    "                         [0, 0, 0]])\n",
    "print(colored('\\nIndependent eigenvectors:', 'blue', attrs=['bold']))\n",
    "print(eigenvectors)\n",
    "\n",
    "# Covariance of noise Z_tilde\n",
    "sigma_squared = 0.04**2\n",
    "Sigma_Z_tilde = sigma_squared * np.identity(n)\n",
    "print(colored('\\nCovariance of noise Z_tilde:', 'blue', attrs=['bold']))\n",
    "print(np.round(Sigma_Z_tilde, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d132e67",
   "metadata": {},
   "source": [
    "## II. Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d34c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAll ways to divide the indices of the generative parameters into three distinct groups:\n",
      "\u001b[0m\n",
      "Partition 1: Group 1: set(), Group 2: set(), Group 3: {4, 5, 6}\n",
      "Partition 2: Group 1: set(), Group 2: {4}, Group 3: {5, 6}\n",
      "Partition 3: Group 1: set(), Group 2: {5}, Group 3: {4, 6}\n",
      "Partition 4: Group 1: set(), Group 2: {6}, Group 3: {4, 5}\n",
      "Partition 5: Group 1: set(), Group 2: {4, 5}, Group 3: {6}\n",
      "Partition 6: Group 1: set(), Group 2: {4, 6}, Group 3: {5}\n",
      "Partition 7: Group 1: set(), Group 2: {5, 6}, Group 3: {4}\n",
      "Partition 8: Group 1: set(), Group 2: {4, 5, 6}, Group 3: set()\n",
      "Partition 9: Group 1: {4}, Group 2: set(), Group 3: {5, 6}\n",
      "Partition 10: Group 1: {5}, Group 2: set(), Group 3: {4, 6}\n",
      "Partition 11: Group 1: {6}, Group 2: set(), Group 3: {4, 5}\n",
      "Partition 12: Group 1: {4}, Group 2: {5}, Group 3: {6}\n",
      "Partition 13: Group 1: {4}, Group 2: {6}, Group 3: {5}\n",
      "Partition 14: Group 1: {5}, Group 2: {4}, Group 3: {6}\n",
      "Partition 15: Group 1: {5}, Group 2: {6}, Group 3: {4}\n",
      "Partition 16: Group 1: {6}, Group 2: {4}, Group 3: {5}\n",
      "Partition 17: Group 1: {6}, Group 2: {5}, Group 3: {4}\n",
      "Partition 18: Group 1: {4}, Group 2: {5, 6}, Group 3: set()\n",
      "Partition 19: Group 1: {5}, Group 2: {4, 6}, Group 3: set()\n",
      "Partition 20: Group 1: {6}, Group 2: {4, 5}, Group 3: set()\n",
      "Partition 21: Group 1: {4, 5}, Group 2: set(), Group 3: {6}\n",
      "Partition 22: Group 1: {4, 6}, Group 2: set(), Group 3: {5}\n",
      "Partition 23: Group 1: {5, 6}, Group 2: set(), Group 3: {4}\n",
      "Partition 24: Group 1: {4, 5}, Group 2: {6}, Group 3: set()\n",
      "Partition 25: Group 1: {4, 6}, Group 2: {5}, Group 3: set()\n",
      "Partition 26: Group 1: {5, 6}, Group 2: {4}, Group 3: set()\n",
      "Partition 27: Group 1: {4, 5, 6}, Group 2: set(), Group 3: set()\n"
     ]
    }
   ],
   "source": [
    "print(colored('All ways to divide the indices of the generative parameters into three distinct groups:\\n', attrs=['bold']))\n",
    "\n",
    "V_indices = np.arange(m+1, m+s+1)\n",
    "\n",
    "group_1_list_V = []\n",
    "group_2_list_V = []\n",
    "group_3_list_V = []\n",
    "group_1_list_XV = []\n",
    "group_2_list_XV = []\n",
    "group_3_list_XV = []\n",
    "\n",
    "# Initialize an empty list to store valid partitions\n",
    "valid_partitions = []\n",
    "\n",
    "# Generate all possible ways to divide the indices of parameters into 3 groups (may be empty)\n",
    "V_indices = np.arange(m+1, m+s+1)\n",
    "\n",
    "for i in range(len(V_indices) + 1):\n",
    "    for j in range(len(V_indices) + 1):\n",
    "        if i + j <= len(V_indices):\n",
    "            group_1_combinations = combinations(V_indices, i)\n",
    "            for group_1 in group_1_combinations:\n",
    "                remaining_indices_1 = set(V_indices) - set(group_1)\n",
    "                group_2_combinations = combinations(remaining_indices_1, j)\n",
    "                for group_2 in group_2_combinations:\n",
    "                    group_3 = tuple(index for index in V_indices if index not in group_1 and index not in group_2)\n",
    "                    valid_partitions.append((set(group_1), set(group_2), set(group_3)))\n",
    "\n",
    "for idx, partition in enumerate(valid_partitions, start=1):\n",
    "    group_1, group_2, group_3 = partition\n",
    "    print(f'Partition {idx}: Group 1: {group_1}, Group 2: {group_2}, Group 3: {group_3}')\n",
    "\n",
    "    # Add group information to respective lists\n",
    "    group_1_list_V.append(list(group_1))\n",
    "    group_2_list_V.append(list(group_2))\n",
    "    group_3_list_V.append(list(group_3))\n",
    "    \n",
    "    group_1_list_XV.append([1] + list(group_1))   \n",
    "    group_2_list_XV.append([2] + list(group_2))\n",
    "    group_3_list_XV.append([3] + list(group_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7221e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the result arrays with empty lists\n",
    "group_list_v1v2 = [[] for _ in range(len(group_1_list_V))]\n",
    "group_list_v1v3 = [[] for _ in range(len(group_1_list_V))]\n",
    "group_list_v2v3 = [[] for _ in range(len(group_1_list_V))]\n",
    "\n",
    "# Function to combine arrays\n",
    "def combine_arrays(result, arr):\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i]:\n",
    "            result[i].extend(arr[i])\n",
    "\n",
    "# Combine group_1_list_V and group_2_list_V\n",
    "combine_arrays(group_list_v1v2, group_1_list_V)\n",
    "combine_arrays(group_list_v1v2, group_2_list_V)\n",
    "\n",
    "# Combine group_1_list_V and group_3_list_V\n",
    "combine_arrays(group_list_v1v3, group_1_list_V)\n",
    "combine_arrays(group_list_v1v3, group_3_list_V)\n",
    "\n",
    "# Combine group_2_list_V and group_3_list_V\n",
    "combine_arrays(group_list_v2v3, group_2_list_V)\n",
    "combine_arrays(group_list_v2v3, group_3_list_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb560a",
   "metadata": {},
   "source": [
    "## III. Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_I3(det_v1, det_v2, det_v3, det_x1v1, det_x2v2, det_x3v3, \n",
    "               det_v1v2, det_v1v3, det_v2v3, len_group_1, len_group_2, len_group_3):\n",
    "    \n",
    "    # 2 groups are empty\n",
    "    if len_group_1 == 0 and len_group_2 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v3/det_x3v3), 8)\n",
    "    elif len_group_1 == 0 and len_group_3 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v2/det_x2v2), 8)\n",
    "    elif len_group_2 == 0 and len_group_3 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v1/det_x1v1), 8)\n",
    "    \n",
    "    # 1 group is empty\n",
    "    elif len_group_1 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v2/det_x2v2) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v2*det_v3/det_v2v3)), 8)\n",
    "    elif len_group_2 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v1*det_v3/det_v1v3)), 8)\n",
    "    elif len_group_3 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v2/det_x2v2) - \\\n",
    "                           np.log(det_v1*det_v2/det_v1v2)), 8)\n",
    "        \n",
    "    # None of the groups are empty\n",
    "    else:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v2/det_x2v2) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v1*det_v2/det_v1v2) - \\\n",
    "                           np.log(det_v1*det_v3/det_v1v3) - \\\n",
    "                           np.log(det_v2*det_v3/det_v2v3)), 8)  \n",
    "    \n",
    "    return I_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "554e7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom colormap with unique colors for each value\n",
    "def create_custom_colormap(matrix_list):\n",
    "    # Create a list of all unique values in all matrices\n",
    "    unique_values = np.unique(np.concatenate([matrix.ravel() for matrix in matrix_list if matrix is not None]))\n",
    "    # Create a colormap dictionary with unique colors for each value\n",
    "    colormap = {value: plt.cm.get_cmap(\"viridis\")(i / len(unique_values)) for i, value in enumerate(unique_values)}\n",
    "\n",
    "    return colormap\n",
    "\n",
    "# Create an image from a matrix using a colormap\n",
    "def create_image(matrix, colormap):\n",
    "    # Return a blank image if the matrix is empty\n",
    "    if matrix is None:\n",
    "        return np.zeros((1, 1, 4), dtype=np.uint8)\n",
    "    # Handle 1D matrix\n",
    "    if len(matrix.shape) == 1:\n",
    "        matrix = matrix.reshape(1, -1)\n",
    "\n",
    "    return np.array([[colormap.get(value, [0, 0, 0, 1]) for value in row] for row in matrix])\n",
    "\n",
    "# Display images for covariance matrices V in rows of 9 matrices\n",
    "def image_show(matrix_list, gamma_lambda_pairs):\n",
    "    colormap = create_custom_colormap(matrix_list)\n",
    "\n",
    "    num_cases = len(matrix_list) // 9\n",
    "    # Initialize the index for gamma_lambda_pairs\n",
    "    gamma_index = 0\n",
    "\n",
    "    for case in range(num_cases):\n",
    "        plt.figure(figsize=(20, 6))\n",
    "        for i in range(9):\n",
    "            group = i % 3\n",
    "            matrix = matrix_list[case * 9 + i]\n",
    "            group_name = f\"Group {group + 1}\"\n",
    "            \n",
    "            # Use the current pair from gamma_lambda_pairs for the second image in each group\n",
    "            if i % 3 == 1:\n",
    "                gamma, lambda_value = gamma_lambda_pairs[gamma_index]\n",
    "                gamma_index = (gamma_index + 1) % len(gamma_lambda_pairs)\n",
    "            else:\n",
    "                gamma, lambda_value = (None, None)\n",
    "            \n",
    "            image = create_image(matrix, colormap)\n",
    "            plt.subplot(1, 9, i + 1)\n",
    "            \n",
    "            if gamma is not None:\n",
    "                plt.title(f\"({gamma}, {lambda_value})\\n{group_name}\")\n",
    "            else:\n",
    "                plt.title(group_name)\n",
    "            \n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        \n",
    "# Custom text for each row\n",
    "gamma_lambda_pairs = [(0.98, -0.02), (0.98, 0), (0.98, 0.02),\n",
    "                      (1, -0.02), (1, 0), (1, 0.02),\n",
    "                      (1.02, -0.02), (1.02, 0), (1.02, 0.02)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a52ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_I3(cov_XV):\n",
    "    max_MI = -1000\n",
    "    max_idx = 0\n",
    "    \n",
    "    I3_arr = []\n",
    "    det_x1v1_arr = []\n",
    "    det_x2v2_arr = []\n",
    "    det_x3v3_arr = []\n",
    "    matrix_list_V = []\n",
    "\n",
    "    # Generate an array of indices\n",
    "    for i, (group_1_idx_V, group_2_idx_V, group_3_idx_V,\n",
    "            group_1_idx_XV, group_2_idx_XV, group_3_idx_XV,\n",
    "            group_idx_v1v2, group_idx_v1v3, group_idx_v2v3) in enumerate(zip(group_1_list_V, group_2_list_V, group_3_list_V,\n",
    "                                                                             group_1_list_XV, group_2_list_XV, group_3_list_XV,\n",
    "                                                                             group_list_v1v2, group_list_v1v3, group_list_v2v3)):\n",
    "        \n",
    "        # Generate two-digit numbers with repetition from the array and in increasing order\n",
    "        group_1_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_1_idx_V, repeat=2)]\n",
    "        group_2_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_2_idx_V, repeat=2)]\n",
    "        group_3_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_3_idx_V, repeat=2)]\n",
    "        \n",
    "        group_1_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_1_idx_XV, repeat=2)]\n",
    "        group_2_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_2_idx_XV, repeat=2)]\n",
    "        group_3_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_3_idx_XV, repeat=2)]\n",
    "        \n",
    "        group_two_digit_numbers_v1v2 = [int(str(a) + str(b)) for a, b in product(group_idx_v1v2, repeat=2)]\n",
    "        group_two_digit_numbers_v1v3 = [int(str(a) + str(b)) for a, b in product(group_idx_v1v3, repeat=2)]\n",
    "        group_two_digit_numbers_v2v3 = [int(str(a) + str(b)) for a, b in product(group_idx_v2v3, repeat=2)]\n",
    "    \n",
    "        # Specify the positions to extract\n",
    "        tuple_list_1_V = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_V]\n",
    "        tuple_list_2_V = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_V]\n",
    "        tuple_list_3_V = [(number // 10 - 1, number % 10 - 1) for number in group_3_two_digit_numbers_V]\n",
    "        \n",
    "        tuple_list_1_XV = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_XV]\n",
    "        tuple_list_2_XV = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_XV]\n",
    "        tuple_list_3_XV = [(number // 10 - 1, number % 10 - 1) for number in group_3_two_digit_numbers_XV]\n",
    "        \n",
    "        tuple_list_v1v2 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v1v2]\n",
    "        tuple_list_v1v3 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v1v3]\n",
    "        tuple_list_v2v3 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v2v3]\n",
    "    \n",
    "        # Get the new matrix from specified positions\n",
    "        dim_v1 = len(group_1_idx_V)\n",
    "        dim_v2 = len(group_2_idx_V)\n",
    "        dim_v3 = len(group_3_idx_V)\n",
    "        \n",
    "        dim_x1v1 = len(group_1_idx_XV)\n",
    "        dim_x2v2 = len(group_2_idx_XV)\n",
    "        dim_x3v3 = len(group_3_idx_XV)\n",
    "        \n",
    "        dim_v1v2 = len(group_idx_v1v2)\n",
    "        dim_v1v3 = len(group_idx_v1v3)\n",
    "        dim_v2v3 = len(group_idx_v2v3)\n",
    "    \n",
    "        cov_v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_V]).reshape(dim_v1, dim_v1)\n",
    "        if len(cov_v1) == 1:\n",
    "            cov_v1 = cov_v1[0]\n",
    "        cov_v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_V]).reshape(dim_v2, dim_v2)\n",
    "        if len(cov_v2) == 1:\n",
    "            cov_v2 = cov_v2[0]\n",
    "        cov_v3 = np.array([cov_XV[i, j] for i, j in tuple_list_3_V]).reshape(dim_v3, dim_v3)\n",
    "        if len(cov_v3) == 1:\n",
    "            cov_v3 = cov_v3[0]\n",
    "    \n",
    "        cov_x1v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_XV]).reshape(dim_x1v1, dim_x1v1)\n",
    "        cov_x2v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_XV]).reshape(dim_x2v2, dim_x2v2)\n",
    "        cov_x3v3 = np.array([cov_XV[i, j] for i, j in tuple_list_3_XV]).reshape(dim_x3v3, dim_x3v3)\n",
    "        \n",
    "        cov_v1v2 = np.array([cov_XV[i, j] for i, j in tuple_list_v1v2]).reshape(dim_v1v2, dim_v1v2)\n",
    "        cov_v1v3 = np.array([cov_XV[i, j] for i, j in tuple_list_v1v3]).reshape(dim_v1v3, dim_v1v3)\n",
    "        cov_v2v3 = np.array([cov_XV[i, j] for i, j in tuple_list_v2v3]).reshape(dim_v2v3, dim_v2v3)\n",
    "        \n",
    "        assign_None(cov_v1, matrix_list_V)\n",
    "        assign_None(cov_v2, matrix_list_V)\n",
    "        assign_None(cov_v3, matrix_list_V)\n",
    "    \n",
    "        # Compute the determinant of each covariance matrix\n",
    "        det_x1v1 = det(cov_x1v1)\n",
    "        det_x2v2 = det(cov_x2v2)\n",
    "        det_x3v3 = det(cov_x3v3)\n",
    "        \n",
    "        det_v1v2 = det(cov_v1v2)\n",
    "        det_v1v3 = det(cov_v1v3)\n",
    "        det_v2v3 = det(cov_v2v3)\n",
    "        \n",
    "        if len(cov_v1) == 1:\n",
    "            det_v1 = cov_v1[0]\n",
    "            det_x1v1_arr.append(det_x1v1) \n",
    "        else:    \n",
    "            det_v1 = det(cov_v1)\n",
    "            \n",
    "        if len(cov_v2) == 1:\n",
    "            det_v2 = cov_v2[0]\n",
    "            det_x2v2_arr.append(det_x2v2) \n",
    "        else:    \n",
    "            det_v2 = det(cov_v2)\n",
    "            \n",
    "        if len(cov_v3) == 1:\n",
    "            det_v3 = cov_v3[0]\n",
    "            det_x3v3_arr.append(det_x3v3) \n",
    "        else:    \n",
    "            det_v3 = det(cov_v3)\n",
    "        \n",
    "        # Compute I_3\n",
    "        I_3 = compute_I3(det_v1, det_v2, det_v3, \n",
    "                         det_x1v1, det_x2v2, det_x3v3, \n",
    "                         det_v1v2, det_v1v3, det_v2v3,\n",
    "                         len(group_1_idx_V), len(group_2_idx_V), len(group_3_idx_V))\n",
    "        I3_arr.append(I_3)\n",
    "    \n",
    "        if I_3 > max_MI:\n",
    "            max_MI = I_3\n",
    "            max_idx = i+1\n",
    "    \n",
    "    print(colored(f'\\nThe maximum value of I_3 is {max_MI} at Partition {max_idx}.', 'red', attrs=['bold']))\n",
    "    \n",
    "    idx_start = (max_idx - 1) * 3\n",
    "    \n",
    "    return matrix_list_V[idx_start:idx_start + 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0559a89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 1:\u001b[0m\n",
      "Given (sigma_v1, sigma_v2, sigma_v3) = (0.01, 0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[ 0.0001  0.      0.    ]\n",
      " [ 0.      0.0004 -0.    ]\n",
      " [ 0.     -0.      0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0. -0.  0.]\n",
      " [ 0. -0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.0001  0.0001  0.0001  0.    ]\n",
      " [ 0.0001 -0.     -0.      0.0001]\n",
      " [ 0.0001  0.0001  0.      0.0001]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 1. -0. -0.]\n",
      " [-0.  1. -0.]\n",
      " [-0. -0.  1.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.6982\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0. -0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.0001  0.0001  0.      0.    ]\n",
      " [-0.      0.      0.      0.    ]\n",
      " [ 0.0001  0.0002  0.      0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 1.  0. -0.]\n",
      " [ 0.  1. -0.]\n",
      " [-0. -0.  1.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.698\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0. -0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.0002  0.      0.      0.0001]\n",
      " [ 0.      0.     -0.      0.    ]\n",
      " [ 0.      0.      0.0001  0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 1. -0. -0.]\n",
      " [-0.  1.  0.]\n",
      " [-0.  0.  1.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.6979\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 1.94e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0003  0.0001 -0.0001]\n",
      " [ 0.0001  0.0001 -0.    ]\n",
      " [-0.0003  0.0008  0.0003]\n",
      " [ 0.0003 -0.0002  0.0011]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.1704  0.057  -0.1172  0.217 ]\n",
      " [ 0.0842  0.0287  0.3248 -0.143 ]\n",
      " [-0.0351 -0.0116  0.1007  0.714 ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 9.998e-01  1.000e-04 -2.000e-04]\n",
      " [ 1.000e-04  9.997e-01  1.000e-04]\n",
      " [-2.000e-04  1.000e-04  9.992e-01]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.8349\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.00065978\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.00065988\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.      0.     -0.    ]\n",
      " [ 0.      0.002   0.     -0.    ]\n",
      " [ 0.      0.      0.0025  0.    ]\n",
      " [-0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "1.94e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "6.092e-05\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 4.957e-05 at Partition 24.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 3.079e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[-0.0002  0.0007 -0.0001]\n",
      " [ 0.0022  0.0007  0.0002]\n",
      " [-0.      0.      0.    ]\n",
      " [-0.     -0.0001  0.0005]]\n",
      "\n",
      "Matrix B:\n",
      "[[-0.1168  1.1227 -0.0062 -0.0122]\n",
      " [ 0.4019  0.3338  0.0182 -0.0334]\n",
      " [-0.0375  0.0806  0.011   0.3089]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 9.975e-01 -7.000e-04 -2.000e-04]\n",
      " [-7.000e-04  9.995e-01 -0.000e+00]\n",
      " [-2.000e-04 -0.000e+00  9.998e-01]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.8347\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.00160834\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.00160834\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.      0.     -0.    ]\n",
      " [ 0.      0.002   0.      0.    ]\n",
      " [ 0.      0.      0.0025  0.    ]\n",
      " [-0.      0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "3.079e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0002848\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.00026038 at Partition 19.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 9.82e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0015  0.0038  0.0011]\n",
      " [-0.      0.      0.    ]\n",
      " [ 0.0005 -0.0007  0.0017]\n",
      " [-0.0003  0.0001  0.0001]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.8921 -0.0119  0.2043 -0.2021]\n",
      " [ 2.2163  0.0026 -0.2748  0.0564]\n",
      " [ 0.6246  0.0079  0.6832  0.0885]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.9985 -0.0032 -0.0013]\n",
      " [-0.0032  0.9915 -0.0019]\n",
      " [-0.0013 -0.0019  0.9982]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.8346\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.00598257\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.00598173\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "9.82e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.00056793\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0004558 at Partition 14.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00985198 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.     -0.      0.    ]\n",
      " [-0.0061 -0.0248  0.0364]\n",
      " [ 0.0116  0.0391  0.0285]\n",
      " [ 0.0383 -0.0107 -0.0008]]\n",
      "\n",
      "Matrix B:\n",
      "[[  0.      -3.0972   4.6663  24.191 ]\n",
      " [  0.     -12.5183  15.7906  -6.7626]\n",
      " [ -0.      18.4031  11.5266  -0.5289]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.  0. -0.]\n",
      " [ 0.  0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-11.8401\n",
      "\n",
      "Mutual information of the encoder:\n",
      "142.95122444\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.90666912\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017 -0.      0.      0.    ]\n",
      " [-0.      0.002  -0.     -0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.33471533\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.19984987 at Partition 4.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00985246 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.     -0.     -0.    ]\n",
      " [ 0.009   0.043  -0.007 ]\n",
      " [-0.0213  0.0115  0.0434]\n",
      " [ 0.035  -0.0043  0.0184]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.      4.5292 -8.6199 22.1242]\n",
      " [-0.     21.7238  4.6576 -2.7236]\n",
      " [ 0.     -3.5409 17.5495 11.5897]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.  0. -0.]\n",
      " [ 0.  0. -0.]\n",
      " [-0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "3.94593387522215e+25\n",
      "\n",
      "Mutual information of the encoder:\n",
      "142.35363694\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.30908103\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017 -0.     -0.      0.    ]\n",
      " [-0.      0.002   0.      0.    ]\n",
      " [-0.      0.      0.0025 -0.    ]\n",
      " [ 0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985246\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.33471533\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.26690286 at Partition 3.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00985294 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[-0.017   0.0174  0.033 ]\n",
      " [ 0.0313 -0.0184  0.0258]\n",
      " [ 0.0288  0.0401 -0.0063]\n",
      " [-0.      0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[-10.1031  15.7953  11.618    0.    ]\n",
      " [ 10.3289  -9.2812  16.2025   0.    ]\n",
      " [ 19.6298  13.0132  -2.5459  -0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.  0. -0.]\n",
      " [ 0.  0.  0.]\n",
      " [-0.  0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-7.8918677504443e+25\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.45417233\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.40961582\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017 -0.      0.     -0.    ]\n",
      " [-0.      0.002  -0.     -0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [-0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985294\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.36502764\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.20698428 at Partition 15.\u001b[0m\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 2:\u001b[0m\n",
      "Given (sigma_v1, sigma_v3) = (0.01, 0.03), alpha = 2, and sigma_z2 = 0.02:\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[0.0001 0.0002 0.    ]\n",
      " [0.0002 0.0008 0.    ]\n",
      " [0.     0.     0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.     0.    ]\n",
      " [0.0002 0.0024 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.01522543 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0006  0.0052  0.0104]\n",
      " [ 0.0007  0.0062  0.0124]\n",
      " [ 0.     -0.      0.    ]\n",
      " [-0.     -0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 0.3347  0.2815  0.     -0.    ]\n",
      " [ 2.7901  2.3466 -0.     -0.    ]\n",
      " [ 5.5835  4.6959  0.      0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.9996 -0.0035 -0.007 ]\n",
      " [-0.0035  0.9709 -0.0582]\n",
      " [-0.007  -0.0582  0.8836]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.6119\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0788507\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.08034292\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.      0.    ]\n",
      " [ 0.0002  0.0024 -0.     -0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01522543\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.01997423\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.01587234 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.01516584 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0024  0.0042  0.0106]\n",
      " [ 0.0028  0.005   0.0126]\n",
      " [-0.      0.     -0.    ]\n",
      " [-0.      0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 1.2613  1.0615 -0.     -0.    ]\n",
      " [ 2.2586  1.9009  0.      0.    ]\n",
      " [ 5.6911  4.7898 -0.     -0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.9941 -0.0106 -0.0268]\n",
      " [-0.0106  0.9809 -0.048 ]\n",
      " [-0.0268 -0.048   0.879 ]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.6117\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.07892925\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.08041713\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.      0.    ]\n",
      " [ 0.0002  0.0024 -0.      0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [ 0.      0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01516584\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.01999967\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.01651774 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.01510628 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0084  0.0043  0.0069]\n",
      " [ 0.01    0.0051  0.0082]\n",
      " [-0.      0.      0.    ]\n",
      " [ 0.      0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 4.4844  3.7768 -0.      0.    ]\n",
      " [ 2.2988  1.9361  0.      0.    ]\n",
      " [ 3.7006  3.1167  0.     -0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.9248 -0.0385 -0.0621]\n",
      " [-0.0385  0.9802 -0.0318]\n",
      " [-0.0621 -0.0318  0.9488]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.6116\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.07900782\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.08049134\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002 -0.      0.    ]\n",
      " [ 0.0002  0.0024  0.      0.    ]\n",
      " [-0.      0.      0.0025 -0.    ]\n",
      " [ 0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510628\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02002516\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.01020203 at Partition 21.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 5.164e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[-0.0085  0.0038  0.0114]\n",
      " [-0.0078  0.0036  0.0105]\n",
      " [ 0.0009 -0.0012  0.001 ]\n",
      " [ 0.0003  0.0003  0.0001]]\n",
      "\n",
      "Matrix B:\n",
      "[[-4.646  -2.8496  0.3413  0.1684]\n",
      " [ 2.1072  1.3076 -0.4838  0.1751]\n",
      " [ 6.2719  3.8646  0.4154  0.0656]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0015 0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.9382  0.0284  0.0828]\n",
      " [ 0.0284  0.9866 -0.0374]\n",
      " [ 0.0828 -0.0374  0.8871]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.7486\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.10400002\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.10400684\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.     -0.    ]\n",
      " [ 0.0002  0.0024 -0.      0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [-0.      0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "5.164e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02191981\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.01306017 at Partition 4.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 2.04e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0119 -0.0021  0.0048]\n",
      " [ 0.0141 -0.0025  0.0056]\n",
      " [ 0.      0.0001  0.    ]\n",
      " [ 0.0007  0.0003 -0.0016]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 6.3907e+00  5.3293e+00  5.4000e-03  4.3220e-01]\n",
      " [-1.1197e+00 -9.5900e-01  5.5200e-02  1.6120e-01]\n",
      " [ 2.5595e+00  2.1304e+00  1.1100e-02 -1.0086e+00]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0015 0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.8485  0.0267 -0.0598]\n",
      " [ 0.0267  0.9952  0.011 ]\n",
      " [-0.0598  0.011   0.9742]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.7485\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1003331\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1003331\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.     -0.    ]\n",
      " [ 0.0002  0.0024 -0.      0.    ]\n",
      " [ 0.     -0.      0.0025  0.    ]\n",
      " [-0.      0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "2.04e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02469436\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.02063558 at Partition 24.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 5.272e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0113 -0.0003  0.0041]\n",
      " [ 0.0156 -0.0005  0.0056]\n",
      " [-0.     -0.0007 -0.    ]\n",
      " [-0.0004  0.      0.0012]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 5.9685e+00  5.9954e+00 -7.5000e-03 -2.6730e-01]\n",
      " [-1.6390e-01 -1.7750e-01 -2.7060e-01  2.0000e-03]\n",
      " [ 2.1626e+00  2.1708e+00 -8.0000e-04  7.3830e-01]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0021 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.8387  0.0046 -0.058 ]\n",
      " [ 0.0046  0.9997  0.0017]\n",
      " [-0.058   0.0017  0.978 ]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.7483\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.10128254\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.10127525\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002 -0.      0.    ]\n",
      " [ 0.0002  0.0024  0.     -0.    ]\n",
      " [-0.      0.      0.0025  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "5.272e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02714817\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.02390977 at Partition 24.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00985198 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[-0.0063  0.0001  0.0405]\n",
      " [-0.009   0.0478  0.0034]\n",
      " [ 0.0484  0.0085  0.0076]\n",
      " [-0.     -0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[-3.3603 -3.4888 19.5638 -0.    ]\n",
      " [-2.3444 20.3093  3.4487  0.    ]\n",
      " [24.1492 -0.5842  3.0571  0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0. -0.  0.]\n",
      " [-0.  0. -0.]\n",
      " [ 0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-11.7632\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.5046762\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.46012154\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.      0.    ]\n",
      " [ 0.0002  0.0024  0.      0.    ]\n",
      " [ 0.      0.      0.0025 -0.    ]\n",
      " [ 0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.45126227\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.39775683 at Partition 20.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00985246 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0012  0.0033  0.0021]\n",
      " [ 0.0139  0.0394  0.0251]\n",
      " [-0.0156  0.0291 -0.0372]\n",
      " [-0.036   0.0021  0.0168]]\n",
      "\n",
      "Matrix B:\n",
      "[[  0.       5.8622  -6.3135 -22.7462]\n",
      " [  0.      16.5913  11.7739   1.3077]\n",
      " [  0.      10.5439 -15.0165  10.5886]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0. -0. -0.]\n",
      " [-0.  0.  0.]\n",
      " [-0.  0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "7.8918677504443e+25\n",
      "\n",
      "Mutual information of the encoder:\n",
      "140.94729417\n",
      "\n",
      "Mutual information of the decoder:\n",
      "140.90273929\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002 -0.     -0.    ]\n",
      " [ 0.0002  0.0024 -0.     -0.    ]\n",
      " [-0.     -0.      0.0025 -0.    ]\n",
      " [-0.     -0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985246\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.42587611\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.23778717 at Partition 5.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00985294 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0161  0.0376 -0.0025]\n",
      " [ 0.0455 -0.0135  0.0111]\n",
      " [-0.0096  0.0073  0.0483]\n",
      " [ 0.     -0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 7.3945 18.5382 -3.8659  0.    ]\n",
      " [23.2625 -7.62    2.9365 -0.    ]\n",
      " [-2.0367  4.8217 19.5042  0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. -0.]\n",
      " [ 0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "1.57837355008886e+26\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.48120277\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.43664675\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.     -0.    ]\n",
      " [ 0.0002  0.0024  0.      0.    ]\n",
      " [ 0.      0.      0.0025  0.    ]\n",
      " [-0.      0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985294\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.45126227\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.41371651 at Partition 21.\u001b[0m\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 3:\u001b[0m\n",
      "Given sigma_v1 = 0.01, (alpha, beta) = (2, 4), and (sigma_z2, sigma_z3) = (0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[0.0001 0.0002 0.0004]\n",
      " [0.0002 0.0008 0.0008]\n",
      " [0.0004 0.0008 0.0025]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.0004 0.    ]\n",
      " [0.0002 0.0024 0.0008 0.    ]\n",
      " [0.0004 0.0008 0.0041 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.01517876 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0069 -0.0008  0.0076]\n",
      " [ 0.0143 -0.0017  0.0157]\n",
      " [ 0.0238 -0.0029  0.026 ]\n",
      " [-0.     -0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 2.4747  4.1866  4.7433 -0.    ]\n",
      " [-0.2976 -0.5034 -0.5704 -0.    ]\n",
      " [ 2.7079  4.5811  5.1903  0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0019 0.     0.    ]\n",
      " [0.     0.     0.0028 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.81    0.0229 -0.2079]\n",
      " [ 0.0229  0.9973  0.025 ]\n",
      " [-0.2079  0.025   0.7725]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.4069\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.27263377\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.27692565\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004 -0.    ]\n",
      " [ 0.0002  0.0024  0.0008  0.    ]\n",
      " [ 0.0004  0.0008  0.0041 -0.    ]\n",
      " [-0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01517876\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.14852331\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0748998 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.01510793 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0096  0.0037 -0.0003]\n",
      " [ 0.0199  0.0077 -0.0007]\n",
      " [ 0.033   0.0127 -0.0012]\n",
      " [-0.      0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 3.4308  5.8029  6.5836 -0.    ]\n",
      " [ 1.3229  2.2376  2.5386  0.    ]\n",
      " [-0.1197 -0.2025 -0.2298 -0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0019 0.     0.    ]\n",
      " [0.     0.     0.0028 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.6343 -0.141   0.0128]\n",
      " [-0.141   0.9456  0.0049]\n",
      " [ 0.0128  0.0049  0.9996]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.4067\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.27280613\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.27707877\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004 -0.    ]\n",
      " [ 0.0002  0.0024  0.0008  0.    ]\n",
      " [ 0.0004  0.0008  0.0041 -0.    ]\n",
      " [-0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510793\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.14863563\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.12656529 at Partition 27.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.01503704 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0086  0.0013  0.0056]\n",
      " [ 0.0177  0.0026  0.0115]\n",
      " [ 0.0295  0.0044  0.0192]\n",
      " [ 0.     -0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 3.0597  5.174   5.8782  0.    ]\n",
      " [ 0.4556  0.7704  0.8753 -0.    ]\n",
      " [ 1.9888  3.3631  3.8209 -0.    ]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0019 0.     0.    ]\n",
      " [0.     0.     0.0028 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.7088 -0.0434 -0.1893]\n",
      " [-0.0434  0.9935 -0.0282]\n",
      " [-0.1893 -0.0282  0.877 ]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.4066\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.272979\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2772324\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004 -0.    ]\n",
      " [ 0.0002  0.0024  0.0008  0.    ]\n",
      " [ 0.0004  0.0008  0.0041 -0.    ]\n",
      " [-0.      0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.01503704\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.14874826\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0980801 at Partition 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 0.00012316 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0061  0.0015  0.0079]\n",
      " [ 0.0139  0.0012  0.0144]\n",
      " [ 0.0265  0.0038  0.0296]\n",
      " [-0.     -0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 1.8451  3.8149  5.529  -0.0159]\n",
      " [ 0.6811  0.1876  0.8135 -0.0243]\n",
      " [ 2.7219  3.7022  6.2242  0.0173]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.7892 -0.0283 -0.233 ]\n",
      " [-0.0283  0.9957 -0.0321]\n",
      " [-0.233  -0.0321  0.7412]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.5436\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.32066174\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.32068386\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004  0.    ]\n",
      " [ 0.0002  0.0024  0.0008 -0.    ]\n",
      " [ 0.0004  0.0008  0.0041  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00012316\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.17732546\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.08897152 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 1e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0095  0.0033  0.0028]\n",
      " [ 0.0168  0.0118  0.0004]\n",
      " [ 0.0341  0.0191  0.0044]\n",
      " [ 0.     -0.     -0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 3.4078e+00  4.3423e+00  7.1306e+00  1.2000e-03]\n",
      " [ 6.0860e-01  3.5624e+00  3.9111e+00 -1.9000e-03]\n",
      " [ 1.4568e+00 -3.0420e-01  9.9920e-01 -1.2000e-03]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0026 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.6516 -0.1989 -0.0428]\n",
      " [-0.1989  0.8811 -0.0203]\n",
      " [-0.0428 -0.0203  0.9916]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.5434\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.31944785\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.31944785\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004  0.    ]\n",
      " [ 0.0002  0.0024  0.0008 -0.    ]\n",
      " [ 0.0004  0.0008  0.0041  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "1e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.17466168\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1231163 at Partition 27.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 2.693e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0098  0.0044  0.0026]\n",
      " [ 0.0164  0.0049  0.0068]\n",
      " [ 0.0362 -0.0135  0.0401]\n",
      " [-0.      0.      0.    ]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 3.4824  3.9644  7.7152 -0.0129]\n",
      " [ 3.2129  3.192  -4.2199  0.0182]\n",
      " [-0.7496 -0.4013  9.9212  0.0178]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0021 0.     0.    ]\n",
      " [0.     0.     0.001  0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.6217  0.069  -0.3452]\n",
      " [ 0.069   0.9133  0.1388]\n",
      " [-0.3452  0.1388  0.6073]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-6.5433\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.76975427\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.7697263\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004  0.    ]\n",
      " [ 0.0002  0.0024  0.0008 -0.    ]\n",
      " [ 0.0004  0.0008  0.0041  0.    ]\n",
      " [ 0.     -0.      0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "2.693e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.336864\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.13626768 at Partition 27.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00948202 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0388  0.0044  0.0125]\n",
      " [ 0.0018  0.011   0.0062]\n",
      " [-0.0054  0.0568  0.0283]\n",
      " [-0.009  -0.018   0.0343]]\n",
      "\n",
      "Matrix B:\n",
      "[[ 23.927    0.      -3.6661  -5.6881]\n",
      " [ -0.6754   0.      14.0623 -11.3465]\n",
      " [  5.9236   0.       6.3971  21.6823]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.     0.     0.     0.    ]\n",
      " [0.     0.0022 0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0. -0.]\n",
      " [ 0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-3.15674710017772e+26\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.40983277\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.36528612\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004  0.    ]\n",
      " [ 0.0002  0.0024  0.0008 -0.    ]\n",
      " [ 0.0004  0.0008  0.0041 -0.    ]\n",
      " [ 0.     -0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00948202\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.48919243\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.33356469 at Partition 8.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00977835 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.      0.0016  0.0065]\n",
      " [-0.0383  0.0012  0.0301]\n",
      " [ 0.0241  0.0176  0.0563]\n",
      " [-0.0061  0.0382 -0.0093]]\n",
      "\n",
      "Matrix B:\n",
      "[[ -0.     -19.3655   9.7204  -3.848 ]\n",
      " [  0.      -0.9852   4.5301  24.1172]\n",
      " [  0.       8.6078  12.1842  -5.8968]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0. -0.  0.]\n",
      " [-0.  0. -0.]\n",
      " [ 0. -0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-11.5627\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.93616676\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.89161715\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[0.0017 0.0002 0.0004 0.    ]\n",
      " [0.0002 0.0024 0.0008 0.    ]\n",
      " [0.0004 0.0008 0.0041 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00977835\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.63959811\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.45592428 at Partition 1.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00978211 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mOptimal solution:\u001b[0m\n",
      "Matrix A:\n",
      "[[ 0.0066  0.0015 -0.0001]\n",
      " [ 0.0262  0.0159 -0.0379]\n",
      " [ 0.0591  0.0067  0.0228]\n",
      " [-0.0082  0.0376  0.0101]]\n",
      "\n",
      "Matrix B:\n",
      "[[  0.       6.6098  13.2698  -5.1711]\n",
      " [  0.       6.5653   0.3785  23.7426]\n",
      " [ -0.     -19.0603   9.3398   6.3848]]\n",
      "\n",
      "Covariance matrix of Z:\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.    ]]\n",
      "\n",
      "Covariance matrix of W:\n",
      "[[ 0. -0. -0.]\n",
      " [-0.  0.  0.]\n",
      " [-0.  0.  0.]]\n",
      "\n",
      "Minimum value of the cost function:\n",
      "-11.5442\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.01409874\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.96954862\n",
      "\n",
      "Value of Sigma_Y_hat:\n",
      "[[ 0.0017  0.0002  0.0004 -0.    ]\n",
      " [ 0.0002  0.0024  0.0008 -0.    ]\n",
      " [ 0.0004  0.0008  0.0041 -0.    ]\n",
      " [-0.     -0.     -0.      0.0016]]\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978211\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.63959811\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.47791783 at Partition 27.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for case in range(num_cases):\n",
    "    matrix_list_V_all_cases = []\n",
    "    \n",
    "    # Compute Sigma_Y given Sigma_V\n",
    "    Sigma_V = generate_Sigma_V(case)\n",
    "    \n",
    "    Sigma_Y = eigenvectors @ Sigma_V @ eigenvectors.T + Sigma_Z_tilde\n",
    "    print(colored('\\nCovariance matrix of input data Y:', 'blue', attrs=['bold']))\n",
    "    print(np.round(Sigma_Y, 4))\n",
    "    is_positive_definite(Sigma_Y)\n",
    "    \n",
    "    # Constants\n",
    "    MAX_SOLS = 1\n",
    "    is_array = 1\n",
    "    flag = 0\n",
    "    case_num = 1\n",
    "\n",
    "    # Initiate arrays\n",
    "    min_recon_err_arr = []\n",
    "    min_en_mi_arr = []\n",
    "    min_de_mi_arr = []\n",
    "    all_recon_mi_arr = []\n",
    "    satisfied_recon_mi_arr = []\n",
    "    satisfied_gamma_lambda_arr = []\n",
    "    \n",
    "    # Iteration step\n",
    "    for i in range(0, len(gamma_arr)):\n",
    "        gamma = gamma_arr[i]\n",
    "        for j in range(0, len(lambda_arr)):\n",
    "            lamda = lambda_arr[j]\n",
    "        \n",
    "            min_recon_err, min_en_mi, min_de_mi, min_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "        \n",
    "            first_iter = 1\n",
    "            for num_sols in range(0, MAX_SOLS):\n",
    "                current_recon_err, current_en_mi, current_de_mi, current_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "    \n",
    "                # Check for unique optimal solutions for each (gamma, lambda) pair\n",
    "                if first_iter == 1:\n",
    "                    if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - min_opt_sol[:2*n*m+n*n+m*m], 1e-6):\n",
    "                        is_unique = 1\n",
    "                        unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                    else:\n",
    "                        is_unique = 0\n",
    "                    first_iter = 0\n",
    "                else:\n",
    "                    if is_unique == 1:\n",
    "                        if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - unique_opt_sol, 1e-6):\n",
    "                            unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                        else:\n",
    "                            is_unique = 0\n",
    "    \n",
    "                # Return the solution with smallest reconstruction error\n",
    "                if current_recon_err < min_recon_err:\n",
    "                    min_recon_err = current_recon_err\n",
    "                    min_en_mi = current_en_mi\n",
    "                    min_de_mi = current_de_mi\n",
    "                    min_opt_sol = current_opt_sol\n",
    "                \n",
    "            min_recon_err_arr = np.concatenate((min_recon_err_arr, [min_recon_err]))\n",
    "            min_en_mi_arr = np.concatenate((min_en_mi_arr, [min_en_mi]))\n",
    "            min_de_mi_arr = np.concatenate((min_de_mi_arr, [min_de_mi]))\n",
    "            all_recon_mi_arr = np.concatenate((all_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            print(colored('\\nCase {}:'.format(case_num), 'blue', attrs=['bold']))\n",
    "            case_num += 1\n",
    "        \n",
    "            if min_recon_err > MAX_RECON_ERR:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that EXCEEDS the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            else:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that SATISFIES the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            \n",
    "                satisfied_gamma_lambda_arr = np.concatenate((satisfied_gamma_lambda_arr, [gamma, lamda]))\n",
    "                satisfied_recon_mi_arr = np.concatenate((satisfied_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            if is_unique == 1:\n",
    "                print(colored('The optimal solution is unique!\\n', 'blue', attrs=['bold']))\n",
    "            else:\n",
    "                print(colored('The optimal solution is NOT unique!\\n', 'red', attrs=['bold']))\n",
    "        \n",
    "            print_optimal_solution(min_opt_sol, m)\n",
    "        \n",
    "            # Compute mutual information I(V;X) and I_3\n",
    "            B_opt = min_opt_sol[n*m:2*n*m].reshape((m, n))\n",
    "            Sigma_W_opt = min_opt_sol[2*n*m+n*n:2*n*m+n*n+m*m].reshape((m, m))\n",
    "        \n",
    "            mutual_info_VX = mi_VX(B_opt, Sigma_W_opt)\n",
    "            print('\\nMutual information between generative variable and latent variable:')\n",
    "            print(round(mutual_info_VX, 8))\n",
    "        \n",
    "            cov_XV = covariance_matrix_XV(B_opt)\n",
    "            matrix_list_V_per_case = max_I3(cov_XV)\n",
    "            \n",
    "            matrix_list_V_all_cases.append(matrix_list_V_per_case)\n",
    "            \n",
    "    # Display the images\n",
    "    flattened_list = [item for sublist in matrix_list_V_all_cases for item in sublist]\n",
    "    image_show(flattened_list, gamma_lambda_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe6262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
