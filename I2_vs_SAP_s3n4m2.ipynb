{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a004ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from adjustText import adjust_text\n",
    "from numpy import pi, e\n",
    "from numpy.linalg import inv, det\n",
    "from numpy.linalg import norm as LA_norm\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from termcolor import colored\n",
    "import itertools\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48c1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(m, n):\n",
    "    return np.random.rand(m, n)\n",
    "\n",
    "def initial_inputs(flag):\n",
    "    if flag == 0:\n",
    "        # Create initial encoder inputs (B, Sigma_W)\n",
    "        B = create_matrix(m, n)\n",
    "        Sigma_W = make_spd_matrix(m)\n",
    "        return np.concatenate(([flag], B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        # Create initial decoder inputs (A, Sigma_Z)\n",
    "        A = create_matrix(n, m)\n",
    "        Sigma_Z = np.diag(random(n))\n",
    "        return np.concatenate(([flag], A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "\n",
    "def is_close_to_zero(arr, etol):\n",
    "    return np.allclose(arr, 0, atol=etol)\n",
    "\n",
    "def is_singular(matrix):\n",
    "    is_singular = np.linalg.matrix_rank(matrix) < min(matrix.shape)\n",
    "    if is_singular:\n",
    "        print(colored('The matrix is singular.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not singular.', 'red', attrs=['bold']))\n",
    "\n",
    "def is_positive_definite(matrix):\n",
    "    if np.all(np.linalg.eigvals(matrix) > 0):\n",
    "        print(colored('The matrix is positive definite.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not positive definite.', 'red', attrs=['bold']))\n",
    "\n",
    "def matrix_B(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    B = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A) @ A.T @ inv_Sigma_Z_hat\n",
    "    return B\n",
    "\n",
    "def covariance_matrix_W(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    Sigma_W = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A)\n",
    "    return Sigma_W\n",
    "\n",
    "def matrix_A(B, Sigma_W):\n",
    "    A = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B) @ B.T @ inv(Sigma_W)\n",
    "    return A\n",
    "\n",
    "def covariance_matrix_Z(B, Sigma_W):\n",
    "    Sigma_Z = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B)\n",
    "    diagonalized_Sigma_Z = np.diag(Sigma_Z.diagonal())\n",
    "    return diagonalized_Sigma_Z\n",
    "\n",
    "def covariance_matrix_XV(B):\n",
    "    cov_XV = np.block([[np.identity(m), B @ eigenvectors @ Sigma_V],\n",
    "                       [(B @ eigenvectors @ Sigma_V).T, Sigma_V]])\n",
    "    return cov_XV\n",
    "\n",
    "def encoder_mi(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(Sigma_W))\n",
    "\n",
    "def decoder_mi(A, Sigma_Z):\n",
    "    return 0.5 * np.log(det(A @ A.T + Sigma_Z) / det(Sigma_Z))\n",
    "\n",
    "def mi_VX(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(sigma_squared * B @ B.T + Sigma_W))\n",
    "\n",
    "def reconstruction_error(recon, orig):\n",
    "    norm_diff = LA_norm(orig - recon, 2)\n",
    "    orig_norm = LA_norm(orig, 2)\n",
    "    recon_err = norm_diff / orig_norm\n",
    "    return recon_err\n",
    "\n",
    "def objective_function(A, B, Sigma_Z, Sigma_W):\n",
    "    Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "    \n",
    "    regularizer = 0.5 * (np.trace(Sigma_X) - np.log(det(Sigma_W)) - m)\n",
    "    reconstruction = 0.5 * (np.trace(Sigma_X) + \\\n",
    "                            np.trace(A.T @ inv(Sigma_Z) @ Sigma_Y @ B.T) + \\\n",
    "                            np.trace(inv(Sigma_Z) @ A @ B @ Sigma_Y) - \\\n",
    "                            np.trace(inv(Sigma_Z) @ Sigma_Y) - \\\n",
    "                            np.trace((np.identity(m) + A.T @ inv(Sigma_Z) @ A) @ Sigma_X) - \\\n",
    "                            n * np.log(2 * pi) - np.log(det(Sigma_Z)))\n",
    "    lambda_term = lamda * np.trace((np.identity(n) - A @ B) @ Sigma_Y @ ((np.identity(n) - A @ B).T) + A @ Sigma_W @ A.T)\n",
    "    \n",
    "    return regularizer - gamma * reconstruction + lambda_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c4fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_function(cf_arr):\n",
    "    \"\"\"\n",
    "    Plot values of objective function against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(cf_arr) + 1), cf_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Cost Function', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_encoder_mi(en_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of encoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(en_mi_arr) + 1), en_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Encoder', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decoder_mi(de_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of decoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(de_mi_arr) + 1), de_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Decoder', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ae4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_optimal_solution(sol, m):\n",
    "    A_arr = sol[:n*m] \n",
    "    B_arr = sol[n*m:2*n*m]\n",
    "    Sigma_Z_arr = sol[2*n*m:2*n*m+n*n]\n",
    "    Sigma_Z = Sigma_Z_arr.reshape((n, n))\n",
    "    Sigma_W_arr = sol[2*n*m+n*n:2*n*m+n*n+m*m]\n",
    "    Sigma_W = Sigma_W_arr.reshape((m, m))\n",
    "    cost_function = sol[2*n*m+n*n+m*m:2*n*m+n*n+m*m+1][0]\n",
    "    en_mi = sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0]\n",
    "    de_mi = sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0]\n",
    "    recon_err = sol[-1]\n",
    "    len_cf_mi_arr = sol[2*n*m+n*n+m*m+3:2*n*m+n*n+m*m+6]\n",
    "    Sigma_X = sol[2*n*m+n*n+m*m+6:2*n*m+n*n+2*m*m+6].reshape((m, m))\n",
    "    Sigma_Y_hat = sol[2*n*m+n*n+2*m*m+6:2*n*m+2*n*n+2*m*m+6].reshape((n, n))\n",
    "    \n",
    "    print(colored('At optimal solution:', attrs=['bold']))\n",
    "    \n",
    "    if m > 1:\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 4)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 4)))\n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "    else:\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 4)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 4)))      \n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "        \n",
    "    return len_cf_mi_arr\n",
    "\n",
    "def print_comprehensive_results(gamma, lamda, flag, m, n, is_arr):\n",
    "    if flag == 0:\n",
    "        # Generate random initial encoder inputs (B, Sigma_W)\n",
    "        B, Sigma_W = initial_inputs(flag)[1:1+m*n].reshape((m, n)), initial_inputs(flag)[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "    else:\n",
    "        # Generate random initial decoder inputs (A, Sigma_Z)\n",
    "        A, Sigma_Z = initial_inputs(flag)[1:1+n*m].reshape((n, m)), initial_inputs(flag)[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "    \n",
    "    # Print given inputs\n",
    "    if is_arr == 0:\n",
    "        if m > 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial matrix B:')\n",
    "            print(np.round(B.reshape((m, n)), 4))\n",
    "            print('\\nInitial covariance matrix of W:')\n",
    "            print(np.round(Sigma_W, 4))\n",
    "        elif m == 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial vector b:')\n",
    "            print(np.round(B.reshape((m, n)), 4)[0])\n",
    "            print('\\nInitial variance of W:')\n",
    "            print(np.round(Sigma_W, 4)[0][0])\n",
    "        elif m > 1 and flag == 1:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial matrix A:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))\n",
    "        else:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial vector a:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))    \n",
    "    \n",
    "        # Print results\n",
    "        if flag == 0:\n",
    "            # Compute optimal solution given encoder inputs\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "    \n",
    "            # Extract length of arrays for cost function and mutual information of encoder and decoder\n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            # Plot values of cost function and mutual information against iterations\n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)  \n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "        \n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)\n",
    "    else:\n",
    "        if flag == 0:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            \n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 4)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 4)\n",
    "            recon_err = round(opt_sol[-1], 4)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]\n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            \n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 4)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 4)\n",
    "            recon_err = round(opt_sol[-1], 4)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fbe240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "*****************************************************************\n",
    "**                          ALGORITHM                          **\n",
    "*****************************************************************\n",
    "   \n",
    "Inputs:\n",
    "- MAX_ITERS: Maximum number of iterations\n",
    "- n, m: Dimensions of the matrix\n",
    "- TOL_ERR: Tolerable error\n",
    "- Sigma_Y: A random nxn positive definite matrix\n",
    "\n",
    "Algorithm:\n",
    "1. Initialize flag\n",
    "    a. If we start with the encoder, set flag = 0.\n",
    "    b. Otherwise, set flag = 1.\n",
    "    \n",
    "2. Generate initial inputs for the iteration step\n",
    "    a. If flag = 0, then do:\n",
    "        i. create random initial encoder inputs, including \n",
    "            - a random mxn matrix B\n",
    "            - a random mxm positive definite covariance matrix Sigma_W\n",
    "        ii. set flag = 1.\n",
    "    b. If flag = 1, then do:\n",
    "        i. create random initial decoder inputs, including \n",
    "            - a random nxm matrix A\n",
    "            - a random nxn positive definite covariance matrix Sigma_Z\n",
    "        ii. set flag = 0.\n",
    "        \n",
    "3. Set iteration counter i = 0. \n",
    "\n",
    "4. Iterative step\n",
    "    a. If flag = 0, given the decoder inputs (A, Sigma_Z) at iteration i,\n",
    "        i. compute the corresponding encoder inputs at iteration i+1:\n",
    "            B = matrix_B(A, Sigma_Z)\n",
    "            Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "        ii. set flag = 1.\n",
    "        iii. compute the resulting gamma-VAE cost function and mutual information of the encoder.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "    b. If flag = 1, given the encoder inputs (B, Sigma_W) at iteration i,\n",
    "        i. compute the corresponding decoder inputs at iteration i:\n",
    "            A = matrix_A(B, Sigma_W)\n",
    "            Sigma_Z = covariance_matrix_Z(B, Sigma_W, is_diagonal)\n",
    "        ii. set flag = 0.\n",
    "        iii. compute the resulting gamma-VAE cost function, mutual information of the decoder, and reconstruction error.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "            \n",
    "5. Increment iteration counter i <- i + 1.\n",
    "\n",
    "6. If the iteration counter i < MAX_ITERS, then move back to step 4.\n",
    "    Otherwise, move to step 7.\n",
    "    \n",
    "7. Compute the values of Sigma_X and Sigma_Y_hat.\n",
    "        \n",
    "8. Display results\n",
    "    a. display the optimal solution (A, B, Sigma_Z, Sigma_W).\n",
    "    b. display the corresponding minimum value of gamma-VAE cost function.\n",
    "    c. display the resulting mutual information of both encoder and decoder.\n",
    "    d. display the values of Sigma_X and Sigma_Y_hat.\n",
    "    e. display the value of reconstruction error.\n",
    "    f. move to step 9.\n",
    "    \n",
    "9. Stop.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def rate_distortion(inputs, is_arr):\n",
    "    flag = inputs[0]\n",
    "    if flag == 0:\n",
    "        B = inputs[1:1+m*n].reshape((m, n))\n",
    "        Sigma_W = inputs[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "        flag = 1\n",
    "        # Array of current encoder inputs (B_t, Sigma_W_t)\n",
    "        current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        A = inputs[1:1+n*m].reshape((n, m))\n",
    "        Sigma_Z = inputs[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "        flag = 0\n",
    "        # Array of current decoder inputs (A_t, Sigma_Z_t)\n",
    "        current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "    \n",
    "    # Cost function and mutual information arrays\n",
    "    cf_arr = []\n",
    "    en_mi_arr = []\n",
    "    de_mi_arr = [] \n",
    "\n",
    "    # Iteration step\n",
    "    try:\n",
    "        for i in range(0, MAX_ITERS):\n",
    "            if  flag == 0:\n",
    "                B = matrix_B(A, Sigma_Z)\n",
    "                Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "                flag = 1\n",
    "                \n",
    "                # Check if the value of the cost function is not a number\n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_en_mi = encoder_mi(B, Sigma_W)\n",
    "                en_mi_arr = np.concatenate((en_mi_arr, [current_en_mi]))\n",
    "                \n",
    "                # For the first iteration, update the current encoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. B and itself in the previous iteration\n",
    "                #    ii. Sigma_W and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current encoder inputs and value of the cost function\n",
    "                else:\n",
    "                    B_diff = B - current_encoder_inputs[:m*n].reshape((m, n))\n",
    "                    B_norm_diff = LA_norm(B_diff, 'fro')\n",
    "                    Sigma_W_diff = Sigma_W - current_encoder_inputs[m*n:m*n+m*m].reshape((m, m))\n",
    "                    Sigma_W_norm_diff = LA_norm(Sigma_W_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    # Check for convergence\n",
    "                    if B_norm_diff <= TOL_ERR and Sigma_W_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break\n",
    "            else:\n",
    "                A = matrix_A(B, Sigma_W)\n",
    "                Sigma_Z = covariance_matrix_Z(B, Sigma_W)\n",
    "                flag = 0\n",
    "                \n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_de_mi = decoder_mi(A, Sigma_Z)\n",
    "                de_mi_arr = np.concatenate((de_mi_arr, [current_de_mi]))\n",
    "                \n",
    "                Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "                recon_err = reconstruction_error(Sigma_Y_hat, Sigma_Y)\n",
    "                \n",
    "                # For the first iteration, update the current decoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. A and itself in the previous iteration\n",
    "                #    ii. Sigma_Z and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current dencoder inputs and value of the cost function                \n",
    "                else:\n",
    "                    A_diff = A - current_decoder_inputs[:n*m].reshape((n, m))\n",
    "                    A_norm_diff = LA_norm(A_diff, 'fro')\n",
    "                    Sigma_Z_diff = Sigma_Z - current_decoder_inputs[n*m:n*m+n*n].reshape((n, n))\n",
    "                    Sigma_Z_norm_diff = LA_norm(Sigma_Z_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    # Check for convergence\n",
    "                    if A_norm_diff <= TOL_ERR and Sigma_Z_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break                       \n",
    "\n",
    "        # Compute Sigma_X and Sigma_Y_hat  \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi],\n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "          \n",
    "        if is_arr == 0 and i == MAX_ITERS - 1 and recon_err > MAX_RECON_ERR:\n",
    "            print(colored('\\nMax iterations was reached!', 'red', attrs=['bold']))\n",
    "            print('There is NO solutions that has reconstruction error statisfying the tolerance error = {}.\\n'.format(MAX_RECON_ERR))\n",
    "            \n",
    "        return sol\n",
    "    \n",
    "    except Exception as e:\n",
    "        if is_arr == 0:\n",
    "            print(colored('\\nThe algorithm fails to converge after {} iterations due to {}.\\n'.format(i+1, e), 'red', attrs=['bold']))\n",
    "         \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi], \n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "        return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ee78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Sigma_V(case):\n",
    "    for case_idx in range(num_cases):\n",
    "        if case_idx == 0:\n",
    "            # Case 1: Independent of generative parameters\n",
    "            std_devs = [std_dev_v1, std_dev_v2, std_dev_v3]\n",
    "            V_1 = [np.random.normal(mean, std_dev, size=num_samples) for std_dev in std_devs]\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_1 = np.round(np.cov(V_1), 4)\n",
    "        \n",
    "        elif case_idx == 1:\n",
    "            # Case 2: Linear dependence of v_1 and v_2, with independence of v_3\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            v_3 = np.random.normal(mean, std_dev_v3, size=num_samples)\n",
    "            \n",
    "            # Calculate v_2 using scaling factor alpha and random noise\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            \n",
    "            # Create generative variable V\n",
    "            V_2 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_2 = np.round(np.cov(V_2), 4)  \n",
    "        \n",
    "        else:\n",
    "            # Case 3: Linear dependence of v_2 and v_3, with v_1\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            \n",
    "            # Calculate additional generative parameters using scaling factors\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            random_noise_z3 = np.random.normal(mean, std_dev_z3, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            v_3 = beta * v_1 + random_noise_z3\n",
    "\n",
    "            # Create generative variable V\n",
    "            V_3 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_3 = np.round(np.cov(V_3), 4)\n",
    "    \n",
    "    if case == 0:\n",
    "        print(colored('Scenario 1:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v2, sigma_v3) = {std_dev_v1, std_dev_v2, std_dev_v3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_1)\n",
    "        is_singular(Sigma_V_1)\n",
    "        return Sigma_V_1\n",
    "    \n",
    "    elif case == 1:\n",
    "        print(colored('\\nScenario 2:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v3) = {std_dev_v1, std_dev_v3}, alpha = {alpha}, and sigma_z2 = {std_dev_z2}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_2)\n",
    "        is_singular(Sigma_V_2) \n",
    "        return Sigma_V_2\n",
    "    \n",
    "    else:\n",
    "        print(colored('\\nScenario 3:', attrs=['bold','underline']))\n",
    "        print(f'Given sigma_v1 = {std_dev_v1}, (alpha, beta) = {alpha, beta}, and (sigma_z2, sigma_z3) = {std_dev_z2, std_dev_z3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_3)\n",
    "        is_singular(Sigma_V_3)  \n",
    "        return Sigma_V_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff45dfc",
   "metadata": {},
   "source": [
    "## I. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc2f26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mAn array of gamma:\u001b[0m\n",
      "[0.98 0.99 1.   1.01 1.02]\n",
      "\u001b[1m\u001b[34m\n",
      "An array of lambda:\u001b[0m\n",
      "[-0.02 -0.01  0.    0.01  0.02]\n",
      "\u001b[1m\u001b[34m\n",
      "Independent eigenvectors:\u001b[0m\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance of noise Z_tilde:\u001b[0m\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0016 0.     0.    ]\n",
      " [0.     0.     0.0016 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given:\n",
    "1. Maximum number of iterations: MAX_ITERS = 10,000\n",
    "2. Dimensions of the matrix: s = 3, n = 4, and m = 2\n",
    "3. Tolerable error: TOL_ERR = 1e-8\n",
    "4. Reconstruction error tolerance: MAX_RECON_ERR = 0.05\n",
    "5. A nxn positive definite matrix Sigma_Y = Gamma * Sigma_V * Gamma_T + Sigma_Z_tilde\n",
    "6. An array of gamma = [0.98, 1.02] with step size = 0.01\n",
    "7. An array of lambda = [-0.02, 0.02] with step size = 0.01\n",
    "\"\"\"\n",
    "\n",
    "# Constants\n",
    "MAX_ITERS = 10000\n",
    "s, n, m = 3, 4, 2\n",
    "TOL_ERR = 1e-8\n",
    "MAX_RECON_ERR = 0.05\n",
    "\n",
    "num_cases = 3\n",
    "num_samples = int(1e7)\n",
    "alpha = 2\n",
    "beta = 4\n",
    "mean = 0\n",
    "std_dev_v1 = 0.01\n",
    "std_dev_v2 = 0.02\n",
    "std_dev_v3 = 0.03\n",
    "std_dev_z2 = 0.02\n",
    "std_dev_z3 = 0.03\n",
    "\n",
    "# Arrays of gamma and lambda\n",
    "gamma_arr = np.round(np.arange(0.98, 1.02, 0.01), 2)\n",
    "print(colored('An array of gamma:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(gamma_arr))\n",
    "\n",
    "lambda_arr = np.round(np.arange(-0.02, 0.03, 0.01), 2)\n",
    "print(colored('\\nAn array of lambda:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(lambda_arr))\n",
    "\n",
    "# Independent eigenvectors\n",
    "eigenvectors = np.array([[1,0,0], [0,1,0], [0,0,1], [0,0,0]])\n",
    "print(colored('\\nIndependent eigenvectors:', 'blue', attrs=['bold']))\n",
    "print(eigenvectors)\n",
    "\n",
    "# Covariance of noise Z_tilde\n",
    "sigma_squared = 0.04**2\n",
    "Sigma_Z_tilde = sigma_squared * np.identity(n)\n",
    "print(colored('\\nCovariance of noise Z_tilde:', 'blue', attrs=['bold']))\n",
    "print(np.round(Sigma_Z_tilde, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d132e67",
   "metadata": {},
   "source": [
    "## II. Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80859011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAll ways to divide the indices of the generative parameters into two distinct groups:\n",
      "\u001b[0m\n",
      "Partition 1: Group 1: set(), Group 2: {3, 4, 5}\n",
      "Partition 2: Group 1: {3}, Group 2: {4, 5}\n",
      "Partition 3: Group 1: {4}, Group 2: {3, 5}\n",
      "Partition 4: Group 1: {5}, Group 2: {3, 4}\n",
      "Partition 5: Group 1: {3, 4}, Group 2: {5}\n",
      "Partition 6: Group 1: {3, 5}, Group 2: {4}\n",
      "Partition 7: Group 1: {4, 5}, Group 2: {3}\n",
      "Partition 8: Group 1: {3, 4, 5}, Group 2: set()\n"
     ]
    }
   ],
   "source": [
    "print(colored('All ways to divide the indices of the generative parameters into two distinct groups:\\n', attrs=['bold']))\n",
    "\n",
    "V_indices = np.arange(m + 1, m + s + 1)\n",
    "\n",
    "groups_list_V = []\n",
    "group_1_list_V = []\n",
    "group_2_list_V = []\n",
    "group_1_list_XV = []\n",
    "group_2_list_XV = []\n",
    "\n",
    "# Initialize an empty list to store valid partitions\n",
    "valid_partitions = []\n",
    "\n",
    "# Generate all possible ways to divide the set into 2 groups\n",
    "for i in range(len(V_indices) + 1):\n",
    "    for j in range(len(V_indices) + 1):\n",
    "        if i + j <= len(V_indices):\n",
    "            group_1_combinations = combinations(V_indices, i)\n",
    "            for group_1 in group_1_combinations:\n",
    "                remaining_indices_1 = set(V_indices) - set(group_1)\n",
    "                group_2_combinations = combinations(remaining_indices_1, j)\n",
    "                for group_2 in group_2_combinations:\n",
    "                    if len(group_1) + len(group_2) == 3:\n",
    "                        valid_partitions.append((set(group_1), set(group_2)))\n",
    "\n",
    "# Print the valid partitions\n",
    "for idx, partition in enumerate(valid_partitions, start=1):\n",
    "    group_1, group_2 = partition\n",
    "    print(f'Partition {idx}: Group 1: {group_1}, Group 2: {group_2}')\n",
    "\n",
    "    groups_list_V.append([e - 1 for e in list(group_1)] + [e - 1 for e in list(group_2)])\n",
    "    group_1_list_V.append(list(group_1))\n",
    "    group_2_list_V.append(list(group_2))\n",
    "    group_1_list_XV.append([1] + list(group_1))\n",
    "    group_2_list_XV.append([2] + list(group_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71998a63",
   "metadata": {},
   "source": [
    "## III. Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c24ec2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_I2(det_v1, det_v2, det_x1v1, det_x2v2, det_v1v2, len_group_1, len_group_2):\n",
    "    \n",
    "    # 1 group is empty\n",
    "    if len_group_1 == 0:\n",
    "        I_2 = round(0.5 * np.log(det_v2/det_x2v2), 8)\n",
    "    elif len_group_2 == 0:\n",
    "        I_2 = round(0.5 * np.log(det_v1/det_x1v1), 8)\n",
    "        \n",
    "    # None of the groups are empty\n",
    "    else:\n",
    "        I_2 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v2/det_x2v2) - \\\n",
    "                           np.log(det_v1*det_v2/det_v1v2)), 8)\n",
    "    \n",
    "    return I_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb42db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_larger_value(a, b):\n",
    "    values = {\"1\": a, \"2\": b}\n",
    "    sorted_values = sorted(values.items(), key=lambda x: x[1], reverse=True)\n",
    "    (name1, value1), (name2, value2) = sorted_values[:2]\n",
    "    return (name1, value1), (name2, value2)\n",
    "\n",
    "def compute_SAP(Cov_x1v1, Cov_x2v1,\n",
    "                Cov_x1v2, Cov_x2v2,\n",
    "                Cov_x1v3, Cov_x2v3):   \n",
    "\n",
    "    S_11 = (Cov_x1v1/std_dev_v1) ** 2 \n",
    "    S_21 = (Cov_x2v1/std_dev_v1) ** 2\n",
    "    \n",
    "    S_12 = (Cov_x1v2/std_dev_v2) ** 2 \n",
    "    S_22 = (Cov_x2v2/std_dev_v2) ** 2 \n",
    "    \n",
    "    S_13 = (Cov_x1v3/std_dev_v3) ** 2 \n",
    "    S_23 = (Cov_x2v3/std_dev_v3) ** 2\n",
    "    \n",
    "    result1_v1, result2_v1 = find_larger_value(S_11, S_21)\n",
    "    result1_v2, result2_v2 = find_larger_value(S_12, S_22)\n",
    "    result1_v3, result2_v3 = find_larger_value(S_13, S_23)\n",
    "          \n",
    "    diff_1 = result1_v1[1] - result2_v1[1]\n",
    "    diff_2 = result1_v2[1] - result2_v2[1]\n",
    "    diff_3 = result1_v3[1] - result2_v3[1]\n",
    "    \n",
    "    SAP = 1/s * (diff_1 + diff_2 + diff_3)\n",
    "    print(colored(f'\\nSAP = {round(SAP, 4)}', 'red', attrs=['bold']))\n",
    "    \n",
    "    if result1_v1[0] == result1_v2[0] == result1_v3[0]:\n",
    "        print('(v1, v2, v3) can be captured by a single latent variable.')\n",
    "    elif result1_v1[0] == result1_v2[0]:\n",
    "        print('(v1, v2) are captured by one latent variable and v3 by a second latent variable.') \n",
    "    elif result1_v2[0] == result1_v3[0]:\n",
    "        print('(v2, v3) are captured by one latent variable and v1 by a second latent variable.')\n",
    "    elif result1_v1[0] == result1_v3[0]:\n",
    "        print('(v1, v3) are captured by one latent variable and v2 by a second latent variable.')\n",
    "    else:\n",
    "        print('Error!') \n",
    "    \n",
    "    return SAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a52ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_I2(cov_XV):\n",
    "    max_MI = -1000\n",
    "    max_idx = 0\n",
    "    \n",
    "    det_x1v1_arr = []\n",
    "    det_x2v2_arr = []\n",
    "\n",
    "    # Generate an array of indices\n",
    "    for i, (group_1_idx_V, group_2_idx_V,\n",
    "            group_1_idx_XV, group_2_idx_XV,\n",
    "            groups_idx_V) in enumerate(zip(group_1_list_V, group_2_list_V,\n",
    "                                           group_1_list_XV, group_2_list_XV,\n",
    "                                           groups_list_V)):\n",
    "        \n",
    "        # Generate two-digit numbers with repetition from the array and in increasing order\n",
    "        group_1_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_1_idx_V, repeat=2)]\n",
    "        group_2_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_2_idx_V, repeat=2)]\n",
    "        group_1_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_1_idx_XV, repeat=2)]\n",
    "        group_2_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_2_idx_XV, repeat=2)]\n",
    "        groups_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(groups_idx_V, repeat=2)]\n",
    "    \n",
    "        # Specify the positions to extract\n",
    "        tuple_list_1_V = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_V]\n",
    "        tuple_list_2_V = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_V]\n",
    "        tuple_list_1_XV = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_XV]\n",
    "        tuple_list_2_XV = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_XV]\n",
    "        tuple_list_V = [(int(str(number)[0]), int(str(number)[1])) for number in groups_two_digit_numbers_V]\n",
    "    \n",
    "        # Get the new matrix from specified positions\n",
    "        dim_v1 = len(group_1_idx_V)\n",
    "        dim_v2 = len(group_2_idx_V)\n",
    "        dim_x1v1 = len(group_1_idx_XV)\n",
    "        dim_x2v2 = len(group_2_idx_XV)\n",
    "        dim_V = s\n",
    "    \n",
    "        cov_v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_V]).reshape(dim_v1, dim_v1)\n",
    "        if len(cov_v1) == 1:\n",
    "            cov_v1 = cov_v1[0]\n",
    "        cov_v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_V]).reshape(dim_v2, dim_v2)\n",
    "        if len(cov_v2) == 1:\n",
    "            cov_v2 = cov_v2[0]\n",
    "        \n",
    "        cov_V = np.array([cov_XV[i, j] for i, j in tuple_list_V]).reshape(dim_V, dim_V)\n",
    "    \n",
    "        cov_x1v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_XV]).reshape(dim_x1v1, dim_x1v1)\n",
    "        cov_x2v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_XV]).reshape(dim_x2v2, dim_x2v2)\n",
    "    \n",
    "        # Compute the determinant of each covariance matrix\n",
    "        det_v1v2 = det(cov_V)\n",
    "        det_x1v1 = det(cov_x1v1)\n",
    "        det_x2v2 = det(cov_x2v2)\n",
    "        \n",
    "        if len(cov_v1) == 1:\n",
    "            det_v1 = cov_v1[0]\n",
    "            det_x1v1_arr.append(det_x1v1) \n",
    "        else:    \n",
    "            det_v1 = det(cov_v1)\n",
    "        if len(cov_v2) == 1:\n",
    "            det_v2 = cov_v2[0]\n",
    "            det_x2v2_arr.append(det_x2v2) \n",
    "        else:    \n",
    "            det_v2 = det(cov_v2)\n",
    "            \n",
    "        # Compute I_2\n",
    "        I_2 = compute_I2(det_v1, det_v2, det_x1v1, det_x2v2, det_v1v2,\n",
    "                         len(group_1_idx_V), len(group_2_idx_V))\n",
    "    \n",
    "        if I_2 > max_MI:\n",
    "            max_MI = I_2\n",
    "            max_idx = i+1\n",
    "    \n",
    "    print(colored(f'\\nThe maximum value of I_2 is {round(max_MI, 4)} at Partition {max_idx}.', 'red', attrs=['bold']))\n",
    "\n",
    "    partition = max_idx\n",
    "    \n",
    "    if partition in [1, 8]:\n",
    "        print('(v1, v2, v3) can be captured by a single latent variable.')\n",
    "    elif partition in [4, 5]:\n",
    "        print('(v1, v2) are captured by one latent variable and v3 by a second latent variable.')\n",
    "    elif partition in [3, 6]:\n",
    "        print('(v1, v3) are captured by one latent variable and v2 by a second latent variable.')\n",
    "    elif partition in [2, 7]:\n",
    "        print('(v2, v3) are captured by one latent variable and v1 by a second latent variable.')\n",
    "    else:\n",
    "        print('Error!')\n",
    "    \n",
    "    return max_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359696db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(I2_scores, SAP_scores):\n",
    "    \"\"\"\n",
    "    Plot the comparison of I2 and SAP scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define indices for (gamma, lambda) pairs\n",
    "    pair_indices = range(1, 26)\n",
    "\n",
    "    # Plot I2 and SAP scores\n",
    "    plt.plot(pair_indices, I2_scores, label='I2', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(pair_indices, SAP_scores, label='SAP', marker='s', linestyle='--', color='green')\n",
    "\n",
    "    # Set axis labels and legend\n",
    "    plt.xlabel(r'$(\\gamma, \\lambda)$ Pair Index')\n",
    "    plt.ylabel('Scores')\n",
    "\n",
    "    # Configure legend placement\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Enable LaTeX rendering\n",
    "    plt.rc('text', usetex=True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f6e5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_across_scenarios(score_1, score_2, score_3, flag):\n",
    "    \"\"\"\n",
    "    Plot of Score Distribution Across Scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    scenarios = ['Scenario 1', 'Scenario 2', 'Scenario 3']\n",
    "    scores = [score_1, score_2, score_3]\n",
    "\n",
    "    # Create a boxplot with colored boxes\n",
    "    boxplot = plt.boxplot(scores, labels=scenarios, patch_artist=True, medianprops=dict(color='black'))\n",
    "\n",
    "    # Set box colors\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for box, color in zip(boxplot['boxes'], colors):\n",
    "        box.set_facecolor(color)\n",
    "\n",
    "    # Add statistics (mean, median, std) labels to legend\n",
    "    legend_labels = []\n",
    "    for i, data in enumerate(scores, start=1):\n",
    "        mean, median, std = np.mean(data), np.median(data), np.std(data)\n",
    "        label = f'Mean = {mean:.2f}\\nMedian = {median:.2f}\\nStd = {std:.2f}'\n",
    "        legend_labels.append(label)\n",
    "\n",
    "    if flag == 0:\n",
    "        plt.ylabel('I2 Scores')\n",
    "    else: \n",
    "        plt.ylabel('SAP Scores')\n",
    "\n",
    "    plt.grid(True, linestyle='-', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Move the legend outside and below the figure\n",
    "    plt.legend(handles=[boxplot[\"boxes\"][0], boxplot[\"boxes\"][1], boxplot[\"boxes\"][2]],\n",
    "               labels=legend_labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0559a89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 1:\u001b[0m\n",
      "Given (sigma_v1, sigma_v2, sigma_v3) = (0.01, 0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[ 0.0001 -0.      0.    ]\n",
      " [-0.      0.0004 -0.    ]\n",
      " [ 0.     -0.      0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0002\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0002\n",
      "\n",
      "Reconstruction error:\n",
      "3.386e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0001\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0001 at Partition 5.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0018\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0018\n",
      "\n",
      "Reconstruction error:\n",
      "1.632e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0007\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0005 at Partition 5.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0003\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0005\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0005\n",
      "\n",
      "Reconstruction error:\n",
      "3.45e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0001\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0001 at Partition 5.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0001\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0011\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0011\n",
      "\n",
      "Reconstruction error:\n",
      "7.376e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0002\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0002 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0002\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0017\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0017\n",
      "\n",
      "Reconstruction error:\n",
      "8.938e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0001\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0001 at Partition 7.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0001\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.004 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.1735\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.1585\n",
      "\n",
      "Reconstruction error:\n",
      "0.00397009\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1419\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1317 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0745\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.004 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "44.2145\n",
      "\n",
      "Mutual information of the decoder:\n",
      "44.1996\n",
      "\n",
      "Reconstruction error:\n",
      "0.00397017\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1419\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.142 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.086\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.004 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.8801\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.8652\n",
      "\n",
      "Reconstruction error:\n",
      "0.00397025\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1116\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0888 at Partition 3.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0415\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.005 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.4145\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.3995\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496293\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.2533 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1387\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.005 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.5661\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.5512\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496305\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.3347\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.2896 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1432\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.0067 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "94.031\n",
      "\n",
      "Mutual information of the decoder:\n",
      "94.0013\n",
      "\n",
      "Reconstruction error:\n",
      "0.00669945\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0303\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0296 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0185\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.0079 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.1648\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.1351\n",
      "\n",
      "Reconstruction error:\n",
      "0.00788181\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1419\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1429 at Partition 3.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0866\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.0099 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.5909\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.5612\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985246\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.3347\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1767 at Partition 3.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0257\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.0099 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "94.6938\n",
      "\n",
      "Mutual information of the decoder:\n",
      "94.6641\n",
      "\n",
      "Reconstruction error:\n",
      "0.0098527\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.3347\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.307 at Partition 3.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1589\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.0067 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.2944\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.2647\n",
      "\n",
      "Reconstruction error:\n",
      "0.00669989\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0303\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0305 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0196\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 2:\u001b[0m\n",
      "Given (sigma_v1, sigma_v3) = (0.01, 0.03), alpha = 2, and sigma_z2 = 0.02:\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[ 0.0001  0.0002 -0.    ]\n",
      " [ 0.0002  0.0008 -0.    ]\n",
      " [-0.     -0.      0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.     0.    ]\n",
      " [0.0002 0.0024 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.0152 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0803\n",
      "\n",
      "Reconstruction error:\n",
      "0.01522543\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.02 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0342\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.0152 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0804\n",
      "\n",
      "Reconstruction error:\n",
      "0.01519563\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0134 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0119\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.0152 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0804\n",
      "\n",
      "Reconstruction error:\n",
      "0.01516584\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0169 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0237\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.0151 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.079\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0805\n",
      "\n",
      "Reconstruction error:\n",
      "0.01513606\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0103 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0013\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.0151 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.079\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0805\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510628\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0113 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0047\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.0075 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.09\n",
      "\n",
      "Reconstruction error:\n",
      "0.00748475\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0223 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0379\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.0075 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.09\n",
      "\n",
      "Reconstruction error:\n",
      "0.00745645\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0223 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.038\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.0074 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.00742817\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0194 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0282\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.0074 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0893\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.00739988\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0225\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0221 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.037\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.0074 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0893\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.0073716\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0225\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0221 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0372\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0996\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0996\n",
      "\n",
      "Reconstruction error:\n",
      "5.376e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0238\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0204 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0291\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1007\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1007\n",
      "\n",
      "Reconstruction error:\n",
      "2.819e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0229\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0229 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.039\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0995\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0995\n",
      "\n",
      "Reconstruction error:\n",
      "1e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0249\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0246 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0416\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0996\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0996\n",
      "\n",
      "Reconstruction error:\n",
      "2.673e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0257\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0217 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0306\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1012\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1012\n",
      "\n",
      "Reconstruction error:\n",
      "5.243e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.027\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0264 at Partition 5.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0437\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.0048 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.282\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.2671\n",
      "\n",
      "Reconstruction error:\n",
      "0.00479667\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2027\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1941 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2571\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.4903\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.4753\n",
      "\n",
      "Reconstruction error:\n",
      "0.00486899\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.2137 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2867\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.005 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.6119\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.597\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496281\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.2268 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1307\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.0034 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "45.0386\n",
      "\n",
      "Mutual information of the decoder:\n",
      "45.0237\n",
      "\n",
      "Reconstruction error:\n",
      "0.00342113\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0303\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0276 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0322\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.1263\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.1114\n",
      "\n",
      "Reconstruction error:\n",
      "0.00486927\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1996 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.244\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.0097 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.1093\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.0796\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966508\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1914 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2189\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.0097 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "93.4183\n",
      "\n",
      "Mutual information of the decoder:\n",
      "93.3886\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966591\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1956 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2307\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.0097 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.1079\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.0782\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966597\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1955 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2305\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.0095 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.4747\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.445\n",
      "\n",
      "Reconstruction error:\n",
      "0.0095223\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2027\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.2045 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.279\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.0097 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.8823\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.8526\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966611\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1441 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1335\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 3:\u001b[0m\n",
      "Given sigma_v1 = 0.01, (alpha, beta) = (2, 4), and (sigma_z2, sigma_z3) = (0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[0.0001 0.0002 0.0004]\n",
      " [0.0002 0.0008 0.0008]\n",
      " [0.0004 0.0008 0.0025]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.0004 0.    ]\n",
      " [0.0002 0.0024 0.0008 0.    ]\n",
      " [0.0004 0.0008 0.0041 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.0152 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2726\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2769\n",
      "\n",
      "Reconstruction error:\n",
      "0.01517876\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1485\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1383 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3417\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.0151 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2727\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.277\n",
      "\n",
      "Reconstruction error:\n",
      "0.01514335\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1486\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1252 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2809\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.0151 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2728\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2771\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510793\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1486\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1098 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2069\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.0151 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2729\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2772\n",
      "\n",
      "Reconstruction error:\n",
      "0.01507249\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1487\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1417 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3567\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.015 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.273\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2772\n",
      "\n",
      "Reconstruction error:\n",
      "0.01503704\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1487\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1442 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3681\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.0088 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2895\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2918\n",
      "\n",
      "Reconstruction error:\n",
      "0.00878012\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1589\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1538 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3875\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.0087 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2896\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2919\n",
      "\n",
      "Reconstruction error:\n",
      "0.00873896\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.159\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.092 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0962\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.0087 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2898\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.292\n",
      "\n",
      "Reconstruction error:\n",
      "0.00869777\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.159\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1557 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3955\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.0087 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2899\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2921\n",
      "\n",
      "Reconstruction error:\n",
      "0.00865654\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1591\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.101 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1402\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.0086 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.29\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2922\n",
      "\n",
      "Reconstruction error:\n",
      "0.00861527\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1592\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.0877 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0737\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3209\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.321\n",
      "\n",
      "Reconstruction error:\n",
      "0.00012597\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1777\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1571 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3593\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3213\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3213\n",
      "\n",
      "Reconstruction error:\n",
      "6.337e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1779\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1576 at Partition 8.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.361\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3214\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3214\n",
      "\n",
      "Reconstruction error:\n",
      "1e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1778\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1593 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3678\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3219\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3219\n",
      "\n",
      "Reconstruction error:\n",
      "6.356e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1783\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1515 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3329\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 0.0001 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3222\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3222\n",
      "\n",
      "Reconstruction error:\n",
      "0.00012732\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1785\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.1402 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2821\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.8817\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.8668\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493023\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.3097 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.4431\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.8958\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.8808\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493044\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.489 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.7012\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.5917\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.5768\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493071\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.5122 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.8421\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.6654\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.6504\n",
      "\n",
      "Reconstruction error:\n",
      "0.0049309\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.4399 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.6631\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.0049 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "46.4838\n",
      "\n",
      "Mutual information of the decoder:\n",
      "46.4689\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493111\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.3231 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.4596\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.0098 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.2912\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.2616\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.5152 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.8261\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.0095 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.7142\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.6845\n",
      "\n",
      "Reconstruction error:\n",
      "0.0094828\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.4549 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.8021\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.0098 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.187\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.1573\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978309\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.5065 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.866\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.0095 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "95.6982\n",
      "\n",
      "Mutual information of the decoder:\n",
      "95.6685\n",
      "\n",
      "Reconstruction error:\n",
      "0.00948334\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.4858 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.8462\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.0098 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "94.8639\n",
      "\n",
      "Mutual information of the decoder:\n",
      "94.8342\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978428\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_2 is 0.4178 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.6355\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n"
     ]
    }
   ],
   "source": [
    "# Numerical Simulation\n",
    "all_I2_score_arr = []\n",
    "all_SAP_score_arr = []\n",
    "\n",
    "for case in range(num_cases):\n",
    "    # Compute Sigma_Y given Sigma_V\n",
    "    Sigma_V = generate_Sigma_V(case)\n",
    "    \n",
    "    Sigma_Y = eigenvectors @ Sigma_V @ eigenvectors.T + Sigma_Z_tilde\n",
    "    print(colored('\\nCovariance matrix of input data Y:', 'blue', attrs=['bold']))\n",
    "    print(np.round(Sigma_Y, 4))\n",
    "    is_positive_definite(Sigma_Y)\n",
    "    \n",
    "    # Constants\n",
    "    MAX_SOLS = 5\n",
    "    is_array = 1\n",
    "    flag = 0\n",
    "    case_num = 1\n",
    "\n",
    "    # Initiate arrays\n",
    "    min_recon_err_arr = []\n",
    "    min_en_mi_arr = []\n",
    "    min_de_mi_arr = []\n",
    "    all_recon_mi_arr = []\n",
    "    satisfied_recon_mi_arr = []\n",
    "    satisfied_gamma_lambda_arr = []\n",
    "    \n",
    "    # Iteration step\n",
    "    for i in range(0, len(gamma_arr)):\n",
    "        gamma = gamma_arr[i]\n",
    "        for j in range(0, len(lambda_arr)):\n",
    "            lamda = lambda_arr[j]\n",
    "        \n",
    "            min_recon_err, min_en_mi, min_de_mi, min_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "        \n",
    "            first_iter = 1\n",
    "            for num_sols in range(0, MAX_SOLS):\n",
    "                current_recon_err, current_en_mi, current_de_mi, current_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "    \n",
    "                # Check for unique optimal solutions for each (gamma, lambda) pair\n",
    "                if first_iter == 1:\n",
    "                    if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - min_opt_sol[:2*n*m+n*n+m*m], 1e-6):\n",
    "                        is_unique = 1\n",
    "                        unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                    else:\n",
    "                        is_unique = 0\n",
    "                    first_iter = 0\n",
    "                else:\n",
    "                    if is_unique == 1:\n",
    "                        if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - unique_opt_sol, 1e-6):\n",
    "                            unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                        else:\n",
    "                            is_unique = 0\n",
    "    \n",
    "                # Return the solution with smallest reconstruction error\n",
    "                if current_recon_err < min_recon_err:\n",
    "                    min_recon_err = current_recon_err\n",
    "                    min_en_mi = current_en_mi\n",
    "                    min_de_mi = current_de_mi\n",
    "                    min_opt_sol = current_opt_sol\n",
    "                \n",
    "            min_recon_err_arr = np.concatenate((min_recon_err_arr, [min_recon_err]))\n",
    "            min_en_mi_arr = np.concatenate((min_en_mi_arr, [min_en_mi]))\n",
    "            min_de_mi_arr = np.concatenate((min_de_mi_arr, [min_de_mi]))\n",
    "            all_recon_mi_arr = np.concatenate((all_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            print(colored('\\nCase {}:'.format(case_num), 'blue', attrs=['bold']))\n",
    "            case_num += 1\n",
    "        \n",
    "            if min_recon_err > MAX_RECON_ERR:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that EXCEEDS the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            else:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that SATISFIES the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            \n",
    "                satisfied_gamma_lambda_arr = np.concatenate((satisfied_gamma_lambda_arr, [gamma, lamda]))\n",
    "                satisfied_recon_mi_arr = np.concatenate((satisfied_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            if is_unique == 1:\n",
    "                print(colored('The optimal solution is unique!\\n', 'blue', attrs=['bold']))\n",
    "            else:\n",
    "                print(colored('The optimal solution is NOT unique!\\n', 'red', attrs=['bold']))\n",
    "        \n",
    "            print_optimal_solution(min_opt_sol, m)\n",
    "        \n",
    "            # Compute mutual information I(V;X) and I_2\n",
    "            B_opt = min_opt_sol[n*m:2*n*m].reshape((m, n))\n",
    "            Sigma_W_opt = min_opt_sol[2*n*m+n*n:2*n*m+n*n+m*m].reshape((m, m))\n",
    "        \n",
    "            mutual_info_VX = mi_VX(B_opt, Sigma_W_opt)\n",
    "            print('\\nMutual information between generative variable and latent variable:')\n",
    "            print(round(mutual_info_VX, 4))\n",
    "        \n",
    "            cov_XV = covariance_matrix_XV(B_opt)\n",
    "            I2_max = max_I2(cov_XV)\n",
    "            \n",
    "            # Extract elements from covariance matrix (X,V)\n",
    "            Cov_x1v1 = cov_XV[0, 2]\n",
    "            Cov_x2v1 = cov_XV[1, 2]\n",
    "\n",
    "            Cov_x1v2 = cov_XV[0, 3]\n",
    "            Cov_x2v2 = cov_XV[1, 3]\n",
    "\n",
    "            Cov_x1v3 = cov_XV[0, 4]\n",
    "            Cov_x2v3 = cov_XV[1, 4]\n",
    "            \n",
    "            # Compute SAP\n",
    "            SAP_score = compute_SAP(Cov_x1v1, Cov_x2v1,\n",
    "                                    Cov_x1v2, Cov_x2v2,\n",
    "                                    Cov_x1v3, Cov_x2v3)\n",
    "            \n",
    "            all_I2_score_arr.append(I2_max)\n",
    "            all_SAP_score_arr.append(SAP_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d428b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 1:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 2:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABCv0lEQVR4nO2deXxU1d3/3ycrCQmZJJAJWxICgmvBEB5xJSq4Q300oBarrUvQ+mtdQGhFq7ZSBW3tY32qQKutj+CGS9VaNVhiXVAEVFARxEAgATJk3/fz++POJJNkZjJJZsnMfN+v17xm7jn33Ps9mcn53LN8v0dprREEQRBClzB/GyAIgiD4FxECQRCEEEeEQBAEIcQRIRAEQQhxRAgEQRBCHBECQRCEECfCGxdVSuUCVUCm1nqNg/zZ1o9ztNbL3CkjCIIgeAeP9wisDTpa643W49k98rOALGt+llIqs68ygiAIgvfwxtDQDKDQ+rkQyLLP1Fpv11qvUkqZgEKtdWFfZQRBEATv4Y2hIVOP42Qn52UD37tbRimVB+QBxMTETB8/fjwdHR2EhYXuNEco1z+U6w6hXX+p+8DrvmfPnjKt9aie6d4Qgiogqa+TtNYblVLz7eYGXJaxzhusAcjOztZbt26loKCAnJycQRscqIRy/UO57hDa9Ze65wy4vFKqyFG6N2T1M7qe8DOB/B6GrLQ+3UOXALgsIwiCIHgPjwuB1noDkGmd8DXZTQDbGvfVQKFd/hpnZQRBEATv45Xlo1rrVdaPG+3S5ljfC+maGN7oqowgCILgfbwiBP6gtbWV4uJimpqa/G2Kxxg2bBjjxo0jMjLS36YIghDEBI0QFBcXEx8fT0ZGBkopf5szaLTWlJeXU1xczIQJE/xtjhAipD6SSml9aa9083AzR5Yc8YNFgi8ImjVYTU1NJCcnB4UIACilSE5ODqoejjD0cSQCrtKF4CBohAAIGhGwEWz1EQRhaBJUQtAf1q2DjAwICzPe160b3PWqqqqYPn165/H8+fOZM2cOixYtGtyFBUEQvExICsG6dZCXB0VFoLXxnpc3eDGwsWbNGtauXUt+vrFiduNGWQglCMLQJWgmi+257Tb44gvn+Z98As3N3dMaGuD662HtWsdlpk2DP/7Rvfvn5eV1fp44cSJVVVXuFRQEQfADQSkEfdFTBPpKHwz5+fm89NJLnr+wIHgB83Cz01VDgmcYiiuzglII+npyz8gwhoN6kp4OBQWes2PRokWsXr0ak8nkuYsKgpf4/ce/Z8U5K7g+63p/mxLUDMWVWSE5R7BiBcTGdk+LjTXSPcWyZctYtmwZmZmZnruoIHiJ3WW7uevfd7Fp/ybA8GM5Wn+UupY6P1sm+IKQFIKFC2HNGqMHoJTxvmaNke4JVq1axcaNG1m0aBFz5sxhw4YNnrmwIHgBrTU/e+tnxETE8Pvzfg/AnvI9pDySwqu7XvWzdYIvCMqhIXdYuNBzDT+AyWRi27ZtACxdupSlS5d67uKC4EXW71zPv/f9mz9f9GfMccZcQFpCGgAHqg/40zTBR4Rkj0AQBIP6lnruePcO/mvsf5E3vWu1W0xkDKNiR4kQhAgh2yMQBAGGRw3n6R8+zdj4sYSHhXfLS0tI42DNQT9ZFrzERsbS0NrQK92fK7NECAQhRGnvaCc8LJyLjrnIYX5aQhp7yvf42Krgpq2jjRHRI5idOZus1Czuf/9+Gpc3Eh0R7Ve7RAgEIQRp62jj9KdO58oTruT2U293eM4NWTdQ3lDuY8uCm3f2vsORuiP8dNpPAZidOZua5hpGRfTaRtiniBAIQgjy+JbH2VKyhaWnOV/U4KynIAycgzUHyUzM5OJjLiYyPJJLj73U3yYBMlksCCFHcU0x92y6hwsnXchlx13m9LzG1ka2H95OVVOV74wLcm7Kvok9/28PkeFDa7OpkBSC1EdSUferXq/UR1IHdV2b38CiRYt6+Q5s2LCBxMTEXmUSExNZtmwZ8+fPZ/78+RKXSPA6t719G20dbTx+0eMuQ53vtOxk+prpfFD0gQ+tC14qGyvRWndOymutOf5/j+f+gvv9bFmIDg15w8V7w4YNTJw4kdWrVwP0atBfeOEFFixYwMaNG5k9e3ZnemZmJitXrgSMKKU33nijxCYSvMae8j289u1r/Obs35CZ6NrrXXwJPMvs/5vNlOQprL98PWDsN9LU1sSeCv9PyAetEOT8LadX2oITFvCzGT/rs2xZQxm5L+Z2Syv4SYHLMiaTifz8fPLy8jCZTN3iC9lEYdGiRTz44IPdhEAQfMnk5Ml8cdMXTE6e3Oe5KcNTiAqPEiHwADtKd7D98HZ+MvUn3dIzTBnsr9rvF5vsCVoh8DWzZ8+mqqqK+fPnU1FRwdq1a8nKygLgxRdfZNGiRWRlZbF9+3aqqqo6haKwsJBly5ZRWFhIVVWV9AYEr7G/aj8ZpgxOTDnRrfPDVBjjR4znQI0IwWB5+vOniQyL5Ecn/ahbeoYpg3e+f8dPVnURtELQ1xO8K0bGjhxQ+dzcXHJzcyksLGT+/PmdISdWr15NdnZ250Y1L774YueeBUlJSZ1DQ4LgSTwR7jgtIU16BIOkpb2FZ3c+y7wp80iOTe6Wl2HK4FDtIZrbmv3qSxC0QuBrCgsLOyONJiUldUvPzs7unDtYtGgR8+fP77Z5jSB4A0/Mhd07617ZO3uQvPXdW5Q1lHX6Dthz6rhT+em0n9LQ2iBC4Gu8sflGVVUVc+bMwWQyUVhYyFrrVmerV6/utm+xTSzshUMQhiqzMmb524SA57yJ57H+svWcP+n8XnlzJs5hzsQ5frCqOyEpBN7YBSgrK6tz6MceR8M+tiEjgO+//97jtgiCpyhrKOOjAx8xK2MWpmEmf5sTkMRGxnLVSVc5zdda09Le4tceQUj6EQiC4B6fH/6cS1+4lJ2lO/1tSkCyfud6Hv7oYTp0h8P8Dt2BaaWJ+9/3ry+BV4RAKZWrlJqtlOo1EK6UMimlsqznrLRLr1RK5SulJJC/IAwRxJdg4GiteejDh9iwawNhynFTG6bCGBk7kn1V+3xsXQ87PH1BpVQugNZ6o/W456L5BUC21nqDNd8mFvO11nO01qsGem+t9UCLDkmCrT6Cb3E259WfubDxCeMBEYKB8PmRz9lp2elwktieCaYJfvcl8MYcwQzgBevnQiAL2GjL1FqvsTs3E7ANrJuUUpla68KB3HTYsGGUl5eTnJwcFKsctNaUl5czbNgwf5siBCi2ubC7/303s9JnDWhSMjYyluSYZBGCAfD0508THR7NFSdc4fK8DFMG//zunz6yyjHeEAJTj+NkRycppTKBClvPAUgCKpRSq7XWixycnwfkAZjNZgoKCqirq6OgoMCWz/Dhwzl4MHg20mhvb6e+vp6ioiKH+fb1DzVCue7gfv1bO1pZ8cEKSg6UEHlwYIHOksKT+Hzf50Pm7x0I331LRwvPfP4MpyedzpeffunyXF2pOVJ3hHfee4focNcTxt6quzeEoAqjUe+LXPsG39ZTUEpVKaVybUNHPfLXAGRnZ+ucnBwKCgrIycnxmOGBRijXP5TrDu7X/1DtIfgAZp44k5zsvs93xPNTnmdE9AgmJU0aUHlP4AnnOF9SXFPMzEMzWXLqEnIm5rg8N+pgFOO/H89pp55GfHS8y3O99bv3hhB8RlevwH7opxNrQ7/K+jkLyAa2aq23e8EeQQhZLPUWwIgbNFCyRmd5ypwB441Akd5k3IhxvHO1e6EjTht/GqeNP83LFrnG45PF1if5TOsksclu0jjf+j4bWKmU2qaU2obRe3jRmpdrdw1BEAaJJ4Rgb8VeHt/yOHUtdZ4yK6ipbKykpKbE7fO11pQ1lFHWUOZFq1zjleWjWutVWuuN9iuAtNZzrO8btdYTtdbTra+NWusqrfV2rfUGrfUyb9gkCKFIRWMFMDgh+Pzw5/z8Xz9nX6V/lzgGCmu3ryX9j+nGsJwbaDRjfj+GRz5+xMuWOUccygQhiLnyxCtpWt7ExKSJA76G+BK4j9aap794mpnjZjImfoxbZcJUGOmmdL8uIRUhEIQgJzoi2qlDkzuIELjPpyWf8m3Zt336DvTE3/sSiBAIQhCzeutq7iu4b1DXMMeZiQyLpKja8TJmX+AJ5zhf8Lcv/kZMRAzzT5jfr3IZCSIEgiB4iTf2vMHru18f1DXCVBjjRozza4/gyJIjfLHoC6YkT+GxaY+h79XoezV7fr6HwsoB+aB6nNb2Vl765iUuP/5yRkSP6FfZDFMGpfWlNLQ2eMk614Rk9FFBCBUs9ZZBTRTb+Pe1/yY5xqFvqM8oqS1hd/luwtO6Nn+/cN2FVDdV89mNnxETGeNX+yLDI9l5806a25r7XfaSyZeQGpfqBavcQ4RAEIIYS72FY0ceO+jrZJgyBm/MILEthTVFmgAjmsC9s+7l/GfP54537uCJS54Y1PUH4rTmKUe3qalTmZo61X1jPYwMDQlCEOOpHsGnxZ+yLH8ZbR1tHrBqYNiEIDEqsTPtvInncedpd/Lktid5Zdcrg7r+QJzWPOXo1qE7+Pzw535boitCIAhBSmNrI8OjhntkyGFH6Q5WfbyKw7WHPWDZwLDUW4iNjCUmvPsQ0APnPMCMMTO4/vXrvTaP8cB/HuChDx/ikY8f4Uid8aS/6+guj97j1L+eyhNbB9erGSgyNCQIQUpMZAxH7zzqkWvZlpAWVRd1hqa2Z906WL4cDhyAtDRYsQIWLvTIrTuZmDiRS4+9tFd6VHgUz13+HLe+feuglsm64p5N93R+PjvjbFLjUvlP0X88dn1/+xKIEAiC0CeufAnWrYO8PGiwLngpKjKOwbNicPOMm7l5xs0Oo29OTJrImz96c8DX/qDoA5f5rfe00tbRRltHGzERRo/k6h9czU3/vGnA9+yJP30JZGhIEIKUjw58RO6LuR4ZLnG1Qc3y5V0iYKOhwUj3NeUN5Vy8/mIK9he4dX5Ncw23/PMWzvrbWS7PiwiLYFjEMOKi4ggPM1YtDY8aPlhzu5GRkOG3ncpECAQhSNlVtouXd73skWvFRcWRFJPUOT5uo7XV6AE44oCHh+uPffxYluW7DkUWHRHN3oq9XP3K1ZQ3lPd5zed2PscTW5/gtlNuczqp7sppzZOObhMSJ1DWUOaX4H4yNCQIQYptlc2o2FEeud6B2w50ewr+7jv40Y+cn5+W5pHbAobPwPeV3/c5BxAXFcfzlz/PzL/O5LrXr+O1K17rtWNhWUMZu47u4sz0M7kh6wZOGXcK01Kn8egFj/bbLk/uhZB7fC4np55MZNjANhAaDCIEghCkWOotxEfFe8zRyiYCWsPTT8MvfgFRUXDrrbB2bffhodhYY8LYU1Q1VdHW0YY5zgxNrs89efTJrJy9ktvfuZ2w3/QWDoXCHGdm/637iY6IZlrqNM8ZOggmJU3y2+Y/MjQkCEGKp3wIbLy++3UWvngdCxbA9dfDKafAjh3wxz/CmjUQYX2sTE83jj05UdzffRVuPeVWp3kazbtXv0t0hOttIX1Ne0c7//j2H3x5xPXWlt5AhEAQgpS4qDhOSDnBY9d7a8tu1u96mlf/Vc3KlZCfD+PGGXkLF8Kpp8KsWbB/v+eXjvZXCHoOB/XkJPNJg7bJ04SpMK58+Uqe3fGsz+8tQ0OCEKSsmbvGI9dpaYF774XVb6ZBLqx74yBXnJ3Q6zyzGXbu9Mgte2EaZuLaqdeSmZjJAU/PQg8RlFKkJ6T7ZeWQ9AgEQejGunWQkQFhYTB2LBx7LDz0EMybZcz+xo9z3BCnpkKpl7YQPsl8En+79G9kJmZ65wZDhAmJE/ziSyBCIAhBSIfu4PSnTu/3MIPNOayoyJgUPnQI9u0zJoSfeDAdcL5BTWoqVFVBUx+TuQOhtb0VrbXnLzzE8Ne+BCIEghCEVDRW8PHBjzv3LHYXR85hAK+9BqlxqSTHJNPY2uiwrNm6dN5i6aexbnDr27cy/tHeoS1cESib2diTYcqgvLGc2uZan95X5ggEIQjp7+SqDWfD7wcOGJOZZUvLnJZNtca2O3LEsz4EYNQnYVjveQlXeHKNv6+4Zuo1zJ0yl9jIWJ/eV4RAEIKQgQiB1hAXB7UOHkbdadhtPQJvzBN4einsUGV0/GhGx4/2+X1laEgQgpCBCMFvf2uIQESPx0N757Antz5J7ou5Dsvb9wg8TWl9aUgIQWt7K49veZwPD3zo0/uKEAhCEBITEcOMMTPcHg9/7DFjiehPfmJ4Daeng1K9ncOKa4p57dvXHG5Qk2Jtp70hBJZ6CymxwSME9iuzMjKMYzCC2y3NX8qru171qT0yNCQIQcjcKXOZO2WuW+c+84yxKui//9sIFRERAVdf7fjctIQ02nU7h2sP99qXIDoaEhM9PzSkteaWGbcwc9xMz17YT7gO262McNTV+31qk/QIBCGE+cc/4Lrr4NxzYf363sNCPXG1LwEY8wSe7hEopXjgnAe4ZPIlnr2wn+grbHeGKcPnW1Z6RQiUUrlKqdlKqTwHeSalVJb1nJXulBEEoX/c9OZNLHhpgctzNm2CK66A7GxjeeiwYX1fty8h8IZTWVNbE2UNZXToDs9e2A80NvYdtnuCyfdOZR4XAqVULoDWeqP1eHaPUxYA2VrrDdb8PDfKCILQD74++jVlDc6Xem7ZAvPmwTHHwFtvGauF3GH8iPEcP+r4zs1ZeuKNHkHB/gJGPTyK+//6CRkZcM45s7qNqwcC9fXwhz9ApgvHaNvKrAxTBpVNldQ01/jGOLzTI5gBFFo/FwJZ9pla6zVaa1sQlEzrOS7LCILQP1wtt/z6a7jwQmNy9913ISnJ/evGR8fz9c++ZsEJjnsb3ugR2FZArbo3xerxrDrH1Ye6GNTWwqpVMGECLF4Mxx1nDAHF9nATsF+ZtSh7EdW/rGZE9Aif2emNyWJTj+NkRycppTKBCq31RqXU/L7KWIeM8gDMZjMFBQXU1dU53L80VAjl+ody3aHv+h+qPsQJw07odc7hw8P4xS9ORin47W8/Z/fuJnbv9pxd9fVp1NZm8vbb/2HYMM8M5Ww+uBmApvLuwtbQAIsXNzF27CceuY8nqasL57XXxvLSS+OpqYkkO7uCe+4p4qSTqq1npPDkkxMpL48mPr6VX/ziO8aOtdDXT9prv3uttUdfwEpgtvXzbGClk/OW9reM7TV9+nSttdabNm3SoUwo1z+U66616/o3tTZp7kP/9v3fdks/dEjrzEytExO13rlz4Pf+1cZf6QufvdBh3lNPaQ1aFxYO/Po9ufPdOzV3R2vo0IbbW/dXZaXn7vXss1qnp2utlPH+7LP9KzNunNaXXaa1yWTYdvHFWn/yieNyHR1aT5yo9UUXdU9vbmvWy/KX6bf2vNWrzGB/98BW7aBN9UaP4DO6egWZQH7PE5RSuVrrVdbPWe6UEQTBPZramrj02Es5KeUk1q0zhiIOHDBWBCkF//kPnHjiwK9f01zD5uLNDvPsncomTBj4Peyx1FsIbzLTjuM9BsaPNzbKue02Y03+QHG0rPP662HPHjj/fGPNv1Jd70rB22/DAw90BdorLjZe06fD6tXGuzOUgrlz4YknoK6ua54mMiySx7c8TnNbMxcec+HAK9QPPD5HoI1J4EzrhK9Jd00A51vfZwMrlVLblFLbgCRnZQRB6D8JwxJ49YpXqdv2w26RRFtbjcZn797BXT8tIY2qpiqHk5neCDMx//j5XDthOTE9dtyMjTUa4R/+EP73f2HiRFiwAD79tOscZ45bNrQ2GvqnnoJFi3ov62xuht/8Bk4/3dh4Z+ZM+K//ghkzjNVWd9/tONpqWZlrEbAxb55xj3y7R1+lDF8CX+5L4BWHMtvTPrDRLm2O9X0jMNGdMoIgDBxH69Wbm430wewgZltCerD6YK8d0LwRZuLiyRdz8WRIOwr33QegSU9XrFjRVY+HHjK8o9esgZdegjPOMBrqNWt6O27t3Ws8fX/0EXz4IRw96vr+SsG//gUdHV0DUrbPl15qvPfE3b1zzjgDEhLgjTcMhz4bvt6XQDyLBSHIWL9zPXe8cwelVVuA3tHiBrvBl70vQU8hGDXKePdkj+Cbo9+QGpfKSScZy5vWrt3GDTdkdztn3Dhjdc4998Bf/2rso/yhg3A9DQ02MTGWcl54odEYn3668dnR3yYtzRgackRammO/AHejr0ZGwkUXwZtvQns7hFtX5WYkZPBB0QfuXcQDiGexIAQZh2sPU1pfyvhRJof5gw0RPcE0gQsmXcDwqOG98iIjYeRIz/UItNZkrc7ioQ8foqTESBs5stnp+fHxxlzB3r3Gk7wjlDI23Pn+e/j73+HGG+H44+F3v3O9rNMRK1b0v0xP5s41eiVbtnSlZZgyUEr5bF8CEQJBCDIs9Raiw6P53b3xg26kHDE6fjT/Wvgvzko/y2G+2ey5HkFtSy3N7c2Yh5spLoaoKEhIaO2zXESEc8FLS4PRDiI9L1xoDCU5C7jniIGU6ckFFxj2vv56V9ptM2+jclkl8dHx7l9oEIgQCEKQYWkwnMmuvlqxxm7/+oE0Uq7QTraOTE31XI/APpx2SYmxh7KzJ/2eDORpfeFC2L/fmAPYv9+9v9VAytiTmAhnnmnME9hw5rntLUQIBCHIsPcqPu88I+2xxwbWSDnjig1XcN6z5znM82SYidI6o2thLwTu4omndV8xb57h8V1oja/Q3NbMwlcW8uLXL/rk/iIEghBk5KTncNlxlwHGmnYwJlM9SVR4FHsrHK9DtYWZ8MRe8456BP1hsE/rvmKuNWK4rVcQFR7FG7vf4KMDH/nk/iIEghBk3Hn6ndx15l2A94QgbUQaxTXFtHe098ozm43VOXV1g7/PyaNPZu3ctUwwZVJc7Pl6DBUmTjQmrG3zBDZfAl/tSyBCIAhBhNaa1vauyVSvCUFCGm0dbRyp6z0GZPMl8MSEcYYpgxuybkA3JdDY2P8eQSAxb57h9V1VZRxnmDJ85ksgQiAIQURdSx1RD0Tx2KePAYYQRER0bSPpKVztS2DzLvbEPME3R7/hyyNfdi4dDWYhmDsX2tqMsBXQJQTOJuU9iQiBIAQRtjF10zATYAjBmDFdjkqe4rhRx3HDyTc4DJXsyR7B/e/fzxUbrujs2QSzEJxyiuGQZxseOm7kcaQlpNHQ2uC6oAcQIRCEIMJ+chXw2rh6himDtfPW9vIsBs+GmSitK+2cKIbgnSMAQ6wvvtgIZ9HaCjfPuJmdN+906LjnaUQIBCGIsAnBqFgj1kNJifcazw7d4dDzdeRII8ibJ3oEtqWwNiFw5AgWTMybZ8wROAqP4U1ECAQhiLDvEWjtvR4BwIy1M1j4Su/1mOHhxhCHJ3oE9kKQkmJ4Fgczc+YYdXzjDSOc+JlPn8lftv/F6/cVIRCEIOKElBO4febtpAxPobra2CvXW0IwJn6M003sPRFmoq2jjfLGclKGp1BcHNzzAzbi4uDcc415gqiwaHaU7uDLI196/b4SfVQQgojTxp/GaeNPA+A7Ly0dtZE2Is2pw5Onwkz8a+G/mGCawGslgw+WFyjMmwc33wy7dysmmCb4xJdAegSCEESUN5TT2NoIeM+HwEZaQhqVTZUO5wk80SOICIvggkkXMGXklAF5FQcql1xivL/+uu98CUQIBCGIWLBhAXP+bw7gGyEAOFhzsFeerUcwmCXwxTXF/OPbf2CprqGsLHSEYNw4yMrqLgTe9iUQIRCEIMJSb2HUcGPFUHGxsXrHtpzT02SPyeb+nPtJiE7olWc2G7uhVVcP/Prv73+fS1+4lB2Fh4HQEQIwnMs2b4bJcdmcmXYmTW0O9sP0ICIEghBEWOotpMR2+RCYzcZmMd7gmORj+PWsXzN2RO8W2hNOZbYVUC2VRn2C2YegJ/PmGb2p2L1X89bCt4iJjOm70CAQIRCEIKG9o52yhjKvO5PZc6TuCCU1Jb3SPRFmwlJvITIskupSExBaPYKTTzbqa79HgTcRIRCEIKGisYIO3eFTITjlL6fwq/d+1SvdUz2ClOEpHDpk7EQTSkKglDE89PZ7DaQ/msGjmx/16v1ECAQhSIgKj+KROY9wZvqZgG+EIC0hzWuB52w7rRUXw/DhMKJ3WKOgZu5caKiOpaK+mu8rv/fqvdzyI1BKTdNaf6GUygBygQ1a6/3eNEwQhP6RMCyBxactBqC21pio9YUQbD64uVd6crLhYTyYHsGj5z9KbXMtD75n1MPdLSqDhXPOMbbWHNbk/SWk7vYIFlnfXwI+B1Z7xxxBEAZKWUMZeyv20tbR5rMgbc42qAkLG/yWlZOSJnHy6JNDyofAnmHD4Pzzoa4kg31V+7x6L3eFIFkpdQ5QqbV+DxjEojBBELzBczuf45g/HUNlY6XXfQhspCWk0drRSml970f/wTiVaa15cuuT7CjdETLhJRwxdy40HZ5AYYV3fQncFYLVwHwgz3q8xTvmCIIwUCz1FsJUGEkxST4TgnMzz+WpeU8RFxXXK28wYSbqW+u5+Z838/Z373DoUOgKwcUXA0WzOKH9aprbm712H3eFIBNQdA0RzfCOOYIgDBRLvYWRsSMJDwvvFIIxY7x7z8nJk/npyT91uEHNYHoENh+CYR0ptLWFlg+BPSkpcGriD+GN1QyLGOa1+7grBLO11jfZHVe6OlkplauUmq2UynORn98jrVIpla+UWuqmTYIg2GFbZQPGiqFRo4xxZm+iteazks/4rvy7XnmpqYYQDGREwyYEqt6oT6j2CMBwLtu2vZ3vi7znXeyuECil1GWAyfru6sRcAK31Ruvx7J7naK03OCg6X2s9R2u9yk2bBEGww7buHnyzdBRAKcWc/5vDn7b8qVee2WzstFXp8rHRMaV1RleitVqE4NwL6+HuGO7c8JjX7uGuECwDJmIMDyX16B30ZAZQaP1cCGS5eQ+TUirTzXMFQejBXWfcxZJTlwC+EwJw7kswmC0rbT2CxjIRguwfDCesLZ5t3+/32j3c3Y/gIeBGrXWNG+eaehwnu3mPJKBCKbVaa72oZ6Z1mCkPwGw2U1BQQF1dHQUFBW5ePvgI5fqHct3Bcf2HY+xtW1BSwL59p5OebqGgoPeQjacZ3jacb0q+6WXP4cMmYBrvvPMFFktVv645rn0cf5/xd955roWwMM2uXe+zZ4+RF4rf/YiOsRysK6SsrNE7ddda9/nCWDVUDjwBPAg86OLclRhzCgCzgZVOzst3UT7XlT3Tp0/XWmu9adMmHcqEcv1Due5a965/S1uL3rRvk7bUWXRDg9ag9YoVvrHl5jdv1kkrk3qlf/ONYcf69QO/9k9+ovW4cd3TQvG7n3LPZZpbjtXQodPTtX722YFdB9iqHbSp/ekRPOTmuZ/R1SvIBPKdn2pgfdrfqrXe7uY9BEGw40jdEc7++9msuWQNZyfcCPh2aKiisYK6lrpuy0gHE2bi+a+ep6W9heLia0J6WAhg3Tr4ftsEOPktAIqKIM+6DGdh7y2jB4RbcwRa630YT/dLgcutx87O3QBkWieJTbpr0rhTEKx52baJZeBFa3qu3TUEQXAT+03rfeVDYGP+8fPJ/3E+UeHdd5ZPTDRCYA9kCena7WtZvW01JSWhu3TUxvLl0LbrIvjP3RDeCkBDg5HuKdyNNfQExpP9KiBXKfWC1voKZ+frrpU/G+3S5th93ggk2h1XAdutLxEBQegn9kLwvY+FYGLSRCYmTeyVrtTAncos9RYmJU3iqxKYM6fv84OZAwcAfQ7sO6d3uodwd9VQktb6Fa31Pq31w9g14oIg+B9HPQJfDam0trfy6q5X+cryVa+8gTqVWeotJEWZqakJ7RVDAGlpABriDkNMeY90z9AfP4JzlFIjlFKXA1WeM0EQhMFytOEo0CUEiYlG6GZfoJQi96VcXvz6xV55A+kR2DbYiW6TpaMAK1ZAjKkOloyB6WsBIyrpihWeu4dbQ0Na6wVKqTuBm4AtWusFnjNBEITBctlxlzHBNIG4qDifR+uMCItgbPxYp/sSbNvWv+uVN5bToTsIbwq9LSodYUwIx3PNV8l0mPaRnm6IgKcmisH9OYJucwJ9zREIguBbMhMzyUw0/DF96UxmIy0hjaLqol7pqalgsUBHhxGa2h1GxY6i9le1PLc+9HYmc8bChfDHtRNQoz9nixe2r3R3+WjPLSFCbIsIQRjabNq3idjIWE4ZdwrFxTBtmm/vn5aQxqcln/ZKN5uhvR3Ky43YR+6glCIuKo6jh4zjUBeC1EdSu4X5Vvcbza95uJkjSwax4YMd7gpBhVLqBmArRgiJCo/cXRAEj7Akfwmpcam8mvtPSkt92yOwb6hsjRQYDdWf0o2G6sgR94Xgk+JPePmbl6k49EsSE5OJifG4yQGFo70eXKUPBHf9CG7C6AXchOEb4CrWkCAIPsYWcO7wYSPapy+FwFVDZXMq68/KoS0lW3hk8yMcOqxDfn7AV7jbI0BrvRZY60VbBEEYAFprjtYfJSXW985kfTGQwHOWegvhKpyjB5JCfljIV7jsESilLlNKjbB+nqaU2qqU+kwpNc0n1gmC0Ce1LbU0tzf7xau4LwbSI7DUWxg1fBQlxWEiBD6ir6GhObor4uhaIBeYg/QMBGHI4M/wEn0xYoSxOU5/ewSjYlMoLZWJYl/RlxBkAiilEjA2rt9vDQfhNNaQIAi+ZdyIcXxy/SecP+l8ioshLs5ogIcCShm9gv4IQV1LHQkRKT6f6xiqmIeb+5U+EPqaI9inlFqC0Qt40i7d5DELBEEYFMMihnHKuFOALh8C5cMF3ubhZocTxraGyrZlpbtsvGYjH37cxplIjwDotkS0oKCAnJwcj9/DZY/AujpoH7BKa/0KgFJqAsaOZYIgDAG+PPIlT3/+NM1tzX5xJjuy5Aj6Xs0fzvuDcbzYOLY1YAMJM3HkkPGMKkLgG/pcPqq1fllr/Z7d8T6t9efeNUsQBHd5Y88bXPf6dSil/CIENqamTkWh2F2+u1t6fwLPNbY28qOXf8S/9xuBi0UIfIPby0cFQRiaWOotmIaZCNNRHD7sPyE4I+0Man9Vy/Co7tHuUlPh6FFoa4OIPlocS72F5756jguaZxMdDcnubnQrDAp3o48KgjBEsTmTlZYa4Rz8JQRR4VG9RACMHoHWUFbW9zVsK6AajqYwdqxv5zpCGRECQQhwbEIwFJaO/t+X/8dNb3YPPNAfpzLbpHPN4RQZFvIhIgSCEOAMJSHYU76Hv2z/C01tTZ1p/XEqs/UIKg6KEPgSEQJBCHDe/fG7/PH8Pw4JIZiWOo123c7Xlq870/rTI2jraCM5JpnSfaPEh8CHiBAIQoAzJn4M4xPGU1xsePEmJfnPlmmp0wD44sgXnWn96RHkTc9j9/VlNNcOlx6BDxEhEIQAprqpmgf+8wBfW772izNZTyYkGruk2QtBXJyxbaa7vgQlJca7CIHvkOWjghDAHKw5yD2b7mFy8mSKi0/we+MZpsKYlT6LMNX9GdNdX4LF7yymuCga+J0MDfkQEQJBCGB6Bpw7/XQ/GwS8+aM3e6W56128cd9GVHUGID0CXyJDQ4IQwNiEYGRMCiUlQzdIm7s9Aku9hbDGFJSC0aO9b5dgIEIgCAGMTQjCm8y0tg4NIdhftZ9pT07jjd1du6y70yPo0B0crT9KR20KKSkQGellQ4VORAgEIYCx7eZVdzQRGBpCYB5uZqdlJ1sPbe1MS001NrBvbXVerrKxknbdTkuFeUjUI5QQIRCEAOa+nPs4tPgQh0qMf+Wh0IDGRMYwJXkKX5Z+2ZlmW0JqsTgvV99azw/MP6DhcLrMD/gYrwiBUipXKTVbKZXnIj+/P2UEQehNRFjEkPEqtmdq6tRuS0jdcSpLS0jjy5u+pPazH4oQ+BiPC4FSKhdAa73Rejy75zla6w39LSMIQm8e/uhhnvnyGUpKjMieKSn+tshgmnkaRdVFVDVVAe47lTU2QkWFrBjyNd7oEcwACq2fC4EsL5URhJBn9bbVvL33bYqLjcYzbIgM9p6RdgZXnXgVdS11gHs9gnU71nHaU6dCdM2Q6dmECt7wIzD1OHYnonifZaxDRnkAZrOZgoIC6urqKCgoGICJwUEo1z+U6w5d9T9cc5iW2Ba+/aqS+PgwCgqGzp5Recl57N2+l73spbk5DDiLzZsLycw84PD8d/a9w5dln0LLcMrKvqSgoNLheaH83Xur7t4Qgiqgv9FO+iyjtV4DrAHIzs7WOTk5Xtu/M1AI5fqHct3BqP/MM2bS8H4DWVOy2FGXSFYWQ+pvorWmrqWO+Oh4AEaMgNjYTHJyMh2e/3zd88SXjKRGh3PRRVM57jjH1w3l794vexYPkM/oesLPBPKdnzqoMoIQ0hytPwrAqNgUv25R6YwrNlzBWX87q/O4L6cyS72F2A5jMkHmCHyLx4XAOhGcaZ3wNdlNAHc27ta8bLtJYodlBEFwTkVjBRFhEcTqFBobh54QTDBN4Juj39DS3gL07VRmqbcQ0ZJCfLzRexB8h1diDWmtV1k/brRLm2P3eSOQ2FcZQRCcMzV1Ks13N/PlDg0MPSGYljqNlvYWvi37lh+Yf4DZDF995fz840cdT9m2UcRJb8DnDJE1BoIgDIQwFcbhknBg6AnB1NSpQNfeBH31CNbMXUPi9hUyLOQHRAgEIUB5Zdcr3PD6DRQdNOI2DDUhmJw8mWERw/jyiOFhbDZDVRU0NzsvU1Ii8wP+QIRAEAKUjw9+zPqd6zlUEkFYWNda/aFCRFgEvzvnd1ww6QKgyz5HE8YlNSWkPZpGyYhXhpyghQKyH4EgBCi2TetLvleMHm14Fg81bj/19s7P9kKQltb9vNL6Ug7WHIS2cOkR+AHpEQhCgGITgqG4dNRGS3sL2w9vp6a5pjPMhKN5gtI6azehPkWEwA+IEAhCgGIvBEO18fys5DOmr5nOB0UfuAwzYdtXQYTAP4gQCEKAEh0RTVpC2pDuEfzA/APAWDlkC4jnaI7AXgiGal2CmSE4qigIgjtsvn4zNTXwRO3QFYL46HgmJk7ki9IviI6GxETHPYIJiROY0n45ezvihkwE1VBCegSCEMAMtX0IHDE1dWq3JaSOegS5x+dyStEGxoxWQyaCaighf3JBCECONB3hwnUX8s6uj4GhLQTTzNPYW7GX2uZap05lWmtKSoZ2PYIZEQJBCECONh/l7b1vc7DUiPc/lBvQq066ivwf5xMdEe20R3DKX05hy/iFMlHsJ2SOQBACkMoWI1Z/41FjQH3MGH9a45pJSZOYlDQJcB5m4lDtIRprT2TsEBa0YEaEQBACkKrWKgBqDqeQkgLR0f61py82Fm6kpb0Fs/kiamuhoQFiY408rTWWegtt1SmMPcW/doYqIgSCEIDYegTlB0cO6WEhG7/74Hc0tDawKPUiwBgemjDByKturqa1oxXqzAFRl2BE5ggEIQCJCY8ha3QWhw5GBUTjOdU8lR2lOxiZ0g50nycQZzL/I0IgCAHIgvEL2Ja3bUg7k9kzLXUajW2NtMR9B3SfJ4iJiOGcuJ+B5UQRAj8hQiAIAUp9PVRWBo4QAFjCDH8C+x7B+ITxnNP0v1A6dUhPegczIgSCEIDc/dXd/Ort+4HAEILjRh1HZFgk+5sMIbDvETS2NnKgpJXkZIiJ8ZOBIY5MFgtCAPJVzVckRxlxfAJBCKLCo9h1yy7STek8NbK7EKz6aBVrUn7DSeOakSbJP8hfXRACjLaONmpaawhrNHwIAkEIACYmTQR6h5mw1FsIb0lk3BhpjvyFDA0JQoBR3lCORtNRawhBoEyw7izdyS3/vIWk8Ue79QgsDRZZMeRnRAgEIcCwLbdsrkghKanLMWuoU9ZQxp+3/pmIcZ936xEcqS2lvUbCT/sTEQJBCECmJkyl8XBGQDWeU1OnAtA28otuPYJD1dIj8DciBIIQYJxkPok/TvsjdXuyA0oIkmKSGD9iPLXDv6ShAeqMeHnMHX0zfHWFCIEfESEQhABlKG9R6YxpqdOwhH0BdK0cOj38Vth1ecDVJZgQIRCEAON3H/yOn2z5KRaLDqgeARhCoMOaIKyN0lJjc/sdB4ogvCXg6hJMeEUIlFK5SqnZSqk8d/OVUpVKqXyl1FJv2CQIwcK+yn1Ut9QBKuAaz/ty7uNfF34PHREcOQLfHP2GB+oyiDzhTRIT/W1d6OJxIVBK5QJorTdaj2e7mT9faz1Ha73K0zYJQjBhabAwnCQgcHwIbISpMMxm43NpadcKqFGxKSjlR8NCHG/0CGYAhdbPhUCWm/kmpVSmF+wRhKDCUm8hqnUkEHhCALD042tRs37LkSNdQjA2wexnq0Ibb7jymXocJ7uZnwRUKKVWa60X9byodRgpD8BsNlNQUEBdXR0FBQWDNjhQCeX6h3LdD5QdYFiD8fy0b98HWCztfraof3xetJ3wyd/z+efXU3aMsedyrMbt7zOUv3tv1d0bQlAF1n5rP/K11msAlFJVSqlcrfUGB/lrALKzs3VOTg4FBQXk5OR4yOzAI5TrH8p1v7j2Yj57fQLx8XDxxWf625x+M6thFt+UP4MqTSUuNR72RDFj6iRyco5xq3wof/feqrs3hOAzup76M4H8vvKtT/tbtdbbvWCPIAQFqY+kUlpvdckdByy+C3U/mIebObLEwUbAQ5Sp5ql0RNZyoGY/i1Ln8fDbGYy7WiYI/InHhUBrvUEptdQ6CWyymxTOt04G98pXSpmATLuJ5A3O7yAIQ4tuDbQdnm6gHd3DVfpQxbY3waGOLxjXcRlsPZ1xv/SvTaGOV8L92a382WiXNsdZvta6CthufYkICAFFsDTQvuLElBMZ034qlvJIPtizA+KTGSveZH5F4r4Kgh39fbqvaa7xhVkUVRX55D6+ICYyhjsSPmbJ13DPrnQ4N4exY//ub7NCGhGCIGcgwxa+GOrwiF3ve94uV0/3hZWFZCZmcrD6IFe9fBXfVXzXtfG6F3nhqxdY9GavhXQBTWoqoDqobbdAQ4pxLPgNCTER5Lhq2Opb6qltrqW6qRqtNQC1zbU+GeoYyD38PQSzeutqABJjEokIi2De5Hk8dO5DLsvsq9w36Pt+c/Qbjh91/KCvM5TYoZ6Be8NpD2siXpmJjPS3RaFNSPQIfDWZF2jEPRjX+blpeRPREdEs//dyP1pk8IfNfyAzMZNLj70UgEc+foTqpmr/GgXclH0TAHFRcRT8pKAz/ZfvOZ/pPP7Px/PL03/J0tOXEhPp/oa8W0q20NjayKyMWdwz6x7umXUP4/4wzunvONDITDHDd8bn5GEp/jVGCA0h8PeT5FBl1exVhKkwwlQY4WHhACw4YQF/2vInv9q1+N3FXDL5km5C4O0hmO2Ht/M/n/6Py3MmJE5wmG4ebnb4WxoVO4pzM8/lvvfvIyIsguVn9S2y7R3tPPThQ9xbcC8zxs7g4+s+JiLM+De1PbQ8+ijccQeUl0OSK4+dIcwZx0yDj4zPqfEiBP4mJIRAcMydp9/ZK+2MtDNclpn5l5n86oxfMW/KPNQAgsPsq9zHqo9ch5OqWlZFVHhU5/GhxYcIU2Go+53fb95z87h95u3kZOT0y669FXu5+99388LXL5AUM7BWta9e5aLpi5g+ejoAWw9tJXFYYuf+vfYcrD7I1a9ezX+K/sOVJ17JExc/4bAuxcUQHd1OYmL4gOz1Nz176J9MujAg/SGCCRECoV9UNlVy6QuXctr401g5e2WfwmFj19FdPPjhg6zfub6z9+GMhGEJ3Y7DVN9TWZ8Uf8I5z5zDVPNUbpt5GwtPWkhkuPOB58bWRpa8u4Q129cQFR7F8jOXc+dpdzLl8SkeH37JycgBQGvNz/75M3aU7iAiLIL61nqH5//90r/z4x/82KmgFRfDqFHNKBUge1T2QHroQw8RgiAnNjKWhtaGXumuGjZnQx3m4Wa+uvkrnv7iae4ruI8znz6TuZPn8vKClxn/6HinZT6+/mNO+PMJxETG8ItTfsHiUxczfc30fje4ruzaf9t+1u1Yx6OfPMovN/6Sq068CnA9PzQxaSI3Zt3IPWfdw+j40UDfT/eDQSnFq1e8yp35d/LcV885Pe+aqde4vI5NCCAwhUAYeogQBDH7q/bT1tHGtVOv5W+X/s3tcn01hnnT87j6B1fzp0//xP6q/USGR7p8ystMzOSv8/7KJZMvYdTwUW7doy+7HMVcuT7req47+ToOVB8gOiKato42l3YV31HcOf7uK8aOGMv6y9e7FIK+KC6GKVOaPWiVEOqEhBA4e5KMiXB/FUcgsrtsNynDU3jgnAc8fu3YyFiWnbHM7fN/evJPPW6DI5RSpJvSAahvcTz0YsPXIuAJnn0WDhyAAwfMZGTAihWwcKG/rRICncD7TxgAjp4+l7y7hOqmajp0h1tj0IHI+ZPOZ9+t+wKywfMEPecavMm6dbB8udFIp6V5p4Fetw7yuvb0o6io61jEQBgMwdkCusGqOatYM3cNYSqs05lqMKQ+koq6X/V6pT7ie5dJrTVv7H6D9o72AYvAunWQkQFhYcb7unUeNXFI09+62xrooiLQms4G2lN/s6oqeP11uPlmaGzsntfQYAhQQFHnZB7IWbrgdUJWCMJUGEopvjn6Daf+9VT2V+0f1PWG0kqIN/e8ybzn57F+53pg6DVs9vfpr9jYypxzziyvCJSrure1QUkJbN0Kb7wBq1fDfffBTTcZDbI9DQ1w223w1VfQ7GA439mkuHm4mZoa+Oc/YckSyM6G5GT44Q+httaxzQcODKrKPif9pSNwn+71Sn9Jlo76i5AZM3DWdQ9X4Xxb9i0/fP6HfHTdR8RFxfV9sSFMW0cbSzcuZXLyZK488crOhs3WUBUVwfXXw+7dMMcaD1brrhcYzkqOGrbly50PQbha0eMIR3bdeCPU18Pll0NHR3e7tIaXX4alS21Pxe4Njbhrl9aGg9aSJY7rfs018OMfd/2N3KGsDE46yRC6zEw49lg47jjjdVPdEVat6v6EHxEBseMhcZlR/6goOPVUuOceOPts4/4HD/a+T1qa+zYNBVas6P7dA8TGGumCfwgJIXDU6HQ1IFN4IfcFLlp/Ede8eg0bFmwI6DmDv2z/C9+WfcurV7xKZHgky5f3btiam+G3vzVe/aGoCG691WjIbI1aSgooZczDuBonr6iA774zXnv3wsMP97arsREWLTJe7tLQANddBy+8YAQyGz3aeLd9/mXEEZav6n6v6Gi46EeGqHz/PRQWGu/OnrjBaJjvvde4pv3LbIZjjjH+Nj0ZPRp+/3v49lvYtct4z8933EMAo8dx6BDcdZfR8J96KsTYrWd48MHgaEBtvwlvz6kI7qM8MT7ua7Kzs/XWrVvd3rYtI8PxP2p6Ouzfb3x+dPOj3PHuHfz6rF9z/9n399smV16v+l7v/I171r+2uZZJf5rElOQpvP+T9ykrU6Q48d5XCt5913i3HdteV14JpQ5GtKKiIDLSeGq3kZhoCEJkJHz8MbS2duWFhxt/48pK42V/b1c/u8ce626P7XXzzc7LTJ0Khw/D0aPuP7VHR8OECcbT+sSJxmvFCuMaPbH/rfSk54MGGA30mjW9G7f2dti3DyZPdmynUoboOKNLbDVpaSokG1DZqjJnwOWVUtu01tk900OiR+BsDLWoyGigEhPhtpm3scOyg037N3F3+90uvVIB6lrquOu9uxgTP4ZfnuF6e6X2jvY+vWk9wcGagyTFJLHy3Ed48knFXXc5PzctDWbPdpz3+987b9iuuspYx257yrW9PvigdwPW3m484V57rfHUbHtNmGD0KJyJ889/7tiuhx5yXuaLL4zPbW1gscCRI4YwXHKJ42spZdQvrEfnb+TI/j919+cJNzwcJk0yznFUl76GeRYuNF4FBe+HbGMoeAGtdcC9pk+frrXWetOmTdod0tN7jjZ3vaKitL7sMq1feUXr6rom3dzW3Of13v7ubZ3+aLpW9ym9+J3FWmutw5aaNffR+3Wv0kveWeKWnf3FUf0/3tyus7KMup19ttYrV2odG9u9zrGxWj/7rOtrP/us8XdTynjv63ylHP99lXJ+/f7aNZAyzr779HTP1X0gDKQu9rj72w9GpO4DB2Nv+F5tqt8b9YG8+isEzv7pfvtbrW+7TWuz2UhLTNR60SKt3/x3mb765R/r//3bkW4NwpN/L9fXvnqt5j70hEeO1cuf/FDfeqvWZ53lXGi46BbNfehnvnjGvW+qH9jX/++fvqqvubFGg9Zjxmj9/PNad3R01d/bDZuvGtyuMh1ulRlsg+tNBvO9SGMYmogQDEIItHb9T9faqvW//qX1woXWRiN1u+ZeB0/396G5Fx0+Z7kmorGzUZk5U+u4OCdCENai1U9zdNivo/XD6z/VzX13OPpRlw6dlqb1D/N2aO5VWs2+Sy9ZonVNzeDvMRCbfNngeuq7D1SkMQxNvCUEgbs8pp8sXGhM9nV0GO/247cREXDBBYb7fmkpPLPqZHA296vg9qkPsO7vw/jmG6ipgc2b4cknjbFke2Jj4f57I7k+/iWoS+XOrf9N6qTD3HKLUUbrwa7xVxw4AP+oX0pYawIfrlrMww9DfPyA/0wDZuFCYw4hPd0Yf09PdzxZ6g9cffeCIITIZHF/iIsz1mtf42Lh0MMP905zPWE4kptKXmfxKysZeWYcTz0Ff/6zsfSysrJrpY1tLX11tTGRW1PT+3X33T2WXWbmwzFvM2LLI5y2wr+7lNgmMgVBCCxECDyIq4Zw+tgfUPDzdfBzOFrRzJv/iOLmm1W35ZZgrKW/5RY3b6ja4bw7oTKDqnf/36BsFwQhdBEh8DEVjRWc99K5XDv1WlpabnN63rPPwogRkJBgvNte06fbLYcdVgUNI+HDX5I+NtoX5guCEISIEPgY0zATGaYMFr+7mFGnnIjlk96L+dPTnfcsqm9MhfYe3l6Z71EVfhsgsVoEQeg/ITNZ3F9cBQUbDGEqjGcufYbjRh5H/UULGDZmb7f8vpyXqnuKQB/pgiAIfSE9Aid4c8vC+Oh4Xr/qdSY9Ngmdd0y3vAZg8WEzC3s83W8+uJnNxZu9ZpMgCKGLV4RAKZULVAGZWus17uT3VSbYyEzMROM4KE5pfSm/3vRrDtUe4i/z/gLAQx89xOu7X/eliYIghAgeHxqyNuhorTdaj2f3ld9XmVBkxQcr+KT4E5rbjFCVj57/KJYlFj9bJQhCMOKNOYIZQKH1cyGQ5UZ+X2VCjrpf1fHVz74iOsJYDZSZmNm58bsgCIIn8cbQkKnHcbIb+X2VQSmVB+QBmM1mCgoKqKuro6CgYKB2Dmk+/ehTh+mJkYlUtlY6TA/Wv4Ujgvm7d4dQrr/UvcDj1/WGEFQBrlxcHeX3VQbrvMEaMPYjyMnJCfy45O87z3JWr4qcis7PAV//QRDKdYfQrr/UPcfj1/XG0NBndD3hZwL5buT3VSYo8dYSVUEQhP7g8R6B1nqDUmqpdcLXZDcBnK+1nuMiv1dasOPNJaqCIAju4pXlo1rrVdaPG+3S5vSR3ytNEARB8D7iWSwIghDiiBAIgiCEOCIEgiAIIY4IgSAIQoijjG0sAwul1FGgCBgJlPnZHH8SyvUP5bpDaNdf6j5w0rXWvUIUBKQQ2FBKbdVaZ/vbDn8RyvUP5bpDaNdf6u75usvQkCAIQogjQiAIghDiBLoQBP2+BX0QyvUP5bpDaNdf6u5hAnqOQBAEQRg8gd4jEARBEAZJwAqBUirXurtZnr9t8TVKqUqlVL5Saqm/bfEV1u8730FaSPwGnNQ/6H8HSimTUirLWv+VdulB/927qLvHv/eAFALZ2pL51kiuq/o+NTjQWm+wPw6130DP+lsJhd/BAiDbVn+lVF4Iffe96m5N9/j3HpBCgGxtaVJKZfrbCD8T6r8BCIHfgdZ6jXVTKjD2KikkRL57J3UHL3zvgSoEph7Hvba2DHKSgAql1Gp/G+JHTD2OQ+03ACH0O7A2fBXWXoCpR3ZQf/c96g5e+N4DVQiq6GNry2DG+qRQBVTZuskhSBUh/BuAkPsd5GqtF1k/VxFa37193b3yvQeqEITk1pbQOUYalF3hfhKyvwEIrd+BUirXNh5urXPIfPc96+6t7z0ghcA6eZIZaltbWnkRuk2WOppEDDqs33V2j3qHzG+gZ/0Jkd+Btd4rlVLblFLbgKRQ+e4d1R0vfe/iUCYIghDiBGSPQBAEQfAcIgSCIAghjgiBIAhCiCNCIAiCEOKIEAiCIIQ4IgRCUDFQBxul1GqllMnu2OTqWtbAXyuVUi9ZXyYn52XZBwxzco7JujzQHTvzgji2juAnRAiEoMHaQG4fYPF8jCBfAFg9N23u/Y4o1Fov01rPB1YDax2dpLXerrVeNkCbBMEniBAIwcQcrXUhdD5lr7aG6zVZ05wG6rI65sx3kLbIcYneKKUyrfd8ydabsPUIeuQ5tcN6fr61zDa7uuQrpV6yt9GuN5JnPX+2XbrJXbsFIcLfBgiCBzHZfZ5ti89ijedeqLXus7eglMq0iYkVZ412pnXIJ9N63/nWXoTtnvlAT6/PBcAEW2/DFVrrZXaNexawWmu9wRaD3vr+gjVttdZ6kVUA5ljP7fMegmBDhEAISnq43lf1db71Cf4ljIbcfiinwkmRCkdDPtY4MNk4FpAX3WygbUJUbn2fSG9RmQhMVErNoKt+q4GVMhQl9BcRAiEUyAS2Osu0ikCV9enarUlbJ9fJw+gdrMHxkFLVAC+9DaNXUEhXyOVtGGJkLxCLgAeVUnl2cewFoU9ECIRgospJeqHd5K8JeE9rPd16nEVXIDOAF5RSWXbDSM6u6fA+GL0JT8fHfxF4zzrskwRGKGLrnIMtrQJYprUutKZnuTMUJgggQeeEIMI6nl7YY4zfFsp3g92xW42ks+sJQrAhq4aEoMEajtgjsdptq25EBIRQQHoEgiAIIY70CARBEEIcEQJBEIQQR4RAEAQhxBEhEARBCHFECARBEEIcEQJBEIQQR4RAEAQhxPn/Z3E9F2C0I/EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 3:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Divide into three arrays, each with 25 values for each scenario\n",
    "SAP_1, SAP_2, SAP_3 = np.array_split(all_SAP_score_arr, 3)\n",
    "I2_1, I2_2, I2_3 = np.array_split(all_I2_score_arr, 3)\n",
    "\n",
    "# Plot Comparison of I2 and SAP Scores for each scenario\n",
    "print(colored('Scenario 1:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I2_1, SAP_1)\n",
    "\n",
    "print(colored('Scenario 2:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I2_2, SAP_2)\n",
    "\n",
    "print(colored('Scenario 3:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I2_3, SAP_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4752a336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots of Distribution of I2 and SAP Scores Across Scenarios\n",
    "plot_score_across_scenarios(I2_1, I2_2, I2_3, 0)\n",
    "plot_score_across_scenarios(SAP_1, SAP_2, SAP_3, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
