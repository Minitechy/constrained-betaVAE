{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a004ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from adjustText import adjust_text\n",
    "from numpy import pi, e\n",
    "from numpy.linalg import inv, det\n",
    "from numpy.linalg import norm as LA_norm\n",
    "from numpy.random import random\n",
    "from scipy.stats import norm\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "from termcolor import colored\n",
    "import itertools\n",
    "from itertools import combinations, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48c1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(m, n):\n",
    "    return np.random.rand(m, n)\n",
    "\n",
    "def initial_inputs(flag):\n",
    "    if flag == 0:\n",
    "        # Create initial encoder inputs (B, Sigma_W)\n",
    "        B = create_matrix(m, n)\n",
    "        Sigma_W = make_spd_matrix(m)\n",
    "        return np.concatenate(([flag], B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        # Create initial decoder inputs (A, Sigma_Z)\n",
    "        A = create_matrix(n, m)\n",
    "        Sigma_Z = np.diag(random(n))\n",
    "        return np.concatenate(([flag], A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "\n",
    "def is_close_to_zero(arr, etol):\n",
    "    return np.allclose(arr, 0, atol=etol)\n",
    "\n",
    "def is_singular(matrix):\n",
    "    is_singular = np.linalg.matrix_rank(matrix) < min(matrix.shape)\n",
    "    if is_singular:\n",
    "        print(colored('The matrix is singular.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not singular.', 'red', attrs=['bold']))\n",
    "\n",
    "def is_positive_definite(matrix):\n",
    "    if np.all(np.linalg.eigvals(matrix) > 0):\n",
    "        print(colored('The matrix is positive definite.', 'red', attrs=['bold']))\n",
    "    else:\n",
    "        print(colored('The matrix is not positive definite.', 'red', attrs=['bold']))\n",
    "\n",
    "def matrix_B(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    B = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A) @ A.T @ inv_Sigma_Z_hat\n",
    "    return B\n",
    "\n",
    "def covariance_matrix_W(A, Sigma_Z):\n",
    "    inv_Sigma_Z_hat = gamma * inv(Sigma_Z) + 2 * lamda * np.identity(n)\n",
    "    Sigma_W = inv(np.identity(m) + A.T @ inv_Sigma_Z_hat @ A)\n",
    "    return Sigma_W\n",
    "\n",
    "def matrix_A(B, Sigma_W):\n",
    "    A = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B) @ B.T @ inv(Sigma_W)\n",
    "    return A\n",
    "\n",
    "def covariance_matrix_Z(B, Sigma_W):\n",
    "    Sigma_Z = inv(inv(Sigma_Y) + B.T @ inv(Sigma_W) @ B)\n",
    "    diagonalized_Sigma_Z = np.diag(Sigma_Z.diagonal())\n",
    "    return diagonalized_Sigma_Z\n",
    "\n",
    "def covariance_matrix_XV(B):\n",
    "    cov_XV = np.block([[np.identity(m), B @ eigenvectors @ Sigma_V],\n",
    "                       [(B @ eigenvectors @ Sigma_V).T, Sigma_V]])\n",
    "    return cov_XV\n",
    "\n",
    "def encoder_mi(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(Sigma_W))\n",
    "\n",
    "def decoder_mi(A, Sigma_Z):\n",
    "    return 0.5 * np.log(det(A @ A.T + Sigma_Z) / det(Sigma_Z))\n",
    "\n",
    "def mi_VX(B, Sigma_W):\n",
    "    return 0.5 * np.log(det(B @ Sigma_Y @ B.T + Sigma_W) / det(sigma_squared * B @ B.T + Sigma_W))\n",
    "\n",
    "def reconstruction_error(recon, orig):\n",
    "    norm_diff = LA_norm(orig - recon, 2)\n",
    "    orig_norm = LA_norm(orig, 2)\n",
    "    recon_err = norm_diff / orig_norm\n",
    "    return recon_err\n",
    "\n",
    "def objective_function(A, B, Sigma_Z, Sigma_W):\n",
    "    Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "    \n",
    "    regularizer = 0.5 * (np.trace(Sigma_X) - np.log(det(Sigma_W)) - m)\n",
    "    reconstruction = 0.5 * (np.trace(Sigma_X) + \\\n",
    "                            np.trace(A.T @ inv(Sigma_Z) @ Sigma_Y @ B.T) + \\\n",
    "                            np.trace(inv(Sigma_Z) @ A @ B @ Sigma_Y) - \\\n",
    "                            np.trace(inv(Sigma_Z) @ Sigma_Y) - \\\n",
    "                            np.trace((np.identity(m) + A.T @ inv(Sigma_Z) @ A) @ Sigma_X) - \\\n",
    "                            n * np.log(2 * pi) - np.log(det(Sigma_Z)))\n",
    "    lambda_term = lamda * np.trace((np.identity(n) - A @ B) @ Sigma_Y @ ((np.identity(n) - A @ B).T) + A @ Sigma_W @ A.T)\n",
    "    \n",
    "    return regularizer - gamma * reconstruction + lambda_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c4fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_function(cf_arr):\n",
    "    \"\"\"\n",
    "    Plot values of objective function against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(cf_arr) + 1), cf_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Cost Function', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_encoder_mi(en_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of encoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(en_mi_arr) + 1), en_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Encoder', fontsize=10)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decoder_mi(de_mi_arr):\n",
    "    \"\"\"\n",
    "    Plot mutual information of decoder against iterations t\n",
    "    \"\"\"\n",
    "    plt.plot(range(1, len(de_mi_arr) + 1), de_mi_arr)\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Mutual Information of Decoder', fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ae4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_optimal_solution(sol, m):\n",
    "    A_arr = sol[:n*m] \n",
    "    B_arr = sol[n*m:2*n*m]\n",
    "    Sigma_Z_arr = sol[2*n*m:2*n*m+n*n]\n",
    "    Sigma_Z = Sigma_Z_arr.reshape((n, n))\n",
    "    Sigma_W_arr = sol[2*n*m+n*n:2*n*m+n*n+m*m]\n",
    "    Sigma_W = Sigma_W_arr.reshape((m, m))\n",
    "    cost_function = sol[2*n*m+n*n+m*m:2*n*m+n*n+m*m+1][0]\n",
    "    en_mi = sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0]\n",
    "    de_mi = sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0]\n",
    "    recon_err = sol[-1]\n",
    "    len_cf_mi_arr = sol[2*n*m+n*n+m*m+3:2*n*m+n*n+m*m+6]\n",
    "    Sigma_X = sol[2*n*m+n*n+m*m+6:2*n*m+n*n+2*m*m+6].reshape((m, m))\n",
    "    Sigma_Y_hat = sol[2*n*m+n*n+2*m*m+6:2*n*m+2*n*n+2*m*m+6].reshape((n, n))\n",
    "    \n",
    "    print(colored('At optimal solution:', attrs=['bold']))\n",
    "    \n",
    "    if m > 1:\n",
    "        # print('Matrix A:\\n{}'.format(np.round(A_arr.reshape((n, m)), 4)))\n",
    "        # print('\\nMatrix B:\\n{}'.format(np.round(B_arr.reshape((m, n)), 4)))\n",
    "        # print('\\nCovariance matrix of Z:\\n{}'.format(np.round(Sigma_Z, 4)))\n",
    "        # print('\\nCovariance matrix of W:\\n{}'.format(np.round(Sigma_W, 4)))\n",
    "        # print('\\nMinimum value of the cost function:\\n{}'.format(round(cost_function, 4)))\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 4)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 4)))\n",
    "        # print('\\nValue of Sigma_Y_hat:\\n{}'.format(np.round(Sigma_Y_hat, 4)))\n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "    else:\n",
    "        print('Vector a:\\n{}'.format(np.round(A_arr.reshape((n, m)), 4)))\n",
    "        print('\\nVector b:\\n{}'.format(np.round(B_arr.reshape((m, n)), 4)[0]))\n",
    "        print('\\nCovariance matrix of Z:\\n{}'.format(np.round(Sigma_Z, 4)))\n",
    "        print('\\nVariance of W:\\n{}'.format(np.round(Sigma_W, 4)[0][0]))\n",
    "        print('\\nMinimum value of the cost function:\\n{}'.format(round(cost_function, 4)))\n",
    "        print('\\nMutual information of the encoder:\\n{}'.format(round(en_mi, 4)))\n",
    "        print('\\nMutual information of the decoder:\\n{}'.format(round(de_mi, 4)))\n",
    "        print('\\nValue of Sigma_Y_hat:\\n{}'.format(np.round(Sigma_Y_hat, 4)))        \n",
    "        print('\\nReconstruction error:\\n{}'.format(round(recon_err, 8)))\n",
    "        \n",
    "    return len_cf_mi_arr\n",
    "\n",
    "def print_comprehensive_results(gamma, lamda, flag, m, n, is_arr):\n",
    "    if flag == 0:\n",
    "        # Generate random initial encoder inputs (B, Sigma_W)\n",
    "        B, Sigma_W = initial_inputs(flag)[1:1+m*n].reshape((m, n)), initial_inputs(flag)[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "    else:\n",
    "        # Generate random initial decoder inputs (A, Sigma_Z)\n",
    "        A, Sigma_Z = initial_inputs(flag)[1:1+n*m].reshape((n, m)), initial_inputs(flag)[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "    \n",
    "    # Print given inputs\n",
    "    if is_arr == 0:\n",
    "        if m > 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial matrix B:')\n",
    "            print(np.round(B.reshape((m, n)), 4))\n",
    "            print('\\nInitial covariance matrix of W:')\n",
    "            print(np.round(Sigma_W, 4))\n",
    "        elif m == 1 and flag == 0:\n",
    "            print(colored('Given encoder X:', attrs=['bold']))\n",
    "            print('Initial vector b:')\n",
    "            print(np.round(B.reshape((m, n)), 4)[0])\n",
    "            print('\\nInitial variance of W:')\n",
    "            print(np.round(Sigma_W, 4)[0][0])\n",
    "        elif m > 1 and flag == 1:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial matrix A:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))\n",
    "        else:\n",
    "            print(colored('Given decoder Y_hat:', attrs=['bold']))\n",
    "            print('Initial vector a:')\n",
    "            print(np.round(A.reshape((n, m)), 4))\n",
    "            print('\\nInitial covariance matrix of Z:')\n",
    "            print(np.round(Sigma_Z, 4))    \n",
    "    \n",
    "        # Print results\n",
    "        if flag == 0:\n",
    "            # Compute optimal solution given encoder inputs\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "    \n",
    "            # Extract length of arrays for cost function and mutual information of encoder and decoder\n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            # Plot values of cost function and mutual information against iterations\n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)  \n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "        \n",
    "            len_all_arrs = print_optimal_solution(opt_sol, m).astype(int)\n",
    "            len_cf_arr, len_en_mi_arr = len_all_arrs[:2]\n",
    "            len_cf_en_mi_arr = len_cf_arr + len_en_mi_arr\n",
    "        \n",
    "            cf_arr = opt_sol[2*n*m+2*n*n+2*m*m+6 : 2*n*m+2*n*n+2*m*m+6+len_cf_arr]\n",
    "            plot_cost_function(cf_arr)\n",
    "    \n",
    "            en_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_arr : 2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr]\n",
    "            plot_encoder_mi(en_mi_arr)\n",
    "    \n",
    "            de_mi_arr = opt_sol[2*n*m+2*n*n+2*m*m+6+len_cf_en_mi_arr:]\n",
    "            plot_decoder_mi(de_mi_arr)\n",
    "    else:\n",
    "        if flag == 0:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            \n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 8)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 8)\n",
    "            recon_err = round(opt_sol[-1], 8)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]\n",
    "        else:\n",
    "            opt_sol = rate_distortion(initial_inputs(flag), is_arr)\n",
    "            \n",
    "            en_mi = round(opt_sol[2*n*m+n*n+m*m+1:2*n*m+n*n+m*m+2][0], 8)\n",
    "            de_mi = round(opt_sol[2*n*m+n*n+m*m+2:2*n*m+n*n+m*m+3][0], 8)\n",
    "            recon_err = round(opt_sol[-1], 8)\n",
    "            \n",
    "            return [recon_err, en_mi, de_mi, opt_sol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fbe240",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "*****************************************************************\n",
    "**                          ALGORITHM                          **\n",
    "*****************************************************************\n",
    "   \n",
    "Inputs:\n",
    "- MAX_ITERS: Maximum number of iterations\n",
    "- n, m: Dimensions of the matrix\n",
    "- TOL_ERR: Tolerable error\n",
    "- Sigma_Y: A random nxn positive definite matrix\n",
    "\n",
    "Algorithm:\n",
    "1. Initialize flag\n",
    "    a. If we start with the encoder, set flag = 0.\n",
    "    b. Otherwise, set flag = 1.\n",
    "    \n",
    "2. Generate initial inputs for the iteration step\n",
    "    a. If flag = 0, then do:\n",
    "        i. create random initial encoder inputs, including \n",
    "            - a random mxn matrix B\n",
    "            - a random mxm positive definite covariance matrix Sigma_W\n",
    "        ii. set flag = 1.\n",
    "    b. If flag = 1, then do:\n",
    "        i. create random initial decoder inputs, including \n",
    "            - a random nxm matrix A\n",
    "            - a random nxn positive definite covariance matrix Sigma_Z\n",
    "        ii. set flag = 0.\n",
    "        \n",
    "3. Set iteration counter i = 0. \n",
    "\n",
    "4. Iterative step\n",
    "    a. If flag = 0, given the decoder inputs (A, Sigma_Z) at iteration i,\n",
    "        i. compute the corresponding encoder inputs at iteration i+1:\n",
    "            B = matrix_B(A, Sigma_Z)\n",
    "            Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "        ii. set flag = 1.\n",
    "        iii. compute the resulting gamma-VAE cost function and mutual information of the encoder.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "    b. If flag = 1, given the encoder inputs (B, Sigma_W) at iteration i,\n",
    "        i. compute the corresponding decoder inputs at iteration i:\n",
    "            A = matrix_A(B, Sigma_W)\n",
    "            Sigma_Z = covariance_matrix_Z(B, Sigma_W, is_diagonal)\n",
    "        ii. set flag = 0.\n",
    "        iii. compute the resulting gamma-VAE cost function, mutual information of the decoder, and reconstruction error.\n",
    "        iv. check if the cost function is NaN:\n",
    "            - if it is, conclude that the algorithm fails to converge and skip to step 7.\n",
    "        v. check for convergence after the second iteration:\n",
    "            - if converges, conclude that the algorithm converges and skip to step 7.\n",
    "            - unless, check if the maximum number of iterations has been reached:\n",
    "                - if it is, conclude that the algorithm failed to converge and skip to step 7.\n",
    "                - otherwise, move to step 5.\n",
    "            \n",
    "5. Increment iteration counter i <- i + 1.\n",
    "\n",
    "6. If the iteration counter i < MAX_ITERS, then move back to step 4.\n",
    "    Otherwise, move to step 7.\n",
    "    \n",
    "7. Compute the values of Sigma_X and Sigma_Y_hat.\n",
    "        \n",
    "8. Display results\n",
    "    a. display the optimal solution (A, B, Sigma_Z, Sigma_W).\n",
    "    b. display the corresponding minimum value of gamma-VAE cost function.\n",
    "    c. display the resulting mutual information of both encoder and decoder.\n",
    "    d. display the values of Sigma_X and Sigma_Y_hat.\n",
    "    e. display the value of reconstruction error.\n",
    "    f. move to step 9.\n",
    "    \n",
    "9. Stop.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def rate_distortion(inputs, is_arr):\n",
    "    flag = inputs[0]\n",
    "    if flag == 0:\n",
    "        B = inputs[1:1+m*n].reshape((m, n))\n",
    "        Sigma_W = inputs[1+m*n:1+m*n+m*m].reshape((m, m))\n",
    "        flag = 1\n",
    "        # Array of current encoder inputs (B_t, Sigma_W_t)\n",
    "        current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "    else:\n",
    "        A = inputs[1:1+n*m].reshape((n, m))\n",
    "        Sigma_Z = inputs[1+n*m:1+n*m+n*n].reshape((n, n))\n",
    "        flag = 0\n",
    "        # Array of current decoder inputs (A_t, Sigma_Z_t)\n",
    "        current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "    \n",
    "    # Cost function and mutual information arrays\n",
    "    cf_arr = []\n",
    "    en_mi_arr = []\n",
    "    de_mi_arr = [] \n",
    "\n",
    "    # Iteration step\n",
    "    try:\n",
    "        for i in range(0, MAX_ITERS):\n",
    "            if  flag == 0:\n",
    "                B = matrix_B(A, Sigma_Z)\n",
    "                Sigma_W = covariance_matrix_W(A, Sigma_Z)\n",
    "                flag = 1\n",
    "                \n",
    "                # Check if the value of the cost function is not a number\n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_en_mi = encoder_mi(B, Sigma_W)\n",
    "                en_mi_arr = np.concatenate((en_mi_arr, [current_en_mi]))\n",
    "                \n",
    "                # For the first iteration, update the current encoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. B and itself in the previous iteration\n",
    "                #    ii. Sigma_W and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current encoder inputs and value of the cost function\n",
    "                else:\n",
    "                    B_diff = B - current_encoder_inputs[:m*n].reshape((m, n))\n",
    "                    B_norm_diff = LA_norm(B_diff, 'fro')\n",
    "                    Sigma_W_diff = Sigma_W - current_encoder_inputs[m*n:m*n+m*m].reshape((m, m))\n",
    "                    Sigma_W_norm_diff = LA_norm(Sigma_W_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_encoder_inputs = np.concatenate((B.reshape((m*n)), Sigma_W.reshape((m*m))))\n",
    "                    # Check for convergence\n",
    "                    if B_norm_diff <= TOL_ERR and Sigma_W_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break\n",
    "            else:\n",
    "                A = matrix_A(B, Sigma_W)\n",
    "                Sigma_Z = covariance_matrix_Z(B, Sigma_W)\n",
    "                flag = 0\n",
    "                \n",
    "                current_obj = objective_function(A, B, Sigma_Z, Sigma_W)\n",
    "                if np.isnan(current_obj):\n",
    "                    if is_arr == 0:\n",
    "                        print(colored('\\nThe algorithm fails to converge after {} iterations due to NaN values.\\n'.format(i+1), 'red', attrs=['bold']))\n",
    "                    break\n",
    "                    \n",
    "                cf_arr = np.concatenate((cf_arr, [current_obj]))\n",
    "                current_de_mi = decoder_mi(A, Sigma_Z)\n",
    "                de_mi_arr = np.concatenate((de_mi_arr, [current_de_mi]))\n",
    "                \n",
    "                Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "                recon_err = reconstruction_error(Sigma_Y_hat, Sigma_Y)\n",
    "                \n",
    "                # For the first iteration, update the current decoder inputs and value of the cost function\n",
    "                if i == 0:\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    previous_obj = current_obj\n",
    "                # From the second iteration,\n",
    "                # 1. Compute the Frobenius norm of the difference between\n",
    "                #    i. A and itself in the previous iteration\n",
    "                #    ii. Sigma_Z and itself in the previous iteration\n",
    "                # 2. Compute the difference between the cost function and itself in the previous iteration\n",
    "                # 3. Update the current dencoder inputs and value of the cost function                \n",
    "                else:\n",
    "                    A_diff = A - current_decoder_inputs[:n*m].reshape((n, m))\n",
    "                    A_norm_diff = LA_norm(A_diff, 'fro')\n",
    "                    Sigma_Z_diff = Sigma_Z - current_decoder_inputs[n*m:n*m+n*n].reshape((n, n))\n",
    "                    Sigma_Z_norm_diff = LA_norm(Sigma_Z_diff, 'fro')\n",
    "                    obj_diff = previous_obj - current_obj\n",
    "                    previous_obj = current_obj\n",
    "                    current_decoder_inputs = np.concatenate((A.reshape((n*m)), Sigma_Z.reshape((n*n))))\n",
    "                    # Check for convergence\n",
    "                    if A_norm_diff <= TOL_ERR and Sigma_Z_norm_diff <= TOL_ERR and round(obj_diff, 8) == 0 and \\\n",
    "                    is_close_to_zero(recon_err, 1e-6):\n",
    "                        if is_arr == 0:\n",
    "                            print(colored('\\nThe algorithm converges after {} iterations.\\n'.format(i+1), 'blue', attrs=['bold']))\n",
    "                        break                       \n",
    "\n",
    "        # Compute Sigma_X and Sigma_Y_hat  \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi],\n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "          \n",
    "        if is_arr == 0 and i == MAX_ITERS - 1 and recon_err > MAX_RECON_ERR:\n",
    "            print(colored('\\nMax iterations was reached!', 'red', attrs=['bold']))\n",
    "            print('There is NO solutions that has reconstruction error statisfying the tolerance error = {}.\\n'.format(MAX_RECON_ERR))\n",
    "            \n",
    "        return sol\n",
    "    \n",
    "    except Exception as e:\n",
    "        if is_arr == 0:\n",
    "            print(colored('\\nThe algorithm fails to converge after {} iterations due to {}.\\n'.format(i+1, e), 'red', attrs=['bold']))\n",
    "         \n",
    "        Sigma_X = B @ Sigma_Y @ B.T + Sigma_W\n",
    "        Sigma_Y_hat = A @ A.T + Sigma_Z\n",
    "        \n",
    "        sol = np.concatenate((A.reshape((n*m)), B.reshape((m*n)),\n",
    "                              Sigma_Z.reshape((n*n)), Sigma_W.reshape((m*m)),\n",
    "                              [current_obj], [current_en_mi], [current_de_mi], \n",
    "                              [len(cf_arr)], [len(en_mi_arr)], [len(de_mi_arr)],\n",
    "                              Sigma_X.reshape((m*m)), Sigma_Y_hat.reshape((n*n)),\n",
    "                              cf_arr, en_mi_arr, de_mi_arr, [recon_err]))\n",
    "        return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ee78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Sigma_V(case):\n",
    "    for case_idx in range(num_cases):\n",
    "        if case_idx == 0:\n",
    "            # Case 1: Independent of generative parameters\n",
    "            std_devs = [std_dev_v1, std_dev_v2, std_dev_v3]\n",
    "            V_1 = [np.random.normal(mean, std_dev, size=num_samples) for std_dev in std_devs]\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_1 = np.round(np.cov(V_1), 4)\n",
    "        \n",
    "        elif case_idx == 1:\n",
    "            # Case 2: Linear dependence of v_1 and v_2, with independence of v_3\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            v_3 = np.random.normal(mean, std_dev_v3, size=num_samples)\n",
    "            \n",
    "            # Calculate v_2 using scaling factor alpha and random noise\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            \n",
    "            # Create generative variable V\n",
    "            V_2 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_2 = np.round(np.cov(V_2), 4)  \n",
    "        \n",
    "        else:\n",
    "            # Case 3: Linear dependence of v_2 and v_3, with v_1\n",
    "            v_1 = np.random.normal(mean, std_dev_v1, size=num_samples)\n",
    "            \n",
    "            # Calculate additional generative parameters using scaling factors\n",
    "            random_noise_z2 = np.random.normal(mean, std_dev_z2, num_samples)\n",
    "            random_noise_z3 = np.random.normal(mean, std_dev_z3, num_samples)\n",
    "            v_2 = alpha * v_1 + random_noise_z2\n",
    "            v_3 = beta * v_1 + random_noise_z3\n",
    "\n",
    "            # Create generative variable V\n",
    "            V_3 = np.array([v_1, v_2, v_3])\n",
    "\n",
    "            # Compute covariance matrix of V \n",
    "            Sigma_V_3 = np.round(np.cov(V_3), 4)\n",
    "    \n",
    "    if case == 0:\n",
    "        print(colored('Scenario 1:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v2, sigma_v3) = {std_dev_v1, std_dev_v2, std_dev_v3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_1)\n",
    "        is_singular(Sigma_V_1)\n",
    "        return Sigma_V_1\n",
    "    \n",
    "    elif case == 1:\n",
    "        print(colored('\\nScenario 2:', attrs=['bold','underline']))\n",
    "        print(f'Given (sigma_v1, sigma_v3) = {std_dev_v1, std_dev_v3}, alpha = {alpha}, and sigma_z2 = {std_dev_z2}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_2)\n",
    "        is_singular(Sigma_V_2) \n",
    "        return Sigma_V_2\n",
    "    \n",
    "    else:\n",
    "        print(colored('\\nScenario 3:', attrs=['bold','underline']))\n",
    "        print(f'Given sigma_v1 = {std_dev_v1}, (alpha, beta) = {alpha, beta}, and (sigma_z2, sigma_z3) = {std_dev_z2, std_dev_z3}:')\n",
    "        print(colored('\\nCovariance matrix of generative variable V:', 'blue', attrs=['bold']))\n",
    "        print(Sigma_V_3)\n",
    "        is_singular(Sigma_V_3)  \n",
    "        return Sigma_V_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff45dfc",
   "metadata": {},
   "source": [
    "## I. Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc2f26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mAn array of gamma:\u001b[0m\n",
      "[0.98 0.99 1.   1.01 1.02]\n",
      "\u001b[1m\u001b[34m\n",
      "An array of lambda:\u001b[0m\n",
      "[-0.02 -0.01  0.    0.01  0.02]\n",
      "\u001b[1m\u001b[34m\n",
      "Independent eigenvectors:\u001b[0m\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance of noise Z_tilde:\u001b[0m\n",
      "[[0.0016 0.     0.     0.    ]\n",
      " [0.     0.0016 0.     0.    ]\n",
      " [0.     0.     0.0016 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given:\n",
    "1. Maximum number of iterations: MAX_ITERS = 10,000\n",
    "2. Dimensions of the matrix: s = 3, n = 4, and m = 3\n",
    "3. Tolerable error: TOL_ERR = 1e-8\n",
    "4. Reconstruction error tolerance: MAX_RECON_ERR = 0.05\n",
    "5. A nxn positive definite matrix Sigma_Y = Gamma * Sigma_V * Gamma_T + Sigma_Z_tilde\n",
    "6. An array of gamma = [0.98, 1.02] with step size = 0.01\n",
    "7. An array of lambda = [-0.02, 0.02] with step size = 0.01\n",
    "\"\"\"\n",
    "\n",
    "# Constants\n",
    "MAX_ITERS = 10000\n",
    "s, n, m = 3, 4, 3\n",
    "TOL_ERR = 1e-8\n",
    "MAX_RECON_ERR = 0.05\n",
    "\n",
    "num_cases = 3\n",
    "num_samples = int(1e7)\n",
    "alpha = 2\n",
    "beta = 4\n",
    "mean = 0\n",
    "std_dev_v1 = 0.01\n",
    "std_dev_v2 = 0.02\n",
    "std_dev_v3 = 0.03\n",
    "std_dev_z2 = 0.02\n",
    "std_dev_z3 = 0.03\n",
    "\n",
    "# Arrays of gamma and lambda\n",
    "gamma_arr = np.round(np.arange(0.98, 1.02, 0.01), 2)\n",
    "print(colored('An array of gamma:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(gamma_arr))\n",
    "\n",
    "lambda_arr = np.round(np.arange(-0.02, 0.03, 0.01), 2)\n",
    "print(colored('\\nAn array of lambda:', 'blue', attrs=['bold']))\n",
    "print('{}'.format(lambda_arr))\n",
    "\n",
    "# Independent eigenvectors\n",
    "eigenvectors = np.array([[1, 0, 0],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 0, 1],\n",
    "                         [0, 0, 0]])\n",
    "print(colored('\\nIndependent eigenvectors:', 'blue', attrs=['bold']))\n",
    "print(eigenvectors)\n",
    "\n",
    "# Covariance of noise Z_tilde\n",
    "sigma_squared = 0.04**2\n",
    "Sigma_Z_tilde = sigma_squared * np.identity(n)\n",
    "print(colored('\\nCovariance of noise Z_tilde:', 'blue', attrs=['bold']))\n",
    "print(np.round(Sigma_Z_tilde, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d132e67",
   "metadata": {},
   "source": [
    "## II. Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d34c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAll ways to divide the indices of the generative parameters into three distinct groups:\n",
      "\u001b[0m\n",
      "Partition 1: Group 1: set(), Group 2: set(), Group 3: {4, 5, 6}\n",
      "Partition 2: Group 1: set(), Group 2: {4}, Group 3: {5, 6}\n",
      "Partition 3: Group 1: set(), Group 2: {5}, Group 3: {4, 6}\n",
      "Partition 4: Group 1: set(), Group 2: {6}, Group 3: {4, 5}\n",
      "Partition 5: Group 1: set(), Group 2: {4, 5}, Group 3: {6}\n",
      "Partition 6: Group 1: set(), Group 2: {4, 6}, Group 3: {5}\n",
      "Partition 7: Group 1: set(), Group 2: {5, 6}, Group 3: {4}\n",
      "Partition 8: Group 1: set(), Group 2: {4, 5, 6}, Group 3: set()\n",
      "Partition 9: Group 1: {4}, Group 2: set(), Group 3: {5, 6}\n",
      "Partition 10: Group 1: {5}, Group 2: set(), Group 3: {4, 6}\n",
      "Partition 11: Group 1: {6}, Group 2: set(), Group 3: {4, 5}\n",
      "Partition 12: Group 1: {4}, Group 2: {5}, Group 3: {6}\n",
      "Partition 13: Group 1: {4}, Group 2: {6}, Group 3: {5}\n",
      "Partition 14: Group 1: {5}, Group 2: {4}, Group 3: {6}\n",
      "Partition 15: Group 1: {5}, Group 2: {6}, Group 3: {4}\n",
      "Partition 16: Group 1: {6}, Group 2: {4}, Group 3: {5}\n",
      "Partition 17: Group 1: {6}, Group 2: {5}, Group 3: {4}\n",
      "Partition 18: Group 1: {4}, Group 2: {5, 6}, Group 3: set()\n",
      "Partition 19: Group 1: {5}, Group 2: {4, 6}, Group 3: set()\n",
      "Partition 20: Group 1: {6}, Group 2: {4, 5}, Group 3: set()\n",
      "Partition 21: Group 1: {4, 5}, Group 2: set(), Group 3: {6}\n",
      "Partition 22: Group 1: {4, 6}, Group 2: set(), Group 3: {5}\n",
      "Partition 23: Group 1: {5, 6}, Group 2: set(), Group 3: {4}\n",
      "Partition 24: Group 1: {4, 5}, Group 2: {6}, Group 3: set()\n",
      "Partition 25: Group 1: {4, 6}, Group 2: {5}, Group 3: set()\n",
      "Partition 26: Group 1: {5, 6}, Group 2: {4}, Group 3: set()\n",
      "Partition 27: Group 1: {4, 5, 6}, Group 2: set(), Group 3: set()\n"
     ]
    }
   ],
   "source": [
    "print(colored('All ways to divide the indices of the generative parameters into three distinct groups:\\n', attrs=['bold']))\n",
    "\n",
    "V_indices = np.arange(m+1, m+s+1)\n",
    "\n",
    "group_1_list_V = []\n",
    "group_2_list_V = []\n",
    "group_3_list_V = []\n",
    "group_1_list_XV = []\n",
    "group_2_list_XV = []\n",
    "group_3_list_XV = []\n",
    "\n",
    "# Initialize an empty list to store valid partitions\n",
    "valid_partitions = []\n",
    "\n",
    "# Generate all possible ways to divide the indices of parameters into 3 groups (may be empty)\n",
    "V_indices = np.arange(m+1, m+s+1)\n",
    "\n",
    "for i in range(len(V_indices) + 1):\n",
    "    for j in range(len(V_indices) + 1):\n",
    "        if i + j <= len(V_indices):\n",
    "            group_1_combinations = combinations(V_indices, i)\n",
    "            for group_1 in group_1_combinations:\n",
    "                remaining_indices_1 = set(V_indices) - set(group_1)\n",
    "                group_2_combinations = combinations(remaining_indices_1, j)\n",
    "                for group_2 in group_2_combinations:\n",
    "                    group_3 = tuple(index for index in V_indices if index not in group_1 and index not in group_2)\n",
    "                    valid_partitions.append((set(group_1), set(group_2), set(group_3)))\n",
    "\n",
    "for idx, partition in enumerate(valid_partitions, start=1):\n",
    "    group_1, group_2, group_3 = partition\n",
    "    print(f'Partition {idx}: Group 1: {group_1}, Group 2: {group_2}, Group 3: {group_3}')\n",
    "\n",
    "    # Add group information to respective lists\n",
    "    group_1_list_V.append(list(group_1))\n",
    "    group_2_list_V.append(list(group_2))\n",
    "    group_3_list_V.append(list(group_3))\n",
    "    \n",
    "    group_1_list_XV.append([1] + list(group_1))   \n",
    "    group_2_list_XV.append([2] + list(group_2))\n",
    "    group_3_list_XV.append([3] + list(group_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7221e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the result arrays with empty lists\n",
    "group_list_v1v2 = [[] for _ in range(len(group_1_list_V))]\n",
    "group_list_v1v3 = [[] for _ in range(len(group_1_list_V))]\n",
    "group_list_v2v3 = [[] for _ in range(len(group_1_list_V))]\n",
    "\n",
    "# Function to combine arrays\n",
    "def combine_arrays(result, arr):\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i]:\n",
    "            result[i].extend(arr[i])\n",
    "\n",
    "# Combine group_1_list_V and group_2_list_V\n",
    "combine_arrays(group_list_v1v2, group_1_list_V)\n",
    "combine_arrays(group_list_v1v2, group_2_list_V)\n",
    "\n",
    "# Combine group_1_list_V and group_3_list_V\n",
    "combine_arrays(group_list_v1v3, group_1_list_V)\n",
    "combine_arrays(group_list_v1v3, group_3_list_V)\n",
    "\n",
    "# Combine group_2_list_V and group_3_list_V\n",
    "combine_arrays(group_list_v2v3, group_2_list_V)\n",
    "combine_arrays(group_list_v2v3, group_3_list_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb560a",
   "metadata": {},
   "source": [
    "## III. Numerical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69c474ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_I3(det_v1, det_v2, det_v3, det_x1v1, det_x2v2, det_x3v3, \n",
    "               det_v1v2, det_v1v3, det_v2v3, len_group_1, len_group_2, len_group_3):\n",
    "    \n",
    "    # 2 groups are empty\n",
    "    if len_group_1 == 0 and len_group_2 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v3/det_x3v3), 8)\n",
    "    elif len_group_1 == 0 and len_group_3 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v2/det_x2v2), 8)\n",
    "    elif len_group_2 == 0 and len_group_3 == 0:\n",
    "        I_3 = round(0.5 * np.log(det_v1/det_x1v1), 8)\n",
    "    \n",
    "    # 1 group is empty\n",
    "    elif len_group_1 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v2/det_x2v2) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v2*det_v3/det_v2v3)), 8)\n",
    "    elif len_group_2 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v1*det_v3/det_v1v3)), 8)\n",
    "    elif len_group_3 == 0:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v2/det_x2v2) - \\\n",
    "                           np.log(det_v1*det_v2/det_v1v2)), 8)\n",
    "        \n",
    "    # None of the groups are empty\n",
    "    else:\n",
    "        I_3 = round(0.5 * (np.log(det_v1/det_x1v1) + \\\n",
    "                           np.log(det_v2/det_x2v2) + \\\n",
    "                           np.log(det_v3/det_x3v3) - \\\n",
    "                           np.log(det_v1*det_v2/det_v1v2) - \\\n",
    "                           np.log(det_v1*det_v3/det_v1v3) - \\\n",
    "                           np.log(det_v2*det_v3/det_v2v3)), 8)\n",
    "    return I_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5b846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_two_largest_values(a, b, c):\n",
    "    values = {\"1\": a, \"2\": b, \"3\": c}\n",
    "    sorted_values = sorted(values.items(), key=lambda x: x[1], reverse=True)\n",
    "    (name1, value1), (name2, value2) = sorted_values[:2]\n",
    "    return (name1, value1), (name2, value2)\n",
    "\n",
    "def compute_SAP(Cov_x1v1, Cov_x2v1, Cov_x3v1,\n",
    "                Cov_x1v2, Cov_x2v2, Cov_x3v2,\n",
    "                Cov_x1v3, Cov_x2v3, Cov_x3v3):   \n",
    "\n",
    "    S_11 = (Cov_x1v1/std_dev_v1) ** 2 \n",
    "    S_21 = (Cov_x2v1/std_dev_v1) ** 2 \n",
    "    S_31 = (Cov_x3v1/std_dev_v1) ** 2 \n",
    "    \n",
    "    S_12 = (Cov_x1v2/std_dev_v2) ** 2 \n",
    "    S_22 = (Cov_x2v2/std_dev_v2) ** 2 \n",
    "    S_32 = (Cov_x3v2/std_dev_v2) ** 2 \n",
    "    \n",
    "    S_13 = (Cov_x1v3/std_dev_v3) ** 2 \n",
    "    S_23 = (Cov_x2v3/std_dev_v3) ** 2 \n",
    "    S_33 = (Cov_x3v3/std_dev_v3) ** 2\n",
    "    \n",
    "    result1_v1, result2_v1 = find_two_largest_values(S_11, S_21, S_31)\n",
    "    result1_v2, result2_v2 = find_two_largest_values(S_12, S_22, S_32)\n",
    "    result1_v3, result2_v3 = find_two_largest_values(S_13, S_23, S_33)\n",
    "          \n",
    "    diff_1 = result1_v1[1] - result2_v1[1]\n",
    "    diff_2 = result1_v2[1] - result2_v2[1]\n",
    "    diff_3 = result1_v3[1] - result2_v3[1]\n",
    "    \n",
    "    SAP = 1/s * (diff_1 + diff_2 + diff_3)\n",
    "    print(colored(f'\\nSAP = {round(SAP, 4)}', 'red', attrs=['bold']))\n",
    "    \n",
    "    if result1_v1[0] == result1_v2[0] == result1_v3[0]:\n",
    "        print('(v1, v2, v3) can be captured by a single latent variable.')\n",
    "    elif result1_v1[0] == result1_v2[0]:\n",
    "        print('(v1, v2) are captured by one latent variable and v3 by a second latent variable.') \n",
    "    elif result1_v2[0] == result1_v3[0]:\n",
    "        print('(v2, v3) are captured by one latent variable and v1 by a second latent variable.')\n",
    "    elif result1_v1[0] == result1_v3[0]:\n",
    "        print('(v1, v3) are captured by one latent variable and v2 by a second latent variable.')\n",
    "    else:\n",
    "        print('Each factor can be captured by a single latent variable.') \n",
    "    \n",
    "    return SAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28a52ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_I3(cov_XV):\n",
    "    max_MI = -1000\n",
    "    max_idx = 0\n",
    "    \n",
    "    det_x1v1_arr = []\n",
    "    det_x2v2_arr = []\n",
    "    det_x3v3_arr = []\n",
    "\n",
    "    # Generate an array of indices\n",
    "    for i, (group_1_idx_V, group_2_idx_V, group_3_idx_V,\n",
    "            group_1_idx_XV, group_2_idx_XV, group_3_idx_XV,\n",
    "            group_idx_v1v2, group_idx_v1v3, group_idx_v2v3) in enumerate(zip(group_1_list_V, group_2_list_V, group_3_list_V,\n",
    "                                                                             group_1_list_XV, group_2_list_XV, group_3_list_XV,\n",
    "                                                                             group_list_v1v2, group_list_v1v3, group_list_v2v3)):\n",
    "        \n",
    "        # Generate two-digit numbers with repetition from the array and in increasing order\n",
    "        group_1_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_1_idx_V, repeat=2)]\n",
    "        group_2_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_2_idx_V, repeat=2)]\n",
    "        group_3_two_digit_numbers_V = [int(str(a) + str(b)) for a, b in product(group_3_idx_V, repeat=2)]\n",
    "        \n",
    "        group_1_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_1_idx_XV, repeat=2)]\n",
    "        group_2_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_2_idx_XV, repeat=2)]\n",
    "        group_3_two_digit_numbers_XV = [int(str(a) + str(b)) for a, b in product(group_3_idx_XV, repeat=2)]\n",
    "        \n",
    "        group_two_digit_numbers_v1v2 = [int(str(a) + str(b)) for a, b in product(group_idx_v1v2, repeat=2)]\n",
    "        group_two_digit_numbers_v1v3 = [int(str(a) + str(b)) for a, b in product(group_idx_v1v3, repeat=2)]\n",
    "        group_two_digit_numbers_v2v3 = [int(str(a) + str(b)) for a, b in product(group_idx_v2v3, repeat=2)]\n",
    "    \n",
    "        # Specify the positions to extract\n",
    "        tuple_list_1_V = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_V]\n",
    "        tuple_list_2_V = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_V]\n",
    "        tuple_list_3_V = [(number // 10 - 1, number % 10 - 1) for number in group_3_two_digit_numbers_V]\n",
    "        \n",
    "        tuple_list_1_XV = [(number // 10 - 1, number % 10 - 1) for number in group_1_two_digit_numbers_XV]\n",
    "        tuple_list_2_XV = [(number // 10 - 1, number % 10 - 1) for number in group_2_two_digit_numbers_XV]\n",
    "        tuple_list_3_XV = [(number // 10 - 1, number % 10 - 1) for number in group_3_two_digit_numbers_XV]\n",
    "        \n",
    "        tuple_list_v1v2 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v1v2]\n",
    "        tuple_list_v1v3 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v1v3]\n",
    "        tuple_list_v2v3 = [(number // 10 - 1, number % 10 - 1) for number in group_two_digit_numbers_v2v3]\n",
    "    \n",
    "        # Get the new matrix from specified positions\n",
    "        dim_v1 = len(group_1_idx_V)\n",
    "        dim_v2 = len(group_2_idx_V)\n",
    "        dim_v3 = len(group_3_idx_V)\n",
    "        \n",
    "        dim_x1v1 = len(group_1_idx_XV)\n",
    "        dim_x2v2 = len(group_2_idx_XV)\n",
    "        dim_x3v3 = len(group_3_idx_XV)\n",
    "        \n",
    "        dim_v1v2 = len(group_idx_v1v2)\n",
    "        dim_v1v3 = len(group_idx_v1v3)\n",
    "        dim_v2v3 = len(group_idx_v2v3)\n",
    "    \n",
    "        cov_v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_V]).reshape(dim_v1, dim_v1)\n",
    "        if len(cov_v1) == 1:\n",
    "            cov_v1 = cov_v1[0]\n",
    "        cov_v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_V]).reshape(dim_v2, dim_v2)\n",
    "        if len(cov_v2) == 1:\n",
    "            cov_v2 = cov_v2[0]\n",
    "        cov_v3 = np.array([cov_XV[i, j] for i, j in tuple_list_3_V]).reshape(dim_v3, dim_v3)\n",
    "        if len(cov_v3) == 1:\n",
    "            cov_v3 = cov_v3[0]\n",
    "    \n",
    "        cov_x1v1 = np.array([cov_XV[i, j] for i, j in tuple_list_1_XV]).reshape(dim_x1v1, dim_x1v1)\n",
    "        cov_x2v2 = np.array([cov_XV[i, j] for i, j in tuple_list_2_XV]).reshape(dim_x2v2, dim_x2v2)\n",
    "        cov_x3v3 = np.array([cov_XV[i, j] for i, j in tuple_list_3_XV]).reshape(dim_x3v3, dim_x3v3)\n",
    "        \n",
    "        cov_v1v2 = np.array([cov_XV[i, j] for i, j in tuple_list_v1v2]).reshape(dim_v1v2, dim_v1v2)\n",
    "        cov_v1v3 = np.array([cov_XV[i, j] for i, j in tuple_list_v1v3]).reshape(dim_v1v3, dim_v1v3)\n",
    "        cov_v2v3 = np.array([cov_XV[i, j] for i, j in tuple_list_v2v3]).reshape(dim_v2v3, dim_v2v3)\n",
    "    \n",
    "        # Compute the determinant of each covariance matrix\n",
    "        det_x1v1 = det(cov_x1v1)\n",
    "        det_x2v2 = det(cov_x2v2)\n",
    "        det_x3v3 = det(cov_x3v3)\n",
    "        \n",
    "        det_v1v2 = det(cov_v1v2)\n",
    "        det_v1v3 = det(cov_v1v3)\n",
    "        det_v2v3 = det(cov_v2v3)\n",
    "        \n",
    "        if len(cov_v1) == 1:\n",
    "            det_v1 = cov_v1[0]\n",
    "            det_x1v1_arr.append(det_x1v1) \n",
    "        else:    \n",
    "            det_v1 = det(cov_v1)\n",
    "            \n",
    "        if len(cov_v2) == 1:\n",
    "            det_v2 = cov_v2[0]\n",
    "            det_x2v2_arr.append(det_x2v2) \n",
    "        else:    \n",
    "            det_v2 = det(cov_v2)\n",
    "            \n",
    "        if len(cov_v3) == 1:\n",
    "            det_v3 = cov_v3[0]\n",
    "            det_x3v3_arr.append(det_x3v3) \n",
    "        else:    \n",
    "            det_v3 = det(cov_v3)\n",
    "        \n",
    "        # Compute I_3\n",
    "        I_3 = compute_I3(det_v1, det_v2, det_v3, \n",
    "                         det_x1v1, det_x2v2, det_x3v3, \n",
    "                         det_v1v2, det_v1v3, det_v2v3,\n",
    "                         len(group_1_idx_V), len(group_2_idx_V), len(group_3_idx_V))\n",
    "    \n",
    "        if I_3 > max_MI:\n",
    "            max_MI = I_3\n",
    "            max_idx = i+1\n",
    "        \n",
    "    print(colored(f'\\nThe maximum value of I_3 is {round(max_MI, 4)} at Partition {max_idx}.', 'red', attrs=['bold']))\n",
    "    \n",
    "    partition = max_idx\n",
    "    \n",
    "    if 12 <= partition <= 17:\n",
    "        print('Each factor can be captured by a single latent variable.') \n",
    "    elif partition in [1, 8, 27]:\n",
    "        print('(v1, v2, v3) can be captured by a single latent variable.')\n",
    "    elif partition in [4, 5, 11, 20, 21, 24]:\n",
    "        print('(v1, v2) are captured by one latent variable and v3 by a second latent variable.')\n",
    "    elif partition in [3, 6, 10, 19, 22, 25]:\n",
    "        print('(v1, v3) are captured by one latent variable and v2 by a second latent variable.')\n",
    "    else:\n",
    "        print('(v2, v3) are captured by one latent variable and v1 by a second latent variable.')\n",
    "    \n",
    "    return max_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a1d0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(I3_scores, SAP_scores):\n",
    "    \"\"\"\n",
    "    Plot the comparison of I3 and SAP scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define indices for (gamma, lambda) pairs\n",
    "    pair_indices = range(1, 26)\n",
    "\n",
    "    # Plot I3 and SAP scores\n",
    "    plt.plot(pair_indices, I3_scores, label='I3', marker='o', linestyle='-', color='blue')\n",
    "    plt.plot(pair_indices, SAP_scores, label='SAP', marker='s', linestyle='--', color='green')\n",
    "\n",
    "    # Set axis labels and legend with LaTeX code\n",
    "    plt.xlabel(r'$(\\gamma, \\lambda)$ Pair Index')\n",
    "    plt.ylabel('Scores')\n",
    "\n",
    "    # Configure legend placement\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Enable LaTeX rendering\n",
    "    plt.rc('text', usetex=True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971ff2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_across_scenarios(score_1, score_2, score_3, flag):\n",
    "    \"\"\"\n",
    "    Plot of Score Distribution Across Scenarios\n",
    "    \"\"\"\n",
    "    \n",
    "    scenarios = ['Scenario 1', 'Scenario 2', 'Scenario 3']\n",
    "    scores = [score_1, score_2, score_3]\n",
    "\n",
    "    # Create a boxplot with colored boxes\n",
    "    boxplot = plt.boxplot(scores, labels=scenarios, patch_artist=True, medianprops=dict(color='black'))\n",
    "\n",
    "    # Set box colors\n",
    "    colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "    for box, color in zip(boxplot['boxes'], colors):\n",
    "        box.set_facecolor(color)\n",
    "\n",
    "    # Add statistics (mean, median, std) labels to legend\n",
    "    legend_labels = []\n",
    "    for i, data in enumerate(scores, start=1):\n",
    "        mean, median, std = np.mean(data), np.median(data), np.std(data)\n",
    "        label = f'Mean = {mean:.2f}\\nMedian = {median:.2f}\\nStd = {std:.2f}'\n",
    "        legend_labels.append(label)\n",
    "\n",
    "    if flag == 0:\n",
    "        plt.ylabel('I3 Scores')\n",
    "    else: \n",
    "        plt.ylabel('SAP Scores')\n",
    "\n",
    "    plt.grid(True, linestyle='-', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Move the legend outside and below the figure\n",
    "    plt.legend(handles=[boxplot[\"boxes\"][0], boxplot[\"boxes\"][1], boxplot[\"boxes\"][2]],\n",
    "               labels=legend_labels, loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=True, shadow=True, ncol=3)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0559a89e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 1:\u001b[0m\n",
      "Given (sigma_v1, sigma_v2, sigma_v3) = (0.01, 0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[ 0.0001 -0.     -0.    ]\n",
      " [-0.      0.0004 -0.    ]\n",
      " [-0.     -0.      0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.     0.     0.    ]\n",
      " [0.     0.002  0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.0 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0\n",
      "\n",
      "Reconstruction error:\n",
      "0.0\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 2.045e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0004\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0004\n",
      "\n",
      "Reconstruction error:\n",
      "2.045e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0001\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0001 at Partition 10.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 3.443e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0003\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0003\n",
      "\n",
      "Reconstruction error:\n",
      "3.443e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0 at Partition 24.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 1.557e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0023\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0023\n",
      "\n",
      "Reconstruction error:\n",
      "1.557e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0003\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0002 at Partition 17.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0001\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 1.2e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0269\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0269\n",
      "\n",
      "Reconstruction error:\n",
      "1.2e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0012\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0005 at Partition 3.\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0001\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 2.795e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0337\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0337\n",
      "\n",
      "Reconstruction error:\n",
      "2.795e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0067\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0056 at Partition 17.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.003\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.00496257 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.5785\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.5561\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496257\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.365\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2628 at Partition 12.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1105\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.00496269 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.5482\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.5259\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496269\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.365\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2161 at Partition 17.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0652\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.00496281 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.1519\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.1295\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496281\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.365\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3091 at Partition 16.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1608\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.00496293 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.2936\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.2712\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496293\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.365\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3066 at Partition 13.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1557\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.0039704 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.5367\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.5143\n",
      "\n",
      "Reconstruction error:\n",
      "0.0039704\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1419\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0614 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0066\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00985198 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.457\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.4124\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1408 at Partition 9.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0312\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.00985222 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "144.2767\n",
      "\n",
      "Mutual information of the decoder:\n",
      "144.2321\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985222\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.208 at Partition 16.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0971\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00985246 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.0818\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.0372\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985246\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2137 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1072\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.0098527 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "142.418\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.3734\n",
      "\n",
      "Reconstruction error:\n",
      "0.0098527\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1997 at Partition 2.\u001b[0m\n",
      "(v2, v3) are captured by one latent variable and v1 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0896\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00985294 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.1381\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.0935\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985294\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.365\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3353 at Partition 14.\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1811\u001b[0m\n",
      "Each factor can be captured by a single latent variable.\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 2:\u001b[0m\n",
      "Given (sigma_v1, sigma_v3) = (0.01, 0.03), alpha = 2, and sigma_z2 = 0.02:\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[0.0001 0.0002 0.    ]\n",
      " [0.0002 0.0008 0.    ]\n",
      " [0.     0.     0.0009]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.     0.    ]\n",
      " [0.0002 0.0024 0.     0.    ]\n",
      " [0.     0.     0.0025 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.01522543 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0803\n",
      "\n",
      "Reconstruction error:\n",
      "0.01522543\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0152 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0194\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.01519563 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0804\n",
      "\n",
      "Reconstruction error:\n",
      "0.01519563\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0175 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0261\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.01516584 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0789\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0804\n",
      "\n",
      "Reconstruction error:\n",
      "0.01516584\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0186 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0296\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.01513606 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.079\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0805\n",
      "\n",
      "Reconstruction error:\n",
      "0.01513606\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0199 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.034\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.01510628 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.079\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0805\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510628\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.02\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0132 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0151\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.00748475 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.09\n",
      "\n",
      "Reconstruction error:\n",
      "0.00748475\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0104 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0048\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.00745645 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.09\n",
      "\n",
      "Reconstruction error:\n",
      "0.00745645\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0193 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0289\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.00742817 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0892\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.00742817\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0224\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0132 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0088\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.00739988 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0893\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.00739988\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0225\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.015 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0133\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.0073716 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0893\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0901\n",
      "\n",
      "Reconstruction error:\n",
      "0.0073716\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0225\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.02 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0321\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 5.371e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1004\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1004\n",
      "\n",
      "Reconstruction error:\n",
      "5.371e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0239\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0175 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0225\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 2.69e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0999\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0999\n",
      "\n",
      "Reconstruction error:\n",
      "2.69e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.025\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0138 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0054\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 4.13e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1004\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1004\n",
      "\n",
      "Reconstruction error:\n",
      "4.13e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0248\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0149 at Partition 4.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0091\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 3.561e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.0996\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.0996\n",
      "\n",
      "Reconstruction error:\n",
      "3.561e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0256\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0205 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0288\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 4.966e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.1668\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.1668\n",
      "\n",
      "Reconstruction error:\n",
      "4.966e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.0516\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.027 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0083\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.00496257 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.974\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.9516\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496257\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4259\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2281 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1062\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.00496269 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.7437\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.7213\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496269\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4513\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3149 at Partition 11.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1959\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.00496281 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.9153\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.8929\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496281\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4513\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3136 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2882\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.00496293 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.2196\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.1972\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496293\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4513\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.311 at Partition 24.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2466\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.00496305 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.6443\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.6219\n",
      "\n",
      "Reconstruction error:\n",
      "0.00496305\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4513\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.4314 at Partition 11.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3877\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00985198 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "145.3234\n",
      "\n",
      "Mutual information of the decoder:\n",
      "145.2788\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2535\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1784 at Partition 5.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0792\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.00985222 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "142.6586\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.614\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985222\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4513\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3884 at Partition 11.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2809\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00985246 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.0361\n",
      "\n",
      "Mutual information of the decoder:\n",
      "142.9915\n",
      "\n",
      "Reconstruction error:\n",
      "0.00985246\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4259\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2128 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0702\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.00966539 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.469\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.4244\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966539\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0946 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.058\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00966564 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "141.9153\n",
      "\n",
      "Mutual information of the decoder:\n",
      "141.8708\n",
      "\n",
      "Reconstruction error:\n",
      "0.00966564\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.2281\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1722 at Partition 21.\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.205\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[4m\u001b[1m\n",
      "Scenario 3:\u001b[0m\n",
      "Given sigma_v1 = 0.01, (alpha, beta) = (2, 4), and (sigma_z2, sigma_z3) = (0.02, 0.03):\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of generative variable V:\u001b[0m\n",
      "[[0.0001 0.0002 0.0004]\n",
      " [0.0002 0.0008 0.0008]\n",
      " [0.0004 0.0008 0.0025]]\n",
      "\u001b[1m\u001b[31mThe matrix is not singular.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Covariance matrix of input data Y:\u001b[0m\n",
      "[[0.0017 0.0002 0.0004 0.    ]\n",
      " [0.0002 0.0024 0.0008 0.    ]\n",
      " [0.0004 0.0008 0.0041 0.    ]\n",
      " [0.     0.     0.     0.0016]]\n",
      "\u001b[1m\u001b[31mThe matrix is positive definite.\u001b[0m\n",
      "\u001b[1m\u001b[34m\n",
      "Case 1:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.02), the reconstruction error = 0.01517876 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2726\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2769\n",
      "\n",
      "Reconstruction error:\n",
      "0.01517876\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1485\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1391 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3499\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 2:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,-0.01), the reconstruction error = 0.01514335 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2727\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.277\n",
      "\n",
      "Reconstruction error:\n",
      "0.01514335\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1486\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0823 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0741\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 3:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.0), the reconstruction error = 0.01510793 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2728\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2771\n",
      "\n",
      "Reconstruction error:\n",
      "0.01510793\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1486\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0684 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0082\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 4:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.01), the reconstruction error = 0.01507249 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2729\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2772\n",
      "\n",
      "Reconstruction error:\n",
      "0.01507249\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1487\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.137 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3435\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 5:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.98,0.02), the reconstruction error = 0.01503704 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.273\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2772\n",
      "\n",
      "Reconstruction error:\n",
      "0.01503704\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1487\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1369 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3423\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 6:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.02), the reconstruction error = 0.00878012 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2895\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2918\n",
      "\n",
      "Reconstruction error:\n",
      "0.00878012\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1589\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1108 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1936\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 7:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,-0.01), the reconstruction error = 0.00873896 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2896\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2919\n",
      "\n",
      "Reconstruction error:\n",
      "0.00873896\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.159\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1007 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1961\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 8:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.0), the reconstruction error = 0.00869777 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2898\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.292\n",
      "\n",
      "Reconstruction error:\n",
      "0.00869777\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.159\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0818 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1045\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 9:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.01), the reconstruction error = 0.00865654 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.2899\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2921\n",
      "\n",
      "Reconstruction error:\n",
      "0.00865654\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1591\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0748 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0153\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 10:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (0.99,0.02), the reconstruction error = 0.00861527 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.29\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.2922\n",
      "\n",
      "Reconstruction error:\n",
      "0.00861527\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1592\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0946 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1754\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 11:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.02), the reconstruction error = 0.00012557 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3209\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3209\n",
      "\n",
      "Reconstruction error:\n",
      "0.00012557\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1777\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1278 at Partition 8.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2405\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 12:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,-0.01), the reconstruction error = 5.912e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3204\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3204\n",
      "\n",
      "Reconstruction error:\n",
      "5.912e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1766\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1244 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2285\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 13:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.0), the reconstruction error = 1e-06 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3235\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3235\n",
      "\n",
      "Reconstruction error:\n",
      "1e-06\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1781\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0792 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.026\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 14:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.01), the reconstruction error = 6.349e-05 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3228\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3228\n",
      "\n",
      "Reconstruction error:\n",
      "6.349e-05\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1783\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1717 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.4239\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 15:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.0,0.02), the reconstruction error = 0.00012126 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "0.3216\n",
      "\n",
      "Mutual information of the decoder:\n",
      "0.3216\n",
      "\n",
      "Reconstruction error:\n",
      "0.00012126\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.1777\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.0859 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.1081\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m\n",
      "Case 16:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.02), the reconstruction error = 0.00477982 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.8466\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.8242\n",
      "\n",
      "Reconstruction error:\n",
      "0.00477982\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.226 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.2267\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 17:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,-0.01), the reconstruction error = 0.00493008 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.6363\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.6139\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493008\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2887 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.3364\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 18:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.0), the reconstruction error = 0.00493054 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "68.5649\n",
      "\n",
      "Mutual information of the decoder:\n",
      "68.5425\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493054\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.4225 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.7438\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 19:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.01), the reconstruction error = 0.00495968 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "69.799\n",
      "\n",
      "Mutual information of the decoder:\n",
      "69.7766\n",
      "\n",
      "Reconstruction error:\n",
      "0.00495968\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6563\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.4014 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.5976\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 20:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.01,0.02), the reconstruction error = 0.00493087 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "70.4844\n",
      "\n",
      "Mutual information of the decoder:\n",
      "70.462\n",
      "\n",
      "Reconstruction error:\n",
      "0.00493087\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.32 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.446\u001b[0m\n",
      "(v1, v2) are captured by one latent variable and v3 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 21:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.02), the reconstruction error = 0.00948155 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.8766\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.8321\n",
      "\n",
      "Reconstruction error:\n",
      "0.00948155\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.3825 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.6029\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 22:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,-0.01), the reconstruction error = 0.00978139 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.5167\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.4721\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978139\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.5095 at Partition 27.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.8608\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 23:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.0), the reconstruction error = 0.00948328 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.4126\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.368\n",
      "\n",
      "Reconstruction error:\n",
      "0.00948328\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.1871 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.0318\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 24:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.01), the reconstruction error = 0.00978198 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.3949\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.3504\n",
      "\n",
      "Reconstruction error:\n",
      "0.00978198\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.6396\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.2691 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.4328\u001b[0m\n",
      "(v1, v3) are captured by one latent variable and v2 by a second latent variable.\n",
      "\u001b[1m\u001b[34m\n",
      "Case 25:\u001b[0m\n",
      "\n",
      "Given (gamma,lambda) = (1.02,0.02), the reconstruction error = 0.00948434 that SATISFIES the tolerance error = 0.05.\n",
      "\n",
      "\u001b[1m\u001b[31mThe optimal solution is NOT unique!\n",
      "\u001b[0m\n",
      "\u001b[1mAt optimal solution:\u001b[0m\n",
      "\n",
      "Mutual information of the encoder:\n",
      "143.9086\n",
      "\n",
      "Mutual information of the decoder:\n",
      "143.8641\n",
      "\n",
      "Reconstruction error:\n",
      "0.00948434\n",
      "\n",
      "Mutual information between generative variable and latent variable:\n",
      "0.4892\n",
      "\u001b[1m\u001b[31m\n",
      "The maximum value of I_3 is 0.4335 at Partition 1.\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n",
      "\u001b[1m\u001b[31m\n",
      "SAP = 0.7498\u001b[0m\n",
      "(v1, v2, v3) can be captured by a single latent variable.\n"
     ]
    }
   ],
   "source": [
    "# Numerical Simulation\n",
    "all_I3_score_arr = []\n",
    "all_SAP_score_arr = []\n",
    "\n",
    "for case in range(num_cases):\n",
    "    # Compute Sigma_Y given Sigma_V\n",
    "    Sigma_V = generate_Sigma_V(case)\n",
    "    \n",
    "    Sigma_Y = eigenvectors @ Sigma_V @ eigenvectors.T + Sigma_Z_tilde\n",
    "    print(colored('\\nCovariance matrix of input data Y:', 'blue', attrs=['bold']))\n",
    "    print(np.round(Sigma_Y, 4))\n",
    "    is_positive_definite(Sigma_Y)\n",
    "    \n",
    "    # Compute the determiant of each generative variable\n",
    "    diagonal_elements = [Sigma_V[i, i] for i in range(s)]\n",
    "    det_v_1, det_v_2, det_v_3 = diagonal_elements[0], diagonal_elements[1], diagonal_elements[2]\n",
    "    \n",
    "    # Constants\n",
    "    MAX_SOLS = 1\n",
    "    is_array = 1\n",
    "    flag = 0\n",
    "    case_num = 1\n",
    "\n",
    "    # Initiate arrays\n",
    "    min_recon_err_arr = []\n",
    "    min_en_mi_arr = []\n",
    "    min_de_mi_arr = []\n",
    "    all_recon_mi_arr = []\n",
    "    satisfied_recon_mi_arr = []\n",
    "    satisfied_gamma_lambda_arr = []\n",
    "    \n",
    "    # Iteration step\n",
    "    for i in range(0, len(gamma_arr)):\n",
    "        gamma = gamma_arr[i]\n",
    "        for j in range(0, len(lambda_arr)):\n",
    "            lamda = lambda_arr[j]\n",
    "        \n",
    "            min_recon_err, min_en_mi, min_de_mi, min_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "        \n",
    "            first_iter = 1\n",
    "            for num_sols in range(0, MAX_SOLS):\n",
    "                current_recon_err, current_en_mi, current_de_mi, current_opt_sol = print_comprehensive_results(gamma, lamda, flag, m, n, is_array)\n",
    "    \n",
    "                # Check for unique optimal solutions for each (gamma, lambda) pair\n",
    "                if first_iter == 1:\n",
    "                    if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - min_opt_sol[:2*n*m+n*n+m*m], 1e-6):\n",
    "                        is_unique = 1\n",
    "                        unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                    else:\n",
    "                        is_unique = 0\n",
    "                    first_iter = 0\n",
    "                else:\n",
    "                    if is_unique == 1:\n",
    "                        if is_close_to_zero(current_opt_sol[:2*n*m+n*n+m*m] - unique_opt_sol, 1e-6):\n",
    "                            unique_opt_sol = current_opt_sol[:2*n*m+n*n+m*m]\n",
    "                        else:\n",
    "                            is_unique = 0\n",
    "    \n",
    "                # Return the solution with smallest reconstruction error\n",
    "                if current_recon_err < min_recon_err:\n",
    "                    min_recon_err = current_recon_err\n",
    "                    min_en_mi = current_en_mi\n",
    "                    min_de_mi = current_de_mi\n",
    "                    min_opt_sol = current_opt_sol\n",
    "                \n",
    "            min_recon_err_arr = np.concatenate((min_recon_err_arr, [min_recon_err]))\n",
    "            min_en_mi_arr = np.concatenate((min_en_mi_arr, [min_en_mi]))\n",
    "            min_de_mi_arr = np.concatenate((min_de_mi_arr, [min_de_mi]))\n",
    "            all_recon_mi_arr = np.concatenate((all_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            print(colored('\\nCase {}:'.format(case_num), 'blue', attrs=['bold']))\n",
    "            case_num += 1\n",
    "        \n",
    "            if min_recon_err > MAX_RECON_ERR:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that EXCEEDS the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            else:\n",
    "                print('\\nGiven (gamma,lambda) = ({},{}), the reconstruction error = {} that SATISFIES the tolerance error = {}.\\n'.format(gamma, lamda, min_recon_err, MAX_RECON_ERR))\n",
    "            \n",
    "                satisfied_gamma_lambda_arr = np.concatenate((satisfied_gamma_lambda_arr, [gamma, lamda]))\n",
    "                satisfied_recon_mi_arr = np.concatenate((satisfied_recon_mi_arr, [min_recon_err, min_en_mi, min_de_mi]))\n",
    "        \n",
    "            if is_unique == 1:\n",
    "                print(colored('The optimal solution is unique!\\n', 'blue', attrs=['bold']))\n",
    "            else:\n",
    "                print(colored('The optimal solution is NOT unique!\\n', 'red', attrs=['bold']))\n",
    "        \n",
    "            print_optimal_solution(min_opt_sol, m)\n",
    "        \n",
    "            # Compute mutual information I(V;X) and I_3\n",
    "            B_opt = min_opt_sol[n*m:2*n*m].reshape((m, n))\n",
    "            Sigma_W_opt = min_opt_sol[2*n*m+n*n:2*n*m+n*n+m*m].reshape((m, m))\n",
    "        \n",
    "            mutual_info_VX = mi_VX(B_opt, Sigma_W_opt)\n",
    "            print('\\nMutual information between generative variable and latent variable:')\n",
    "            print(round(mutual_info_VX, 4))\n",
    "        \n",
    "            cov_XV = covariance_matrix_XV(B_opt)\n",
    "            I3_max = max_I3(cov_XV)\n",
    "            \n",
    "            # Extract elements from covariance matrix (X,V)\n",
    "            Cov_x1v1 = cov_XV[0, 3]\n",
    "            Cov_x2v1 = cov_XV[1, 3]\n",
    "            Cov_x3v1 = cov_XV[2, 3]\n",
    "\n",
    "            Cov_x1v2 = cov_XV[0, 4]\n",
    "            Cov_x2v2 = cov_XV[1, 4]\n",
    "            Cov_x3v2 = cov_XV[2, 4]\n",
    "\n",
    "            Cov_x1v3 = cov_XV[0, 5]\n",
    "            Cov_x2v3 = cov_XV[1, 5]\n",
    "            Cov_x3v3 = cov_XV[2, 5]\n",
    "            \n",
    "            # Compute SAP\n",
    "            SAP_score = compute_SAP(Cov_x1v1, Cov_x2v1, Cov_x3v1,\n",
    "                                    Cov_x1v2, Cov_x2v2, Cov_x3v2,\n",
    "                                    Cov_x1v3, Cov_x2v3, Cov_x3v3)\n",
    "            \n",
    "            all_I3_score_arr.append(I3_max)\n",
    "            all_SAP_score_arr.append(SAP_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e835507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 1:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 2:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4m\u001b[1mScenario 3:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Divide into three arrays, each with 25 values for each scenario\n",
    "SAP_1, SAP_2, SAP_3 = np.array_split(all_SAP_score_arr, 3)\n",
    "I3_1, I3_2, I3_3 = np.array_split(all_I3_score_arr, 3)\n",
    "\n",
    "# Plot Comparison of I3 and SAP Scores for each scenario\n",
    "print(colored('Scenario 1:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I3_1, SAP_1)\n",
    "\n",
    "print(colored('Scenario 2:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I3_2, SAP_2)\n",
    "\n",
    "print(colored('Scenario 3:', attrs=['bold', 'underline']))\n",
    "plot_comparison(I3_3, SAP_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27097c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots of Distribution of I3 and SAP Scores Across Scenarios\n",
    "plot_score_across_scenarios(I3_1, I3_2, I3_3, 0)\n",
    "plot_score_across_scenarios(SAP_1, SAP_2, SAP_3, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
